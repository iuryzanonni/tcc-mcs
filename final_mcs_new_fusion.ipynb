{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Classifiers Ensemble System (MCS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iury Zanonni de Faria"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diversity imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifiers imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = ['Unnamed: 0', 'revenue','cost-goods-sold','gross-profit','research-development-expenses','selling-general-administrative-expenses','operating-expenses',\n",
    "'operating-income','total-non-operating-income-expense','pre-tax-income','total-provision-income-taxes','income-after-taxes','income-from-continuous-operations',\n",
    "'income-from-discontinued-operations','net-income','ebitda','ebit','basic-shares-outstanding','shares-outstanding','eps-basic-net-earnings-per-share',\n",
    "'eps-earnings-per-share-diluted','cash-on-hand','receivables-total','inventory','other-current-assets','total-current-assets','net-property-plant-equipment',\n",
    "'long-term-investments','goodwill-intangible-assets-total','other-long-term-assets','total-long-term-assets','total-assets','total-current-liabilities','long-term-debt',\n",
    "'other-non-current-liabilities','total-long-term-liabilities','total-liabilities','common-stock-net','retained-earnings-accumulated-deficit','comprehensive-income',\n",
    "'total-share-holder-equity','total-liabilities-share-holders-equity','net-income-loss','total-depreciation-amortization-cash-flow','other-non-cash-items','total-non-cash-items',\n",
    "'change-in-accounts-receivable','change-in-inventories','change-in-accounts-payable','change-in-assets-liabilities','total-change-in-assets-liabilities',\n",
    "'cash-flow-from-operating-activities','net-change-in-property-plant-equipment','net-change-in-intangible-assets','net-acquisitions-divestitures','investing-activities-other',\n",
    "'cash-flow-from-investing-activities','net-long-term-debt','net-current-debt','debt-issuance-retirement-net-total','net-common-equity-issued-repurchased',\n",
    "'net-total-equity-issued-repurchased','total-common-preferred-stock-dividends-paid','financial-activities-other','cash-flow-from-financial-activities',\n",
    "'net-cash-flow','stock-based-compensation','common-stock-dividends-paid','current-ratio','long-term-debt-capital','debt-equity-ratio','gross-margin',\n",
    "'operating-margin','ebit-margin','pre-tax-profit-margin','net-profit-margin','asset-turnover','inventory-turnover','receiveable-turnover','days-sales-in-receivables',\n",
    "'roe','return-on-tangible-equity','roa','roi','book-value-per-share','operating-cash-flow-per-share','free-cash-flow-per-share','net-change-in-short-term-investments',\n",
    "'net-change-in-long-term-investments','net-change-in-investments-total','other-operating-income-expenses','pre-paid-expenses','other-share-holders-equity','other-income',\n",
    "'ebitda-margin']\n",
    "\n",
    "REAL_RETURN_CLASS = \"RealReturnClass\"\n",
    "REAL_RETURN = \"RealReturn\"\n",
    "RISK_CLASS = 'RiskClass'\n",
    "RISK = \"Risk\"\n",
    "\n",
    "HIGH = 'high'\n",
    "MEDIUM = 'medium'\n",
    "LOW = 'low'\n",
    "\n",
    "DATE = 'Unnamed: 0'\n",
    "\n",
    "N_PERIODS = 2\n",
    "N_FEATURES = 80\n",
    "\n",
    "DATASET_PATH = 'new_dataset/process_final_{}.csv'.format(N_PERIODS)\n",
    "\n",
    "MUTUAL_INFORMATION = \"MUTUAL_INFORMATION\"\n",
    "\n",
    "SPEARMAN = \"SPEARMAN\"\n",
    "\n",
    "ONE_R = \"ONE_R\"\n",
    "\n",
    "FEATURE_SELECTION = SPEARMAN\n",
    "\n",
    "#Remove os warnings do notebook\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f'files_fusion/FUSION.txt', 'w+')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(dataset:pd.DataFrame, title_1:str, title_2:str):\n",
    "  fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "  fig.set_figwidth(15)\n",
    "  fig.set_figheight(5)\n",
    "\n",
    "  x = dataset[REAL_RETURN_CLASS].value_counts()\n",
    "  x.plot.bar(ax=axes[0])\n",
    "  axes[0].set_title(title_1)\n",
    "\n",
    "  x = dataset[RISK_CLASS].value_counts()\n",
    "  x.plot.bar(ax=axes[1])\n",
    "  axes[1].set_title(title_2)\n",
    "\n",
    "plotResults(dataset, \"Real Return\", \"Risk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.replace(to_replace=[HIGH], value=2.0)\n",
    "dataset = dataset.replace(to_replace=[MEDIUM], value=1.0)\n",
    "dataset = dataset.replace(to_replace=[LOW], value=0.0)\n",
    "\n",
    "dataset = dataset.replace(to_replace=[np.NaN], value=0.0)\n",
    "\n",
    "dataset_X = dataset.drop(columns=[REAL_RETURN_CLASS, REAL_RETURN, RISK_CLASS, RISK, DATE])\n",
    "dataset_y = dataset.drop(columns=DATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"######## FEATURES ########\")\n",
    "file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_start_date = dt.datetime.now()\n",
    "file.write(f\"\\nSTART: {run_start_date}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFeatures(typeFeature, typeClass, num):\n",
    "\tfile = open(f'./feature_selection/files/{typeFeature}_{typeClass}.txt', 'r')\n",
    "\tresult = []\n",
    "\t\n",
    "\tfor feature in file:\n",
    "\t\tresult.append(eval(str(feature)))\n",
    "\t    \n",
    "\tfile.close()\n",
    "    \n",
    "\treturn result[:num]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ranking_real_return = readFeatures(FEATURE_SELECTION, REAL_RETURN, N_FEATURES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ranking_risk  = readFeatures(FEATURE_SELECTION, RISK, N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColumnsRank(rank: list):\n",
    "  ranking = []\n",
    "  for column in rank:\n",
    "    ranking.append(column[0])\n",
    "    \n",
    "  return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesSelection(feature_selection, type, n_features):\n",
    "  final_rank = readFeatures(feature_selection, type, N_FEATURES)\n",
    "  features = getColumnsRank(final_rank)[:n_features]\n",
    "  return features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dataset = DATA\n",
    "columns_dataset.append(REAL_RETURN)\n",
    "columns_dataset.append(RISK)\n",
    "columns_dataset.append(REAL_RETURN_CLASS)\n",
    "columns_dataset.append(RISK_CLASS)\n",
    "\n",
    "df_train = None\n",
    "df_test = None\n",
    "\n",
    "df_train = pd.DataFrame(columns=columns_dataset)\n",
    "df_test = pd.DataFrame(columns=columns_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./util/dataset_train.csv')\n",
    "df_test = pd.read_csv('./util/dataset_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetTrainTest(feature_selection, type, n_features):\n",
    "  features = getFeaturesSelection(feature_selection, type, n_features)\n",
    "\n",
    "  class_type = REAL_RETURN_CLASS if type == REAL_RETURN else RISK_CLASS\n",
    "\n",
    "  X_train = df_train[features]\n",
    "  y_train = df_train[class_type]\n",
    "\n",
    "  X_test = df_test[features]\n",
    "  y_test = df_test[class_type]\n",
    "\n",
    "  return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificadores Únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## CLASSIFICADORES UNICOS ########\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_real_return = {}\n",
    "classifiers_risk = {}\n",
    "dataset_classifiers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_FOREST = 'RANDOM_FOREST'\n",
    "SVM = 'SVM'\n",
    "DECISION_TREE = 'DECISION_TREE'\n",
    "NEURAL_NETWORK = 'NEURAL_NETWORK'\n",
    "LOGISTIC_REGRESSION ='LOGISTIC_REGRESSION'\n",
    "XG_BOOST = 'XG_BOOST'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_real_return_train, y_real_return_train, X_real_return_test, y_real_return_test = datasetTrainTest(MUTUAL_INFORMATION, REAL_RETURN, 70)\n",
    "dataset_classifiers[RANDOM_FOREST] = {REAL_RETURN: (MUTUAL_INFORMATION, 70)}\n",
    "\n",
    "randon_forest_return = RandomForestClassifier(n_estimators = 840, max_depth = 178, min_samples_split = 4, min_samples_leaf = 6, max_features = 'sqrt')\n",
    "classifiers_real_return[RANDOM_FOREST] = randon_forest_return\n",
    "\n",
    "randon_forest_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_randon_forest_return = randon_forest_return.score(X_real_return_test, y_real_return_test)\n",
    "result_randon_forest_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risk_train, y_risk_train, X_risk_test, y_risk_test = datasetTrainTest(SPEARMAN, RISK, 80)\n",
    "dataset_classifiers[RANDOM_FOREST] = {RISK: (SPEARMAN, 80)}\n",
    "\n",
    "randon_forest_risk = RandomForestClassifier(n_estimators = 622, max_depth = 70, min_samples_split = 3, min_samples_leaf = 9, max_features = 'log2')\n",
    "\n",
    "classifiers_risk[RANDOM_FOREST] = randon_forest_risk\n",
    "randon_forest_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_randon_forest_risk = randon_forest_risk.score(X_risk_test, y_risk_test)\n",
    "result_randon_forest_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"RANDOM FOREST:({result_randon_forest_return},{result_randon_forest_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_return_train, y_real_return_train, X_real_return_test, y_real_return_test = datasetTrainTest(MUTUAL_INFORMATION, REAL_RETURN, 1)\n",
    "dataset_classifiers[SVM] = {REAL_RETURN: (MUTUAL_INFORMATION, 1)}\n",
    "\n",
    "svm_real_return = SVC(kernel = 'rbf', C = 99.94849891435051, class_weight = 'balanced')\n",
    "classifiers_real_return[SVM] = svm_real_return\n",
    "\n",
    "svm_real_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_svm_return = svm_real_return.score(X_real_return_test, y_real_return_test)\n",
    "result_svm_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risk_train, y_risk_train, X_risk_test, y_risk_test = datasetTrainTest(MUTUAL_INFORMATION, RISK, 80)\n",
    "dataset_classifiers[SVM] = {RISK: (MUTUAL_INFORMATION, 80)}\n",
    "\n",
    "svm_risk = SVC(kernel = 'rbf', C = 99.89489576327396, class_weight = 'balanced')\n",
    "classifiers_risk[SVM] = svm_risk\n",
    "\n",
    "svm_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_svm_risk = svm_risk.score(X_risk_test, y_risk_test)\n",
    "result_svm_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"SVM:({result_svm_return},{result_svm_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_return_train, y_real_return_train, X_real_return_test, y_real_return_test = datasetTrainTest(SPEARMAN, REAL_RETURN, 40)\n",
    "dataset_classifiers[DECISION_TREE] = {REAL_RETURN: (SPEARMAN, 40)}\n",
    "\n",
    "decision_tree_real_return = DecisionTreeClassifier(criterion = 'entropy', splitter = 'best', max_depth = 10, min_samples_split = 1097)\n",
    "classifiers_real_return[DECISION_TREE] = decision_tree_real_return\n",
    "\n",
    "decision_tree_real_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_decision_return = decision_tree_real_return.score(X_real_return_test, y_real_return_test)\n",
    "result_decision_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risk_train, y_risk_train, X_risk_test, y_risk_test = datasetTrainTest(SPEARMAN, RISK, 30)\n",
    "dataset_classifiers[DECISION_TREE] = {RISK: (SPEARMAN, 30)}\n",
    "\n",
    "decision_tree_risk = DecisionTreeClassifier(criterion = 'entropy', splitter = 'best', max_depth = 133, min_samples_split = 919)\n",
    "classifiers_risk[DECISION_TREE] = decision_tree_risk\n",
    "\n",
    "decision_tree_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_decision_risk = decision_tree_risk.score(X_risk_test, y_risk_test)\n",
    "result_decision_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"DECISION TREE:({result_decision_return},{result_decision_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rede Neural"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_return_train, y_real_return_train, X_real_return_test, y_real_return_test = datasetTrainTest(SPEARMAN, REAL_RETURN, 1)\n",
    "dataset_classifiers[NEURAL_NETWORK] = {REAL_RETURN: (SPEARMAN, 1)}\n",
    "\n",
    "neural_return = MLPClassifier(activation = 'logistic', solver = 'lbfgs', max_iter = 500, hidden_layer_sizes = (300,), learning_rate = 'constant')\n",
    "classifiers_real_return[NEURAL_NETWORK] = neural_return\n",
    "\n",
    "neural_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_neural_return = neural_return.score(X_real_return_test, y_real_return_test)\n",
    "result_neural_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risk_train, y_risk_train, X_risk_test, y_risk_test = datasetTrainTest(SPEARMAN, RISK, 30)\n",
    "dataset_classifiers[NEURAL_NETWORK] = {RISK: (SPEARMAN, 30)}\n",
    "\n",
    "neural_risk = MLPClassifier(activation = 'logistic', solver = 'lbfgs', max_iter = 500, hidden_layer_sizes = (300,), learning_rate = 'constant')\n",
    "classifiers_risk[NEURAL_NETWORK] = neural_risk\n",
    "\n",
    "neural_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_neural_risk = neural_risk.score(X_risk_test, y_risk_test)\n",
    "result_neural_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"NEURAL NETWORK:({result_neural_return},{result_decision_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_return_train, y_real_return_train, X_real_return_test, y_real_return_test = datasetTrainTest(MUTUAL_INFORMATION, REAL_RETURN, 1)\n",
    "dataset_classifiers[LOGISTIC_REGRESSION] = {REAL_RETURN: (MUTUAL_INFORMATION, 1)}\n",
    "\n",
    "rl_return = LogisticRegression(penalty = 'l2', C = 48.72671442481355, class_weight = 'balanced', solver = 'lbfgs', max_iter = 97847, n_jobs=-1)\n",
    "classifiers_real_return[LOGISTIC_REGRESSION] = rl_return\n",
    "\n",
    "rl_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_rl_return = rl_return.score(X_real_return_test, y_real_return_test)\n",
    "result_rl_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risk_train, y_risk_train, X_risk_test, y_risk_test = datasetTrainTest(SPEARMAN, RISK, 70)\n",
    "dataset_classifiers[LOGISTIC_REGRESSION] = {RISK: (SPEARMAN, 70)}\n",
    "\n",
    "rl_risk = LogisticRegression(penalty = 'l2', C = 48.72671442481355, class_weight = 'balanced', solver = 'lbfgs', max_iter = 97847, n_jobs=-1)\n",
    "classifiers_risk[LOGISTIC_REGRESSION] = rl_risk\n",
    "\n",
    "rl_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_rl_risk = rl_risk.score(X_risk_test, y_risk_test)\n",
    "result_rl_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"LOGISTIC REGRESSION:({result_rl_return},{result_rl_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGboost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_return_train, y_real_return_train, X_real_return_test, y_real_return_test = datasetTrainTest(MUTUAL_INFORMATION, REAL_RETURN, 94)\n",
    "dataset_classifiers[XG_BOOST] = {REAL_RETURN: (MUTUAL_INFORMATION, 94)}\n",
    "\n",
    "xg_boost_return = xgboost.XGBClassifier()\n",
    "classifiers_real_return[XG_BOOST] = xg_boost_return\n",
    "\n",
    "xg_boost_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_xgboost_result = xg_boost_return.score(X_real_return_test, y_real_return_test)\n",
    "result_xgboost_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risk_train, y_risk_train, X_risk_test, y_risk_test = datasetTrainTest(SPEARMAN, RISK, 80)\n",
    "dataset_classifiers[XG_BOOST] = {RISK: (SPEARMAN, 80)}\n",
    "\n",
    "xg_boost_risk = xgboost.XGBClassifier()\n",
    "classifiers_risk[XG_BOOST] = xg_boost_risk\n",
    "\n",
    "xg_boost_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_xgboost_risk = xg_boost_risk.score(X_risk_test, y_risk_test)\n",
    "result_xgboost_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"XGBOOST:({result_xgboost_result},{result_xgboost_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 10\n",
    "result_cv_real_return = {}\n",
    "result_cv_risk = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(feature_selection, type, n_features):\n",
    "  features = getFeaturesSelection(feature_selection, type, n_features)\n",
    "\n",
    "  class_type = REAL_RETURN_CLASS if type == REAL_RETURN else RISK_CLASS\n",
    "\n",
    "  X_dataset = dataset[features]\n",
    "  y_dataset = dataset[class_type]  \n",
    "\n",
    "  return X_dataset, y_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset_real_return, y_dataset_real_return = dataset(MUTUAL_INFORMATION, REAL_RETURN, 70)\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[RANDOM_FOREST], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[RANDOM_FOREST] = cv_result.mean()\n",
    "\n",
    "X_dataset_real_return, y_dataset_real_return = dataset(MUTUAL_INFORMATION, REAL_RETURN, 1)\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[SVM], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[SVM] = cv_result.mean()\n",
    "\n",
    "X_dataset_real_return, y_dataset_real_return = dataset(SPEARMAN, REAL_RETURN, 40)\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[DECISION_TREE], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[DECISION_TREE] = cv_result.mean()\n",
    "\n",
    "X_dataset_real_return, y_dataset_real_return = dataset(SPEARMAN, REAL_RETURN, 1)\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[NEURAL_NETWORK], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[NEURAL_NETWORK] = cv_result.mean()\n",
    "\n",
    "X_dataset_real_return, y_dataset_real_return = dataset(MUTUAL_INFORMATION, REAL_RETURN, 1)\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[LOGISTIC_REGRESSION], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[LOGISTIC_REGRESSION] = cv_result.mean()\n",
    "\n",
    "X_dataset_real_return, y_dataset_real_return = dataset(SPEARMAN, REAL_RETURN, 94)\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[XG_BOOST], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[XG_BOOST] = cv_result.mean()\n",
    "\n",
    "result_cv_real_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset_risk, y_dataset_risk = dataset(SPEARMAN, RISK, 80)\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[RANDOM_FOREST], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[RANDOM_FOREST] = cv_result.mean()\n",
    "\n",
    "X_dataset_risk, y_dataset_risk = dataset(MUTUAL_INFORMATION, RISK, 80)\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[SVM], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[SVM] = cv_result.mean()\n",
    "\n",
    "X_dataset_risk, y_dataset_risk = dataset(SPEARMAN, RISK, 30)\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[DECISION_TREE], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[DECISION_TREE] = cv_result.mean()\n",
    "\n",
    "X_dataset_risk, y_dataset_risk = dataset(SPEARMAN, RISK, 30)\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[NEURAL_NETWORK], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[NEURAL_NETWORK] = cv_result.mean()\n",
    "\n",
    "X_dataset_risk, y_dataset_risk = dataset(SPEARMAN, RISK, 70)\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[LOGISTIC_REGRESSION], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[LOGISTIC_REGRESSION] = cv_result.mean()\n",
    "\n",
    "X_dataset_risk, y_dataset_risk = dataset(SPEARMAN, RISK, 80)\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[XG_BOOST], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[XG_BOOST] = cv_result.mean()\n",
    "\n",
    "result_cv_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## CV ########\\n\")\n",
    "file.write(f\"Real Return: {result_cv_real_return}\\n\")\n",
    "file.write(f\"Risk: {result_cv_risk}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Of Cassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = list(result_cv_real_return.keys())\n",
    "list_sets = []\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "  for j in range(i + 1, len(classifiers)):\n",
    "    list_sets.append((classifiers[i], classifiers[j]))\n",
    "\n",
    "list_sets\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Return Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_return_classifiers = []\n",
    "\n",
    "for classifier_set in list_sets:  \n",
    "  set_0 = result_cv_real_return[classifier_set[0]]\n",
    "  set_1 = result_cv_real_return[classifier_set[1]]\n",
    "\n",
    "  avg = (set_0 + set_1) / 2\n",
    "  if avg >= 0.75:\n",
    "    if classifier_set[0] not in real_return_classifiers:\n",
    "      real_return_classifiers.append(classifier_set[0])\n",
    "\n",
    "    if classifier_set[1] not in real_return_classifiers:\n",
    "      real_return_classifiers.append(classifier_set[1])\n",
    "\n",
    "real_return_classifiers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_classifiers = []\n",
    "\n",
    "for classifier_set in list_sets:  \n",
    "  set_0 = result_cv_risk[classifier_set[0]]\n",
    "  set_1 = result_cv_risk[classifier_set[1]]\n",
    "\n",
    "  avg = (set_0 + set_1) / 2\n",
    "  if avg >= 0.45:\n",
    "    if classifier_set[0] not in risk_classifiers:\n",
    "      risk_classifiers.append(classifier_set[0])\n",
    "\n",
    "    if classifier_set[1] not in risk_classifiers:\n",
    "      risk_classifiers.append(classifier_set[1])\n",
    "\n",
    "risk_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## CLASSIFIERS SELECTION ########\\n\")\n",
    "file.write(f\"Real Return: {real_return_classifiers}\\n\")\n",
    "file.write(f\"Risk: {risk_classifiers}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion of Classifiers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with diversification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Whitout diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## WHITOUT DIVERSITY ########\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_return_whitout_diversity = {}\n",
    "\n",
    "for classifier in real_return_classifiers:\n",
    "  feature_selection = dataset_classifiers[classifier][REAL_RETURN][0]\n",
    "  n_feature_selection = dataset_classifiers[classifier][REAL_RETURN][1]\n",
    "\n",
    "  X_real_return_train, y_real_return_train, X_real_return_test, y_real_return_test = datasetTrainTest(feature_selection, REAL_RETURN, n_feature_selection)\n",
    "\n",
    "  real_return_whitout_diversity[classifier] = classifiers_real_return[classifier]\n",
    "  real_return_whitout_diversity[classifier].fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "  file.write(f\"Real Return: {classifier}, {real_return_whitout_diversity[classifier].score(X_real_return_test, y_real_return_test)}\\n\")\n",
    "  print(classifier, real_return_whitout_diversity[classifier].score(X_real_return_test, y_real_return_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_whitout_diversity = {}\n",
    "\n",
    "for classifier in risk_classifiers:\n",
    "  feature_selection = dataset_classifiers[classifier][RISK][0]\n",
    "  n_feature_selection = dataset_classifiers[classifier][RISK][1]\n",
    "\n",
    "  X_risk_train, y_risk_train, X_risk_test, y_risk_test = datasetTrainTest(feature_selection, RISK, n_feature_selection)\n",
    "\n",
    "  risk_whitout_diversity[classifier] = classifiers_risk[classifier]\n",
    "  risk_whitout_diversity[classifier].fit(X_risk_train, y_risk_train)\n",
    "\n",
    "  file.write(f\"Risk: {classifier}, {risk_whitout_diversity[classifier].score(X_risk_test, y_risk_test)}\\n\")\n",
    "  print(classifier, risk_whitout_diversity[classifier].score(X_risk_test, y_risk_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## BAGGING ########\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_return_bagging = {}\n",
    "count = 0\n",
    "for classifier in real_return_classifiers:\n",
    "  feature_selection = dataset_classifiers[classifier][REAL_RETURN][0]\n",
    "  n_feature_selection = dataset_classifiers[classifier][REAL_RETURN][1]\n",
    "\n",
    "  X_real_return_train, y_real_return_train, X_real_return_test, y_real_return_test = datasetTrainTest(feature_selection, REAL_RETURN, n_feature_selection)\n",
    "  \n",
    "  estimator = classifiers_real_return[classifier]\n",
    "  real_return_bagging[classifier] = BaggingClassifier(estimator=estimator, n_jobs=-1)\n",
    "  real_return_bagging[classifier].fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "  file.write(f\"Real Return: {classifier}, {real_return_bagging[classifier].score(X_real_return_test, y_real_return_test)}\\n\")\n",
    "  print(classifier, real_return_bagging[classifier].score(X_real_return_test, y_real_return_test))\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_bagging = {}\n",
    "\n",
    "for classifier in risk_classifiers:\n",
    "  feature_selection = dataset_classifiers[classifier][RISK][0]\n",
    "  n_feature_selection = dataset_classifiers[classifier][RISK][1]\n",
    "\n",
    "  X_risk_train, y_risk_train, X_risk_test, y_risk_test = datasetTrainTest(feature_selection, RISK, n_feature_selection)\n",
    "  \n",
    "  estimator = classifiers_risk[classifier]\n",
    "  risk_bagging[classifier] = BaggingClassifier(estimator=estimator, n_jobs=-1)\n",
    "  risk_bagging[classifier].fit(X_risk_train, y_risk_train)\n",
    "\n",
    "  file.write(f\"Risk: {classifier}, {risk_bagging[classifier].score(X_risk_test, y_risk_test)}\\n\")\n",
    "  print(classifier, risk_bagging[classifier].score(X_risk_test, y_risk_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## ADABOOST ########\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_return_adaboost = {}\n",
    "\n",
    "for classifier in real_return_classifiers:\n",
    "  feature_selection = dataset_classifiers[classifier][REAL_RETURN][0]\n",
    "  n_feature_selection = dataset_classifiers[classifier][REAL_RETURN][1]\n",
    "\n",
    "  X_real_return_train, y_real_return_train, X_real_return_test, y_real_return_test = datasetTrainTest(feature_selection, REAL_RETURN, n_feature_selection)\n",
    "  \n",
    "  estimator = classifiers_real_return[classifier]\n",
    "  try:\n",
    "    real_return_adaboost[classifier] = AdaBoostClassifier(estimator=estimator)\n",
    "    real_return_adaboost[classifier].fit(X_real_return_train, y_real_return_train)\n",
    "    file.write(f\"RealReturn: {classifier}, {real_return_adaboost[classifier].score(X_real_return_test, y_real_return_test)}\\n\")\n",
    "    print(classifier, real_return_adaboost[classifier].score(X_real_return_test, y_real_return_test))\n",
    "  except:\n",
    "    real_return_adaboost.pop(classifier)\n",
    "    print(classifier, \"Não utilizado\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_adaboost = {}\n",
    "\n",
    "for classifier in risk_classifiers:\n",
    "  feature_selection = dataset_classifiers[classifier][RISK][0]\n",
    "  n_feature_selection = dataset_classifiers[classifier][RISK][1]\n",
    "\n",
    "  X_risk_train, y_risk_train, X_risk_test, y_risk_test = datasetTrainTest(feature_selection, RISK, n_feature_selection)\n",
    "\n",
    "  estimator = classifiers_risk[classifier]\n",
    "  try:\n",
    "    risk_adaboost[classifier] = AdaBoostClassifier(estimator=estimator)\n",
    "    risk_adaboost[classifier].fit(X_risk_train, y_risk_train)\n",
    "    file.write(f\"Risk: {classifier}, {risk_adaboost[classifier].score(X_risk_test, y_risk_test)}\\n\")\n",
    "    print(classifier, risk_adaboost[classifier].score(X_risk_test, y_risk_test))\n",
    "  except:\n",
    "    risk_adaboost.pop(classifier)\n",
    "    print(classifier, \"Não utilizado\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(fusion_model, models, X_data, y_data):\n",
    "  df_fusion = pd.DataFrame()\n",
    "\n",
    "  for model in models:\n",
    "    X_predict = models[model].predict(X_data)\n",
    "  \n",
    "    df_fusion[model] = X_predict\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(df_fusion, y_data, test_size=0.3, random_state=42)\n",
    "\n",
    "  print(X_train)\n",
    "  fusion_model.fit(X_train, y_train)\n",
    "  \n",
    "  return fusion_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFusionClassifiers(model_fusion, model_fusion_name, X_dataset_real_return, y_dataset_real_return, X_dataset_risk, y_dataset_risk):\n",
    "  whiout_return = fusion(model_fusion, real_return_whitout_diversity, X_dataset_real_return, y_dataset_real_return)\n",
    "  whiout_risk = fusion(model_fusion, risk_whitout_diversity, X_dataset_risk, y_dataset_risk)\n",
    "\n",
    "  file.write(f\"[WHITOUT] [{model_fusion_name}] RealReturn: {whiout_return}\\n\")\n",
    "  file.write(f\"[WHITOUT] [{model_fusion_name}] Risk: {whiout_risk}\\n\") if len(risk_classifiers) > 0 else file.write(f\"[WHITOUT] [{model_fusion_name}] Risk: -\\n\")\n",
    "\n",
    "  bagging_return = fusion(model_fusion, real_return_bagging, X_dataset_real_return, y_dataset_real_return)\n",
    "  bagging_risk = fusion(model_fusion, risk_bagging, X_dataset_risk, y_dataset_risk)\n",
    "\n",
    "  file.write(f\"[BAGGING] [{model_fusion_name}] RealReturn: {bagging_return}\\n\")\n",
    "  file.write(f\"[BAGGING] [{model_fusion_name}] Risk: {bagging_risk}\\n\") if len(risk_classifiers) > 0 else file.write(f\"[BAGGING] [{model_fusion_name}] Risk: -\\n\")\n",
    "\n",
    "  ada_return = fusion(model_fusion, real_return_adaboost, X_dataset_real_return, y_dataset_real_return)\n",
    "  ada_risk = fusion(model_fusion, risk_adaboost, X_dataset_risk, y_dataset_risk)\n",
    "\n",
    "  file.write(f\"[ADABOOST] [{model_fusion_name}] RealReturn: {ada_return}\\n\")\n",
    "  file.write(f\"[ADABOOST] [{model_fusion_name}] Risk: {ada_risk}\\n\") if len(risk_classifiers) > 0 else file.write(f\"[ADABOOST] [{model_fusion_name}] Risk: -\\n\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## FUSION ########\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "  RANDOM_FOREST: RandomForestClassifier(),\n",
    "  SVM: SVC(),\n",
    "  DECISION_TREE: DecisionTreeClassifier(),\n",
    "  NEURAL_NETWORK: MLPClassifier(),\n",
    "  LOGISTIC_REGRESSION: LogisticRegression(),\n",
    "  XG_BOOST: xgboost.XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in models.keys():\n",
    "  feature_selection = dataset_classifiers[key][REAL_RETURN][0]\n",
    "  n_feature_selection = dataset_classifiers[key][REAL_RETURN][1]\n",
    "\n",
    "  X_dataset_real_return, y_dataset_real_return = dataset(feature_selection, REAL_RETURN, n_feature_selection)\n",
    "\n",
    "  feature_selection = dataset_classifiers[key][RISK][0]\n",
    "  n_feature_selection = dataset_classifiers[key][RISK][1]\n",
    "\n",
    "  X_dataset_risk, y_dataset_risk = dataset(feature_selection, RISK, n_feature_selection)\n",
    "\n",
    "  testFusionClassifiers(models[key], key, X_dataset_real_return, y_dataset_real_return, X_dataset_risk, y_dataset_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_end_date = dt.datetime.now()\n",
    "file.write(f\"\\nEND: {run_end_date}\")\n",
    "file.write(f\"\\nTOTAL EXEC: {run_end_date-run_start_date}\")\n",
    "\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc8a3245a31a46333b724f0fa902266a4a2d307e3e7797c60732a355503841f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
