{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Classifiers Ensemble System (MCS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iury Zanonni de Faria"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "# Info gain - weka"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diversity imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifiers imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = ['Date', 'Current Ratio','Quick Ratio','Current Assets', 'Long-term debt to equity ratio', 'Share Holder Equity','Debt to Equity Ratio', 'Percentage of net profit to sale',\n",
    "'Percentage of operating profit to sale','Percentage of Gross profit to sale','ROA','ROE','EPS','P/E','P/S','Stock book value','Stock Price','ROI','MarketReturn', 'Company']\n",
    "\n",
    "DATA = ['Unnamed: 0', 'revenue','cost-goods-sold','gross-profit','research-development-expenses','selling-general-administrative-expenses','operating-expenses',\n",
    "'operating-income','total-non-operating-income-expense','pre-tax-income','total-provision-income-taxes','income-after-taxes','income-from-continuous-operations',\n",
    "'income-from-discontinued-operations','net-income','ebitda','ebit','basic-shares-outstanding','shares-outstanding','eps-basic-net-earnings-per-share',\n",
    "'eps-earnings-per-share-diluted','cash-on-hand','receivables-total','inventory','other-current-assets','total-current-assets','net-property-plant-equipment',\n",
    "'long-term-investments','goodwill-intangible-assets-total','other-long-term-assets','total-long-term-assets','total-assets','total-current-liabilities','long-term-debt',\n",
    "'other-non-current-liabilities','total-long-term-liabilities','total-liabilities','common-stock-net','retained-earnings-accumulated-deficit','comprehensive-income',\n",
    "'total-share-holder-equity','total-liabilities-share-holders-equity','net-income-loss','total-depreciation-amortization-cash-flow','other-non-cash-items','total-non-cash-items',\n",
    "'change-in-accounts-receivable','change-in-inventories','change-in-accounts-payable','change-in-assets-liabilities','total-change-in-assets-liabilities',\n",
    "'cash-flow-from-operating-activities','net-change-in-property-plant-equipment','net-change-in-intangible-assets','net-acquisitions-divestitures','investing-activities-other',\n",
    "'cash-flow-from-investing-activities','net-long-term-debt','net-current-debt','debt-issuance-retirement-net-total','net-common-equity-issued-repurchased',\n",
    "'net-total-equity-issued-repurchased','total-common-preferred-stock-dividends-paid','financial-activities-other','cash-flow-from-financial-activities',\n",
    "'net-cash-flow','stock-based-compensation','common-stock-dividends-paid','current-ratio','long-term-debt-capital','debt-equity-ratio','gross-margin',\n",
    "'operating-margin','ebit-margin','pre-tax-profit-margin','net-profit-margin','asset-turnover','inventory-turnover','receiveable-turnover','days-sales-in-receivables',\n",
    "'roe','return-on-tangible-equity','roa','roi','book-value-per-share','operating-cash-flow-per-share','free-cash-flow-per-share','net-change-in-short-term-investments',\n",
    "'net-change-in-long-term-investments','net-change-in-investments-total','other-operating-income-expenses','pre-paid-expenses','other-share-holders-equity','other-income',\n",
    "'ebitda-margin']\n",
    "\n",
    "REAL_RETURN_CLASS = \"RealReturnClass\"\n",
    "REAL_RETURN = \"RealReturn\"\n",
    "RISK_CLASS = 'RiskClass'\n",
    "RISK = \"Risk\"\n",
    "\n",
    "HIGH = 'high'\n",
    "MEDIUM = 'medium'\n",
    "LOW = 'low'\n",
    "\n",
    "DATE = 'Unnamed: 0'\n",
    "\n",
    "N_PERIODS = 2\n",
    "N_FEATURES = 20\n",
    "\n",
    "DATASET_PATH = 'new_dataset/process_final_{}.csv'.format(N_PERIODS)\n",
    "\n",
    "N_TRIALS = 100\n",
    "\n",
    "N_JOBS = -1\n",
    "\n",
    "MUTUAL_INFORMATION = \"MUTUAL_INFORMATION\"\n",
    "\n",
    "#Remove os warnings do notebook\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.replace(to_replace=[HIGH], value=2.0)\n",
    "dataset = dataset.replace(to_replace=[MEDIUM], value=1.0)\n",
    "dataset = dataset.replace(to_replace=[LOW], value=0.0)\n",
    "\n",
    "dataset = dataset.replace(to_replace=[np.NaN], value=0.0)\n",
    "\n",
    "dataset_X = dataset.drop(columns=[REAL_RETURN_CLASS, REAL_RETURN, RISK_CLASS, RISK, DATE])\n",
    "dataset_y = dataset.drop(columns=DATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFeatures(typeFeature, typeClass, num):\n",
    "\tfile = open(f'./feature_selection/files/{typeFeature}_{typeClass}.txt', 'r')\n",
    "\tresult = []\n",
    "\t\n",
    "\tfor feature in file:\n",
    "\t\tresult.append(eval(str(feature)))\n",
    "\t    \n",
    "\tfile.close()\n",
    "    \n",
    "\treturn result[:num]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ranking_real_return = readFeatures(MUTUAL_INFORMATION, REAL_RETURN, N_FEATURES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ranking_risk  = readFeatures(MUTUAL_INFORMATION, RISK, N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColumnsRank(rank: list):\n",
    "  ranking = []\n",
    "  for column in rank:\n",
    "    ranking.append(column[0])\n",
    "    \n",
    "  return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_real_return = getColumnsRank(final_ranking_real_return)[:N_FEATURES]\n",
    "features_risk = getColumnsRank(final_ranking_risk)[:N_FEATURES]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dataset = DATA\n",
    "columns_dataset.append(REAL_RETURN)\n",
    "columns_dataset.append(RISK)\n",
    "columns_dataset.append(REAL_RETURN_CLASS)\n",
    "columns_dataset.append(RISK_CLASS)\n",
    "\n",
    "df_train = None\n",
    "df_test = None\n",
    "\n",
    "df_train = pd.DataFrame(columns=columns_dataset)\n",
    "df_test = pd.DataFrame(columns=columns_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING_START_DATE =  dt.datetime.strptime('2009-03-31', \"%Y-%m-%d\")\n",
    "# TRAINING_END_DATE =  dt.datetime.strptime('2018-03-31', \"%Y-%m-%d\")\n",
    "\n",
    "# TEST_START_DATE =  dt.datetime.strptime('2018-06-30', \"%Y-%m-%d\")\n",
    "# TEST_END_DATE =  dt.datetime.strptime('2022-03-31', \"%Y-%m-%d\")\n",
    "\n",
    "# dataset_sort = dataset.sort_values(by=DATE)\n",
    "# count_train = 0\n",
    "# count_test = 0\n",
    "\n",
    "# for index, row in dataset_sort.iterrows():\n",
    "#   date = dt.datetime.strptime(row[DATE], \"%Y-%m-%d\")\n",
    "#   if date.year < TEST_START_DATE.year:\n",
    "#     df_train = df_train.append(row)\n",
    "#     count_train +=1\n",
    "#   elif date.year == TEST_START_DATE.year and date.month < TEST_START_DATE.month:\n",
    "#     df_train = df_train.append(row)\n",
    "#     count_train +=1\n",
    "#   else:\n",
    "#     df_test = df_test.append(row)\n",
    "#     count_test += 1\n",
    "\n",
    "# print(count_train)\n",
    "# print(count_test)\n",
    "\n",
    "# df_train = df_train.drop(columns=[REAL_RETURN, RISK, DATE])\n",
    "# df_test = df_test.drop(columns=[REAL_RETURN, RISK, DATE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./util/dataset_train.csv')\n",
    "df_test = pd.read_csv('./util/dataset_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_return_train = df_train[features_real_return]\n",
    "y_real_return_train = df_train[REAL_RETURN_CLASS]\n",
    "\n",
    "X_real_return_test = df_test[features_real_return]\n",
    "y_real_return_test = df_test[REAL_RETURN_CLASS]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risk_train = df_train[features_risk]\n",
    "y_risk_train = df_train[RISK_CLASS]\n",
    "\n",
    "X_risk_test = df_test[features_risk]\n",
    "y_risk_test = df_test[RISK_CLASS]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificadores Únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_real_return = {}\n",
    "classifiers_risk = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_best_result(study, classifier, type):\n",
    "\tprint(f'{classifier} - {type}')\n",
    "\tprint('Melhor pontuação:', study.best_value)\n",
    "\tprint('Melhores hiperparâmetros:', study.best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_random_forest_return(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 200),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'n_jobs': N_JOBS\n",
    "    }\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_real_return_train, y_real_return_train)\n",
    "    preds = model.predict(X_real_return_test)\n",
    "    accuracy = accuracy_score(y_real_return_test, preds)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 14:43:29,322]\u001b[0m A new study created in memory with name: no-name-35cb4aaf-80d4-4a80-a686-ae24ae54b5fb\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:43:34,564]\u001b[0m Trial 10 finished with value: 0.8376912881070009 and parameters: {'n_estimators': 13, 'max_depth': 53, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 10 with value: 0.8376912881070009.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:43:38,305]\u001b[0m Trial 2 finished with value: 0.8363658272080974 and parameters: {'n_estimators': 51, 'max_depth': 195, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.8376912881070009.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:03,188]\u001b[0m Trial 7 finished with value: 0.8390167490059043 and parameters: {'n_estimators': 318, 'max_depth': 107, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:07,560]\u001b[0m Trial 0 finished with value: 0.8364863236534522 and parameters: {'n_estimators': 326, 'max_depth': 122, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:10,473]\u001b[0m Trial 4 finished with value: 0.8382937703337752 and parameters: {'n_estimators': 394, 'max_depth': 180, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:15,628]\u001b[0m Trial 15 finished with value: 0.8378117845523557 and parameters: {'n_estimators': 76, 'max_depth': 137, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:18,891]\u001b[0m Trial 11 finished with value: 0.8382937703337752 and parameters: {'n_estimators': 511, 'max_depth': 153, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:23,991]\u001b[0m Trial 16 finished with value: 0.8378117845523557 and parameters: {'n_estimators': 130, 'max_depth': 141, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:26,693]\u001b[0m Trial 6 finished with value: 0.8358838414266779 and parameters: {'n_estimators': 480, 'max_depth': 156, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:30,566]\u001b[0m Trial 9 finished with value: 0.8374502952162911 and parameters: {'n_estimators': 544, 'max_depth': 59, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:34,877]\u001b[0m Trial 19 finished with value: 0.8375707916616459 and parameters: {'n_estimators': 97, 'max_depth': 118, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:37,336]\u001b[0m Trial 20 finished with value: 0.8379322809977106 and parameters: {'n_estimators': 101, 'max_depth': 24, 'min_samples_split': 10, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:38,286]\u001b[0m Trial 8 finished with value: 0.8376912881070009 and parameters: {'n_estimators': 625, 'max_depth': 140, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:41,689]\u001b[0m Trial 13 finished with value: 0.8358838414266779 and parameters: {'n_estimators': 555, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:45,521]\u001b[0m Trial 18 finished with value: 0.8380527774430654 and parameters: {'n_estimators': 287, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:49,095]\u001b[0m Trial 12 finished with value: 0.8376912881070009 and parameters: {'n_estimators': 748, 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:44:53,721]\u001b[0m Trial 5 finished with value: 0.83841426677913 and parameters: {'n_estimators': 822, 'max_depth': 93, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:45:02,129]\u001b[0m Trial 17 finished with value: 0.8374502952162911 and parameters: {'n_estimators': 430, 'max_depth': 93, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:45:02,296]\u001b[0m Trial 1 finished with value: 0.8380527774430654 and parameters: {'n_estimators': 977, 'max_depth': 177, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:45:10,995]\u001b[0m Trial 3 finished with value: 0.83841426677913 and parameters: {'n_estimators': 975, 'max_depth': 73, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:45:14,324]\u001b[0m Trial 14 finished with value: 0.83841426677913 and parameters: {'n_estimators': 722, 'max_depth': 80, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:45:36,367]\u001b[0m Trial 31 finished with value: 0.8379322809977106 and parameters: {'n_estimators': 225, 'max_depth': 73, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:45:40,444]\u001b[0m Trial 21 finished with value: 0.836727316544162 and parameters: {'n_estimators': 729, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:46:00,342]\u001b[0m Trial 23 finished with value: 0.8390167490059043 and parameters: {'n_estimators': 800, 'max_depth': 198, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:46:06,540]\u001b[0m Trial 24 finished with value: 0.8388962525605494 and parameters: {'n_estimators': 829, 'max_depth': 192, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:46:14,444]\u001b[0m Trial 26 finished with value: 0.8387757561151946 and parameters: {'n_estimators': 817, 'max_depth': 194, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:46:15,560]\u001b[0m Trial 22 finished with value: 0.8390167490059043 and parameters: {'n_estimators': 944, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:46:20,040]\u001b[0m Trial 25 finished with value: 0.8390167490059043 and parameters: {'n_estimators': 919, 'max_depth': 85, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:46:27,888]\u001b[0m Trial 27 finished with value: 0.8381732738884203 and parameters: {'n_estimators': 927, 'max_depth': 197, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:46:38,788]\u001b[0m Trial 28 finished with value: 0.8388962525605494 and parameters: {'n_estimators': 969, 'max_depth': 85, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:46:40,992]\u001b[0m Trial 30 finished with value: 0.83841426677913 and parameters: {'n_estimators': 894, 'max_depth': 90, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:46:50,731]\u001b[0m Trial 29 finished with value: 0.8380527774430654 and parameters: {'n_estimators': 998, 'max_depth': 86, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:46:59,314]\u001b[0m Trial 32 finished with value: 0.8380527774430654 and parameters: {'n_estimators': 993, 'max_depth': 71, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:47:19,801]\u001b[0m Trial 33 finished with value: 0.8387757561151946 and parameters: {'n_estimators': 973, 'max_depth': 105, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:47:27,137]\u001b[0m Trial 39 finished with value: 0.8376912881070009 and parameters: {'n_estimators': 652, 'max_depth': 43, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:47:27,771]\u001b[0m Trial 34 finished with value: 0.8379322809977106 and parameters: {'n_estimators': 975, 'max_depth': 106, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:47:32,688]\u001b[0m Trial 40 finished with value: 0.8380527774430654 and parameters: {'n_estimators': 652, 'max_depth': 109, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:47:42,655]\u001b[0m Trial 36 finished with value: 0.8379322809977106 and parameters: {'n_estimators': 902, 'max_depth': 190, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:47:45,793]\u001b[0m Trial 41 finished with value: 0.8382937703337752 and parameters: {'n_estimators': 650, 'max_depth': 40, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:47:48,783]\u001b[0m Trial 35 finished with value: 0.8386552596698398 and parameters: {'n_estimators': 992, 'max_depth': 39, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:47:49,649]\u001b[0m Trial 38 finished with value: 0.8382937703337752 and parameters: {'n_estimators': 901, 'max_depth': 36, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:47:50,907]\u001b[0m Trial 37 finished with value: 0.8382937703337752 and parameters: {'n_estimators': 910, 'max_depth': 171, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:47:56,538]\u001b[0m Trial 43 finished with value: 0.8380527774430654 and parameters: {'n_estimators': 649, 'max_depth': 38, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:47:57,639]\u001b[0m Trial 50 finished with value: 0.8210627786480299 and parameters: {'n_estimators': 347, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:48:04,230]\u001b[0m Trial 42 finished with value: 0.8386552596698398 and parameters: {'n_estimators': 883, 'max_depth': 37, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:48:17,506]\u001b[0m Trial 49 finished with value: 0.8373297987709363 and parameters: {'n_estimators': 350, 'max_depth': 36, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:48:24,136]\u001b[0m Trial 44 finished with value: 0.8385347632244848 and parameters: {'n_estimators': 898, 'max_depth': 35, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:48:24,936]\u001b[0m Trial 51 finished with value: 0.8388962525605494 and parameters: {'n_estimators': 357, 'max_depth': 164, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:48:42,543]\u001b[0m Trial 45 finished with value: 0.8381732738884203 and parameters: {'n_estimators': 880, 'max_depth': 38, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:48:51,028]\u001b[0m Trial 47 finished with value: 0.8378117845523557 and parameters: {'n_estimators': 883, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:48:54,724]\u001b[0m Trial 46 finished with value: 0.8387757561151946 and parameters: {'n_estimators': 869, 'max_depth': 39, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:49:03,327]\u001b[0m Trial 48 finished with value: 0.8387757561151946 and parameters: {'n_estimators': 888, 'max_depth': 41, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:49:16,775]\u001b[0m Trial 52 finished with value: 0.8373297987709363 and parameters: {'n_estimators': 836, 'max_depth': 173, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:49:17,016]\u001b[0m Trial 53 finished with value: 0.8379322809977106 and parameters: {'n_estimators': 833, 'max_depth': 172, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8390167490059043.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:49:25,817]\u001b[0m Trial 54 finished with value: 0.8405832027955176 and parameters: {'n_estimators': 840, 'max_depth': 178, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:49:26,015]\u001b[0m Trial 55 finished with value: 0.8393782383419689 and parameters: {'n_estimators': 837, 'max_depth': 180, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:49:30,920]\u001b[0m Trial 56 finished with value: 0.8394987347873237 and parameters: {'n_estimators': 816, 'max_depth': 171, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:49:41,166]\u001b[0m Trial 57 finished with value: 0.8390167490059043 and parameters: {'n_estimators': 817, 'max_depth': 171, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:49:47,654]\u001b[0m Trial 58 finished with value: 0.8390167490059043 and parameters: {'n_estimators': 812, 'max_depth': 171, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:49:52,217]\u001b[0m Trial 59 finished with value: 0.840221713459453 and parameters: {'n_estimators': 826, 'max_depth': 182, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:50:06,808]\u001b[0m Trial 60 finished with value: 0.8391372454512592 and parameters: {'n_estimators': 816, 'max_depth': 61, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:50:14,831]\u001b[0m Trial 61 finished with value: 0.8382937703337752 and parameters: {'n_estimators': 798, 'max_depth': 183, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:50:17,353]\u001b[0m Trial 62 finished with value: 0.8387757561151946 and parameters: {'n_estimators': 804, 'max_depth': 185, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:50:27,979]\u001b[0m Trial 63 finished with value: 0.8397397276780335 and parameters: {'n_estimators': 809, 'max_depth': 183, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:50:37,363]\u001b[0m Trial 65 finished with value: 0.8385347632244848 and parameters: {'n_estimators': 774, 'max_depth': 56, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:50:38,629]\u001b[0m Trial 64 finished with value: 0.8385347632244848 and parameters: {'n_estimators': 797, 'max_depth': 183, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:50:43,200]\u001b[0m Trial 66 finished with value: 0.8385347632244848 and parameters: {'n_estimators': 761, 'max_depth': 184, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:50:44,677]\u001b[0m Trial 67 finished with value: 0.8385347632244848 and parameters: {'n_estimators': 770, 'max_depth': 184, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:50:49,027]\u001b[0m Trial 68 finished with value: 0.8380527774430654 and parameters: {'n_estimators': 777, 'max_depth': 186, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:50:54,816]\u001b[0m Trial 69 finished with value: 0.8382937703337752 and parameters: {'n_estimators': 768, 'max_depth': 185, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:51:02,273]\u001b[0m Trial 70 finished with value: 0.83841426677913 and parameters: {'n_estimators': 770, 'max_depth': 183, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:51:06,383]\u001b[0m Trial 71 finished with value: 0.8382937703337752 and parameters: {'n_estimators': 764, 'max_depth': 184, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:51:19,412]\u001b[0m Trial 72 finished with value: 0.8392577418966141 and parameters: {'n_estimators': 744, 'max_depth': 181, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:51:24,185]\u001b[0m Trial 73 finished with value: 0.8387757561151946 and parameters: {'n_estimators': 696, 'max_depth': 155, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:51:33,311]\u001b[0m Trial 74 finished with value: 0.8376912881070009 and parameters: {'n_estimators': 758, 'max_depth': 159, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:51:42,212]\u001b[0m Trial 75 finished with value: 0.8376912881070009 and parameters: {'n_estimators': 755, 'max_depth': 159, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:51:48,377]\u001b[0m Trial 77 finished with value: 0.8391372454512592 and parameters: {'n_estimators': 696, 'max_depth': 150, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:51:49,747]\u001b[0m Trial 76 finished with value: 0.83841426677913 and parameters: {'n_estimators': 722, 'max_depth': 149, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:51:53,054]\u001b[0m Trial 78 finished with value: 0.8375707916616459 and parameters: {'n_estimators': 696, 'max_depth': 154, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:51:58,124]\u001b[0m Trial 80 finished with value: 0.8387757561151946 and parameters: {'n_estimators': 703, 'max_depth': 160, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:51:59,490]\u001b[0m Trial 79 finished with value: 0.8378117845523557 and parameters: {'n_estimators': 730, 'max_depth': 150, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:52:02,665]\u001b[0m Trial 81 finished with value: 0.8378117845523557 and parameters: {'n_estimators': 704, 'max_depth': 149, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:52:08,649]\u001b[0m Trial 82 finished with value: 0.8378117845523557 and parameters: {'n_estimators': 709, 'max_depth': 152, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:52:26,546]\u001b[0m Trial 84 finished with value: 0.8385347632244848 and parameters: {'n_estimators': 686, 'max_depth': 150, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:52:35,253]\u001b[0m Trial 85 finished with value: 0.8391372454512592 and parameters: {'n_estimators': 699, 'max_depth': 146, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:52:43,684]\u001b[0m Trial 83 finished with value: 0.8390167490059043 and parameters: {'n_estimators': 951, 'max_depth': 150, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:52:45,797]\u001b[0m Trial 86 finished with value: 0.8387757561151946 and parameters: {'n_estimators': 698, 'max_depth': 133, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:52:52,210]\u001b[0m Trial 87 finished with value: 0.8385347632244848 and parameters: {'n_estimators': 699, 'max_depth': 133, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:02,244]\u001b[0m Trial 92 finished with value: 0.83841426677913 and parameters: {'n_estimators': 594, 'max_depth': 121, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:02,646]\u001b[0m Trial 88 finished with value: 0.8385347632244848 and parameters: {'n_estimators': 725, 'max_depth': 147, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:03,389]\u001b[0m Trial 89 finished with value: 0.8393782383419689 and parameters: {'n_estimators': 699, 'max_depth': 200, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:04,199]\u001b[0m Trial 93 finished with value: 0.8378117845523557 and parameters: {'n_estimators': 580, 'max_depth': 131, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:08,156]\u001b[0m Trial 94 finished with value: 0.8376912881070009 and parameters: {'n_estimators': 592, 'max_depth': 123, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:13,800]\u001b[0m Trial 90 finished with value: 0.8390167490059043 and parameters: {'n_estimators': 854, 'max_depth': 200, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:16,607]\u001b[0m Trial 91 finished with value: 0.8386552596698398 and parameters: {'n_estimators': 856, 'max_depth': 129, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:19,942]\u001b[0m Trial 96 finished with value: 0.8385347632244848 and parameters: {'n_estimators': 570, 'max_depth': 136, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:22,936]\u001b[0m Trial 97 finished with value: 0.8381732738884203 and parameters: {'n_estimators': 567, 'max_depth': 128, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:24,234]\u001b[0m Trial 98 finished with value: 0.8379322809977106 and parameters: {'n_estimators': 603, 'max_depth': 176, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:24,780]\u001b[0m Trial 99 finished with value: 0.8393782383419689 and parameters: {'n_estimators': 581, 'max_depth': 178, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:24,952]\u001b[0m Trial 95 finished with value: 0.8392577418966141 and parameters: {'n_estimators': 851, 'max_depth': 133, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 54 with value: 0.8405832027955176.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_random_forest_return, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Real Return\n",
      "Melhor pontuação: 0.8405832027955176\n",
      "Melhores hiperparâmetros: {'n_estimators': 840, 'max_depth': 178, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'Random Forest', 'Real Return')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_random_forest_risk(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 200),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'n_jobs': N_JOBS\n",
    "    }\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_risk_train, y_risk_train)\n",
    "    preds = model.predict(X_risk_test)\n",
    "    accuracy = accuracy_score(y_risk_test, preds)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 14:53:25,214]\u001b[0m A new study created in memory with name: no-name-521767eb-a1f3-4560-b7ef-b26cd6e10aaa\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:49,292]\u001b[0m Trial 9 finished with value: 0.4986142908784191 and parameters: {'n_estimators': 175, 'max_depth': 65, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 9 with value: 0.4986142908784191.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:51,681]\u001b[0m Trial 11 finished with value: 0.4988552837691288 and parameters: {'n_estimators': 181, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.4988552837691288.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:53:58,202]\u001b[0m Trial 6 finished with value: 0.5000602482226775 and parameters: {'n_estimators': 285, 'max_depth': 114, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 6 with value: 0.5000602482226775.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:54:16,205]\u001b[0m Trial 1 finished with value: 0.49813230509699963 and parameters: {'n_estimators': 390, 'max_depth': 131, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 6 with value: 0.5000602482226775.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:54:18,501]\u001b[0m Trial 0 finished with value: 0.5013857091215809 and parameters: {'n_estimators': 446, 'max_depth': 83, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 0 with value: 0.5013857091215809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:54:20,845]\u001b[0m Trial 5 finished with value: 0.5010242197855164 and parameters: {'n_estimators': 469, 'max_depth': 91, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 0 with value: 0.5013857091215809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:54:30,450]\u001b[0m Trial 17 finished with value: 0.5016267020122906 and parameters: {'n_estimators': 87, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 17 with value: 0.5016267020122906.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:54:44,987]\u001b[0m Trial 7 finished with value: 0.501265212676226 and parameters: {'n_estimators': 754, 'max_depth': 155, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 17 with value: 0.5016267020122906.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:54:50,078]\u001b[0m Trial 8 finished with value: 0.4980118086516448 and parameters: {'n_estimators': 704, 'max_depth': 69, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 17 with value: 0.5016267020122906.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:54:51,806]\u001b[0m Trial 12 finished with value: 0.496927340643451 and parameters: {'n_estimators': 530, 'max_depth': 172, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 17 with value: 0.5016267020122906.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:54:53,936]\u001b[0m Trial 13 finished with value: 0.4999397517773226 and parameters: {'n_estimators': 525, 'max_depth': 152, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 17 with value: 0.5016267020122906.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:54:56,602]\u001b[0m Trial 21 finished with value: 0.48789010724183635 and parameters: {'n_estimators': 62, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 17 with value: 0.5016267020122906.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:54:56,836]\u001b[0m Trial 22 finished with value: 0.48668514278828773 and parameters: {'n_estimators': 36, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 17 with value: 0.5016267020122906.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:54:57,825]\u001b[0m Trial 10 finished with value: 0.49463790818170866 and parameters: {'n_estimators': 742, 'max_depth': 91, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 17 with value: 0.5016267020122906.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:55:01,378]\u001b[0m Trial 16 finished with value: 0.4949993975177732 and parameters: {'n_estimators': 364, 'max_depth': 99, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 17 with value: 0.5016267020122906.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:55:05,594]\u001b[0m Trial 3 finished with value: 0.49752982287022535 and parameters: {'n_estimators': 796, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 17 with value: 0.5016267020122906.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:55:05,896]\u001b[0m Trial 4 finished with value: 0.4970478370888059 and parameters: {'n_estimators': 798, 'max_depth': 23, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 17 with value: 0.5016267020122906.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:55:13,840]\u001b[0m Trial 14 finished with value: 0.5017471984576455 and parameters: {'n_estimators': 710, 'max_depth': 69, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 14 with value: 0.5017471984576455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:55:19,855]\u001b[0m Trial 2 finished with value: 0.496083865525967 and parameters: {'n_estimators': 899, 'max_depth': 42, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 14 with value: 0.5017471984576455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:55:20,645]\u001b[0m Trial 18 finished with value: 0.5003012411133871 and parameters: {'n_estimators': 437, 'max_depth': 110, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 14 with value: 0.5017471984576455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:55:33,095]\u001b[0m Trial 25 finished with value: 0.5005422340040969 and parameters: {'n_estimators': 334, 'max_depth': 47, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 14 with value: 0.5017471984576455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:55:53,729]\u001b[0m Trial 20 finished with value: 0.4959633690806121 and parameters: {'n_estimators': 568, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 14 with value: 0.5017471984576455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:56:04,526]\u001b[0m Trial 19 finished with value: 0.5011447162308712 and parameters: {'n_estimators': 933, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 14 with value: 0.5017471984576455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:56:17,867]\u001b[0m Trial 28 finished with value: 0.5006627304494518 and parameters: {'n_estimators': 644, 'max_depth': 54, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 14 with value: 0.5017471984576455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:56:21,543]\u001b[0m Trial 15 finished with value: 0.4982528015423545 and parameters: {'n_estimators': 986, 'max_depth': 37, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 14 with value: 0.5017471984576455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:56:28,599]\u001b[0m Trial 23 finished with value: 0.5011447162308712 and parameters: {'n_estimators': 855, 'max_depth': 43, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 14 with value: 0.5017471984576455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:56:29,031]\u001b[0m Trial 30 finished with value: 0.5013857091215809 and parameters: {'n_estimators': 631, 'max_depth': 60, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 14 with value: 0.5017471984576455.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:56:35,143]\u001b[0m Trial 24 finished with value: 0.5037956380286781 and parameters: {'n_estimators': 930, 'max_depth': 43, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 24 with value: 0.5037956380286781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:56:41,856]\u001b[0m Trial 32 finished with value: 0.5009037233401614 and parameters: {'n_estimators': 614, 'max_depth': 72, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 24 with value: 0.5037956380286781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:56:49,536]\u001b[0m Trial 26 finished with value: 0.5029521629111942 and parameters: {'n_estimators': 992, 'max_depth': 41, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 24 with value: 0.5037956380286781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:56:57,101]\u001b[0m Trial 38 finished with value: 0.49752982287022535 and parameters: {'n_estimators': 235, 'max_depth': 77, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 24 with value: 0.5037956380286781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:56:57,663]\u001b[0m Trial 27 finished with value: 0.5009037233401614 and parameters: {'n_estimators': 994, 'max_depth': 45, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 24 with value: 0.5037956380286781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:57:03,592]\u001b[0m Trial 29 finished with value: 0.501265212676226 and parameters: {'n_estimators': 986, 'max_depth': 41, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 24 with value: 0.5037956380286781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:57:04,432]\u001b[0m Trial 33 finished with value: 0.5052415953729364 and parameters: {'n_estimators': 622, 'max_depth': 70, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:57:09,358]\u001b[0m Trial 31 finished with value: 0.5010242197855164 and parameters: {'n_estimators': 983, 'max_depth': 57, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:57:14,977]\u001b[0m Trial 34 finished with value: 0.5019881913483553 and parameters: {'n_estimators': 647, 'max_depth': 67, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:57:26,736]\u001b[0m Trial 35 finished with value: 0.5035546451379684 and parameters: {'n_estimators': 623, 'max_depth': 73, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:57:31,917]\u001b[0m Trial 36 finished with value: 0.49969875888661286 and parameters: {'n_estimators': 635, 'max_depth': 73, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:57:39,391]\u001b[0m Trial 37 finished with value: 0.49969875888661286 and parameters: {'n_estimators': 649, 'max_depth': 78, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:57:41,819]\u001b[0m Trial 39 finished with value: 0.5000602482226775 and parameters: {'n_estimators': 627, 'max_depth': 76, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:58:26,157]\u001b[0m Trial 40 finished with value: 0.5007832268948066 and parameters: {'n_estimators': 984, 'max_depth': 79, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:58:32,129]\u001b[0m Trial 43 finished with value: 0.5024701771297747 and parameters: {'n_estimators': 865, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:58:36,850]\u001b[0m Trial 45 finished with value: 0.5046391131461622 and parameters: {'n_estimators': 855, 'max_depth': 83, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:58:38,380]\u001b[0m Trial 41 finished with value: 0.49957826244125797 and parameters: {'n_estimators': 996, 'max_depth': 78, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:58:41,647]\u001b[0m Trial 44 finished with value: 0.5033136522472587 and parameters: {'n_estimators': 870, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:58:46,783]\u001b[0m Trial 47 finished with value: 0.503072659356549 and parameters: {'n_estimators': 812, 'max_depth': 200, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:58:47,519]\u001b[0m Trial 42 finished with value: 0.5028316664658392 and parameters: {'n_estimators': 989, 'max_depth': 23, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:58:48,735]\u001b[0m Trial 46 finished with value: 0.5023496806844198 and parameters: {'n_estimators': 886, 'max_depth': 83, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:58:57,807]\u001b[0m Trial 48 finished with value: 0.5018676949030003 and parameters: {'n_estimators': 873, 'max_depth': 87, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:59:03,111]\u001b[0m Trial 49 finished with value: 0.5015062055669358 and parameters: {'n_estimators': 862, 'max_depth': 86, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:59:09,079]\u001b[0m Trial 50 finished with value: 0.4998192553319677 and parameters: {'n_estimators': 843, 'max_depth': 90, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:59:15,359]\u001b[0m Trial 51 finished with value: 0.5035546451379684 and parameters: {'n_estimators': 872, 'max_depth': 124, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 14:59:54,879]\u001b[0m Trial 52 finished with value: 0.5003012411133871 and parameters: {'n_estimators': 848, 'max_depth': 89, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:00:02,070]\u001b[0m Trial 55 finished with value: 0.5024701771297747 and parameters: {'n_estimators': 791, 'max_depth': 90, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:00:02,859]\u001b[0m Trial 53 finished with value: 0.5029521629111942 and parameters: {'n_estimators': 822, 'max_depth': 29, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:00:05,148]\u001b[0m Trial 54 finished with value: 0.5029521629111942 and parameters: {'n_estimators': 793, 'max_depth': 90, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:00:11,338]\u001b[0m Trial 57 finished with value: 0.500421737558742 and parameters: {'n_estimators': 797, 'max_depth': 109, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:00:13,750]\u001b[0m Trial 56 finished with value: 0.5019881913483553 and parameters: {'n_estimators': 827, 'max_depth': 89, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:00:14,586]\u001b[0m Trial 59 finished with value: 0.5025906735751295 and parameters: {'n_estimators': 819, 'max_depth': 92, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:00:19,386]\u001b[0m Trial 60 finished with value: 0.5046391131461622 and parameters: {'n_estimators': 769, 'max_depth': 99, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:00:23,187]\u001b[0m Trial 58 finished with value: 0.5007832268948066 and parameters: {'n_estimators': 924, 'max_depth': 123, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:00:26,754]\u001b[0m Trial 61 finished with value: 0.49933726955054825 and parameters: {'n_estimators': 792, 'max_depth': 98, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:00:34,234]\u001b[0m Trial 62 finished with value: 0.5009037233401614 and parameters: {'n_estimators': 806, 'max_depth': 187, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:00:53,758]\u001b[0m Trial 63 finished with value: 0.5009037233401614 and parameters: {'n_estimators': 939, 'max_depth': 124, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:01:20,377]\u001b[0m Trial 65 finished with value: 0.5036751415833233 and parameters: {'n_estimators': 748, 'max_depth': 126, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:01:25,380]\u001b[0m Trial 66 finished with value: 0.5031931558019038 and parameters: {'n_estimators': 763, 'max_depth': 120, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:01:32,548]\u001b[0m Trial 64 finished with value: 0.5037956380286781 and parameters: {'n_estimators': 922, 'max_depth': 124, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:01:40,134]\u001b[0m Trial 72 finished with value: 0.5040366309193879 and parameters: {'n_estimators': 723, 'max_depth': 141, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:01:43,046]\u001b[0m Trial 67 finished with value: 0.5022291842390649 and parameters: {'n_estimators': 940, 'max_depth': 128, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:01:48,518]\u001b[0m Trial 68 finished with value: 0.5013857091215809 and parameters: {'n_estimators': 941, 'max_depth': 117, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:01:51,261]\u001b[0m Trial 69 finished with value: 0.5028316664658392 and parameters: {'n_estimators': 924, 'max_depth': 137, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:01:56,093]\u001b[0m Trial 73 finished with value: 0.5010242197855164 and parameters: {'n_estimators': 738, 'max_depth': 142, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:01:57,229]\u001b[0m Trial 71 finished with value: 0.5024701771297747 and parameters: {'n_estimators': 926, 'max_depth': 126, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:02:02,861]\u001b[0m Trial 74 finished with value: 0.49849379443306424 and parameters: {'n_estimators': 725, 'max_depth': 141, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:02:03,783]\u001b[0m Trial 70 finished with value: 0.49945776599590314 and parameters: {'n_estimators': 924, 'max_depth': 125, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:02:20,936]\u001b[0m Trial 75 finished with value: 0.4970478370888059 and parameters: {'n_estimators': 738, 'max_depth': 105, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:02:36,183]\u001b[0m Trial 76 finished with value: 0.5003012411133871 and parameters: {'n_estimators': 725, 'max_depth': 140, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:02:45,251]\u001b[0m Trial 77 finished with value: 0.4992167731051934 and parameters: {'n_estimators': 697, 'max_depth': 154, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:02:48,465]\u001b[0m Trial 78 finished with value: 0.5017471984576455 and parameters: {'n_estimators': 711, 'max_depth': 149, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:02:55,805]\u001b[0m Trial 79 finished with value: 0.5027111700204844 and parameters: {'n_estimators': 703, 'max_depth': 144, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:02:55,949]\u001b[0m Trial 80 finished with value: 0.501265212676226 and parameters: {'n_estimators': 686, 'max_depth': 139, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:00,723]\u001b[0m Trial 81 finished with value: 0.5033136522472587 and parameters: {'n_estimators': 691, 'max_depth': 144, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:03,897]\u001b[0m Trial 82 finished with value: 0.5003012411133871 and parameters: {'n_estimators': 708, 'max_depth': 157, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:09,300]\u001b[0m Trial 83 finished with value: 0.4998192553319677 and parameters: {'n_estimators': 690, 'max_depth': 105, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:10,216]\u001b[0m Trial 84 finished with value: 0.5042776238100976 and parameters: {'n_estimators': 699, 'max_depth': 161, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:15,357]\u001b[0m Trial 85 finished with value: 0.4999397517773226 and parameters: {'n_estimators': 683, 'max_depth': 149, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:16,069]\u001b[0m Trial 86 finished with value: 0.501265212676226 and parameters: {'n_estimators': 686, 'max_depth': 161, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:34,410]\u001b[0m Trial 87 finished with value: 0.5009037233401614 and parameters: {'n_estimators': 687, 'max_depth': 154, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:49,742]\u001b[0m Trial 89 finished with value: 0.5028316664658392 and parameters: {'n_estimators': 591, 'max_depth': 148, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:51,020]\u001b[0m Trial 88 finished with value: 0.5031931558019038 and parameters: {'n_estimators': 696, 'max_depth': 52, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:53,104]\u001b[0m Trial 93 finished with value: 0.501265212676226 and parameters: {'n_estimators': 494, 'max_depth': 161, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:56,118]\u001b[0m Trial 92 finished with value: 0.5015062055669358 and parameters: {'n_estimators': 569, 'max_depth': 133, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:57,166]\u001b[0m Trial 91 finished with value: 0.5009037233401614 and parameters: {'n_estimators': 586, 'max_depth': 160, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:03:58,306]\u001b[0m Trial 90 finished with value: 0.5016267020122906 and parameters: {'n_estimators': 676, 'max_depth': 64, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:04:01,742]\u001b[0m Trial 94 finished with value: 0.5003012411133871 and parameters: {'n_estimators': 595, 'max_depth': 132, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:04:04,204]\u001b[0m Trial 95 finished with value: 0.5024701771297747 and parameters: {'n_estimators': 583, 'max_depth': 132, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:04:04,479]\u001b[0m Trial 96 finished with value: 0.5009037233401614 and parameters: {'n_estimators': 586, 'max_depth': 51, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:04:05,418]\u001b[0m Trial 97 finished with value: 0.5022291842390649 and parameters: {'n_estimators': 574, 'max_depth': 161, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:04:06,650]\u001b[0m Trial 98 finished with value: 0.4959633690806121 and parameters: {'n_estimators': 557, 'max_depth': 167, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:04:07,976]\u001b[0m Trial 99 finished with value: 0.5010242197855164 and parameters: {'n_estimators': 583, 'max_depth': 169, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 33 with value: 0.5052415953729364.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_random_forest_risk, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Risk\n",
      "Melhor pontuação: 0.5052415953729364\n",
      "Melhores hiperparâmetros: {'n_estimators': 622, 'max_depth': 70, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'Random Forest', 'Risk')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_svc_return(trial):\n",
    "    params = {\n",
    "        'kernel': trial.suggest_categorical('kernel', ['poly', 'rbf', 'sigmoid']),\n",
    "        'C':trial.suggest_float('C', 1, 100),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None])\n",
    "\t}\n",
    "    model = SVC(**params)\n",
    "    model.fit(X_real_return_train, y_real_return_train)\n",
    "    preds = model.predict(X_real_return_test)\n",
    "    accuracy = accuracy_score(y_real_return_test, preds)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 15:04:08,175]\u001b[0m A new study created in memory with name: no-name-3e33e691-c1a9-432f-a158-803810329a38\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:05:15,133]\u001b[0m Trial 1 finished with value: 0.38149174599349317 and parameters: {'kernel': 'sigmoid', 'C': 43.27231690712184, 'class_weight': None}. Best is trial 1 with value: 0.38149174599349317.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:05:15,918]\u001b[0m Trial 5 finished with value: 0.38161224243884806 and parameters: {'kernel': 'sigmoid', 'C': 69.7530951812302, 'class_weight': None}. Best is trial 5 with value: 0.38161224243884806.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:05:19,689]\u001b[0m Trial 11 finished with value: 0.38799855404265576 and parameters: {'kernel': 'sigmoid', 'C': 48.424966953003626, 'class_weight': 'balanced'}. Best is trial 11 with value: 0.38799855404265576.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:05:42,182]\u001b[0m Trial 9 finished with value: 0.6941800216893602 and parameters: {'kernel': 'rbf', 'C': 87.96849210269706, 'class_weight': None}. Best is trial 9 with value: 0.6941800216893602.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:05:43,130]\u001b[0m Trial 8 finished with value: 0.6939390287986504 and parameters: {'kernel': 'rbf', 'C': 82.18508756851594, 'class_weight': None}. Best is trial 9 with value: 0.6941800216893602.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:05:43,237]\u001b[0m Trial 10 finished with value: 0.6951439932521991 and parameters: {'kernel': 'rbf', 'C': 93.052395233287, 'class_weight': None}. Best is trial 10 with value: 0.6951439932521991.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:05:45,970]\u001b[0m Trial 2 finished with value: 0.6976744186046512 and parameters: {'kernel': 'rbf', 'C': 93.85799253427689, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.6976744186046512.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:05:48,812]\u001b[0m Trial 4 finished with value: 0.6923725750090373 and parameters: {'kernel': 'rbf', 'C': 20.45138746199331, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.6976744186046512.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:06:03,090]\u001b[0m Trial 6 finished with value: 0.44776479093866733 and parameters: {'kernel': 'poly', 'C': 4.658525841779188, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.6976744186046512.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:06:15,928]\u001b[0m Trial 12 finished with value: 0.38149174599349317 and parameters: {'kernel': 'sigmoid', 'C': 55.9203094663916, 'class_weight': None}. Best is trial 2 with value: 0.6976744186046512.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:06:18,827]\u001b[0m Trial 0 finished with value: 0.4582479816845403 and parameters: {'kernel': 'poly', 'C': 25.26325197200975, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.6976744186046512.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:06:24,354]\u001b[0m Trial 14 finished with value: 0.38799855404265576 and parameters: {'kernel': 'sigmoid', 'C': 47.30590808284811, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.6976744186046512.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:06:30,356]\u001b[0m Trial 7 finished with value: 0.38884202916013977 and parameters: {'kernel': 'poly', 'C': 38.63219417289379, 'class_weight': None}. Best is trial 2 with value: 0.6976744186046512.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:06:46,972]\u001b[0m Trial 13 finished with value: 0.6909266176647789 and parameters: {'kernel': 'rbf', 'C': 16.434903118976333, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.6976744186046512.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:07:08,313]\u001b[0m Trial 15 finished with value: 0.6939390287986504 and parameters: {'kernel': 'rbf', 'C': 80.92569006335361, 'class_weight': None}. Best is trial 2 with value: 0.6976744186046512.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:07:11,023]\u001b[0m Trial 18 finished with value: 0.68996264610194 and parameters: {'kernel': 'rbf', 'C': 50.913014176641084, 'class_weight': None}. Best is trial 2 with value: 0.6976744186046512.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:07:12,941]\u001b[0m Trial 3 finished with value: 0.3900469936136884 and parameters: {'kernel': 'poly', 'C': 88.21675798315387, 'class_weight': None}. Best is trial 2 with value: 0.6976744186046512.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:07:17,426]\u001b[0m Trial 19 finished with value: 0.6918905892276178 and parameters: {'kernel': 'rbf', 'C': 37.699356394897904, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.6976744186046512.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:07:41,529]\u001b[0m Trial 22 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 98.81845159132698, 'class_weight': 'balanced'}. Best is trial 22 with value: 0.6982769008314255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:07:48,807]\u001b[0m Trial 23 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 99.06823677066927, 'class_weight': 'balanced'}. Best is trial 22 with value: 0.6982769008314255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:07:55,295]\u001b[0m Trial 24 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 99.94849891435051, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:08:08,244]\u001b[0m Trial 16 finished with value: 0.46101939992770213 and parameters: {'kernel': 'poly', 'C': 67.34835258110225, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:08:10,031]\u001b[0m Trial 20 finished with value: 0.3849861429087842 and parameters: {'kernel': 'poly', 'C': 13.5800939422259, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:08:14,637]\u001b[0m Trial 25 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 98.70324190251102, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:08:36,420]\u001b[0m Trial 17 finished with value: 0.3900469936136884 and parameters: {'kernel': 'poly', 'C': 81.27575425286254, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:08:37,498]\u001b[0m Trial 26 finished with value: 0.6975539221592963 and parameters: {'kernel': 'rbf', 'C': 93.69760623337322, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:08:39,774]\u001b[0m Trial 27 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 97.09667268514087, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:08:44,020]\u001b[0m Trial 28 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 99.9233050746574, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:08:47,678]\u001b[0m Trial 29 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 98.11086971530246, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:08:58,310]\u001b[0m Trial 21 finished with value: 0.46234486082660564 and parameters: {'kernel': 'poly', 'C': 98.38939128677406, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:09:09,459]\u001b[0m Trial 30 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 98.45750788764678, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:09:17,708]\u001b[0m Trial 31 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 97.23275766527152, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:09:24,382]\u001b[0m Trial 32 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 99.29217425083274, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:09:37,409]\u001b[0m Trial 33 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 96.24412998983684, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:09:38,550]\u001b[0m Trial 34 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 99.14677657870061, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:09:42,840]\u001b[0m Trial 35 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 99.50215709321823, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:10:06,096]\u001b[0m Trial 36 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 98.38196326326961, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:10:07,562]\u001b[0m Trial 37 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 99.38451508487086, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:10:10,323]\u001b[0m Trial 38 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 99.37518472017346, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:10:13,809]\u001b[0m Trial 39 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 99.62557519111894, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:10:17,577]\u001b[0m Trial 40 finished with value: 0.696951439932522 and parameters: {'kernel': 'rbf', 'C': 73.21769614626248, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:10:26,342]\u001b[0m Trial 41 finished with value: 0.6974334257139414 and parameters: {'kernel': 'rbf', 'C': 87.55691551411886, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:10:35,243]\u001b[0m Trial 42 finished with value: 0.6971924328232317 and parameters: {'kernel': 'rbf', 'C': 86.61719946917496, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:10:44,717]\u001b[0m Trial 43 finished with value: 0.6975539221592963 and parameters: {'kernel': 'rbf', 'C': 87.7992097019638, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:10:51,721]\u001b[0m Trial 44 finished with value: 0.6975539221592963 and parameters: {'kernel': 'rbf', 'C': 87.57183712299043, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:11:05,796]\u001b[0m Trial 45 finished with value: 0.6976744186046512 and parameters: {'kernel': 'rbf', 'C': 89.54536184284876, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:11:06,407]\u001b[0m Trial 46 finished with value: 0.6974334257139414 and parameters: {'kernel': 'rbf', 'C': 88.40673416696546, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:11:11,217]\u001b[0m Trial 47 finished with value: 0.697794915050006 and parameters: {'kernel': 'rbf', 'C': 88.69814276412107, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:11:12,054]\u001b[0m Trial 49 finished with value: 0.38775756115194604 and parameters: {'kernel': 'sigmoid', 'C': 87.04463656070794, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:11:15,173]\u001b[0m Trial 50 finished with value: 0.38775756115194604 and parameters: {'kernel': 'sigmoid', 'C': 88.47969468729572, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:11:19,240]\u001b[0m Trial 51 finished with value: 0.38775756115194604 and parameters: {'kernel': 'sigmoid', 'C': 90.34525176698287, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:11:31,007]\u001b[0m Trial 53 finished with value: 0.38775756115194604 and parameters: {'kernel': 'sigmoid', 'C': 90.68092288633015, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:11:35,783]\u001b[0m Trial 48 finished with value: 0.697794915050006 and parameters: {'kernel': 'rbf', 'C': 89.2383750190282, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:11:40,070]\u001b[0m Trial 54 finished with value: 0.38775756115194604 and parameters: {'kernel': 'sigmoid', 'C': 93.47585294986379, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:11:47,130]\u001b[0m Trial 52 finished with value: 0.697794915050006 and parameters: {'kernel': 'rbf', 'C': 88.59432840510115, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:11:49,744]\u001b[0m Trial 55 finished with value: 0.38775756115194604 and parameters: {'kernel': 'sigmoid', 'C': 93.39529990354916, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:11:59,350]\u001b[0m Trial 56 finished with value: 0.38775756115194604 and parameters: {'kernel': 'sigmoid', 'C': 92.5415014651386, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:12:15,832]\u001b[0m Trial 57 finished with value: 0.38775756115194604 and parameters: {'kernel': 'sigmoid', 'C': 92.58500705070938, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:12:16,530]\u001b[0m Trial 58 finished with value: 0.38775756115194604 and parameters: {'kernel': 'sigmoid', 'C': 91.70598936842212, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:12:22,378]\u001b[0m Trial 59 finished with value: 0.38775756115194604 and parameters: {'kernel': 'sigmoid', 'C': 93.34249028636151, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:12:23,194]\u001b[0m Trial 60 finished with value: 0.38775756115194604 and parameters: {'kernel': 'sigmoid', 'C': 92.93351127561549, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:12:25,716]\u001b[0m Trial 61 finished with value: 0.38775756115194604 and parameters: {'kernel': 'sigmoid', 'C': 92.0192060366729, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:12:51,706]\u001b[0m Trial 62 finished with value: 0.6979154114953608 and parameters: {'kernel': 'rbf', 'C': 94.24295238977382, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:13:02,115]\u001b[0m Trial 63 finished with value: 0.6980359079407158 and parameters: {'kernel': 'rbf', 'C': 94.25888669706217, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:13:05,119]\u001b[0m Trial 64 finished with value: 0.6979154114953608 and parameters: {'kernel': 'rbf', 'C': 94.39513810820439, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:13:08,904]\u001b[0m Trial 65 finished with value: 0.6975539221592963 and parameters: {'kernel': 'rbf', 'C': 92.70784586781132, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:13:15,621]\u001b[0m Trial 66 finished with value: 0.6976744186046512 and parameters: {'kernel': 'rbf', 'C': 93.80120176881022, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:13:40,648]\u001b[0m Trial 72 finished with value: 0.6956259790336186 and parameters: {'kernel': 'rbf', 'C': 95.6883995253552, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:13:44,037]\u001b[0m Trial 73 finished with value: 0.6953849861429088 and parameters: {'kernel': 'rbf', 'C': 96.28212278610697, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:14:09,399]\u001b[0m Trial 74 finished with value: 0.6939390287986504 and parameters: {'kernel': 'rbf', 'C': 83.38896515967674, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:14:43,721]\u001b[0m Trial 67 finished with value: 0.38980600072297866 and parameters: {'kernel': 'poly', 'C': 94.72128616616185, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:14:59,141]\u001b[0m Trial 68 finished with value: 0.3900469936136884 and parameters: {'kernel': 'poly', 'C': 83.21765004183001, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:15:10,910]\u001b[0m Trial 71 finished with value: 0.3900469936136884 and parameters: {'kernel': 'poly', 'C': 83.1783500909039, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:15:19,648]\u001b[0m Trial 70 finished with value: 0.38992649716833355 and parameters: {'kernel': 'poly', 'C': 83.56228109060943, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:15:35,543]\u001b[0m Trial 69 finished with value: 0.38980600072297866 and parameters: {'kernel': 'poly', 'C': 95.42959724948241, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:15:57,361]\u001b[0m Trial 76 finished with value: 0.38992649716833355 and parameters: {'kernel': 'poly', 'C': 83.63842556479992, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:15:59,617]\u001b[0m Trial 78 finished with value: 0.3900469936136884 and parameters: {'kernel': 'poly', 'C': 82.97652946170045, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:16:02,426]\u001b[0m Trial 75 finished with value: 0.38980600072297866 and parameters: {'kernel': 'poly', 'C': 96.09295711395761, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:16:12,290]\u001b[0m Trial 77 finished with value: 0.38980600072297866 and parameters: {'kernel': 'poly', 'C': 96.01677238589728, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:16:13,733]\u001b[0m Trial 82 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 95.98070553538017, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:16:27,483]\u001b[0m Trial 83 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 96.95623172880175, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:16:39,036]\u001b[0m Trial 84 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 96.38601322590026, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:16:41,720]\u001b[0m Trial 80 finished with value: 0.3900469936136884 and parameters: {'kernel': 'poly', 'C': 82.61575687863481, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:16:42,812]\u001b[0m Trial 79 finished with value: 0.38992649716833355 and parameters: {'kernel': 'poly', 'C': 83.59892817629871, 'class_weight': None}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:16:45,559]\u001b[0m Trial 81 finished with value: 0.4621038679358959 and parameters: {'kernel': 'poly', 'C': 96.74385233052388, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:16:46,959]\u001b[0m Trial 85 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 96.71237249386422, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:17:02,125]\u001b[0m Trial 86 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 99.99314331093403, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:17:24,447]\u001b[0m Trial 87 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 99.66267386497081, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:17:29,356]\u001b[0m Trial 88 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 99.9566582553118, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:17:30,930]\u001b[0m Trial 89 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 99.97551253523847, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:17:39,559]\u001b[0m Trial 90 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 99.57495210573673, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:17:41,835]\u001b[0m Trial 91 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 99.74882371289017, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:17:49,954]\u001b[0m Trial 92 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 98.074206055659, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:17:58,126]\u001b[0m Trial 93 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 99.95952950996411, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:18:00,370]\u001b[0m Trial 94 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 98.96295690642475, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:18:00,618]\u001b[0m Trial 95 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 99.57240644120019, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:18:02,636]\u001b[0m Trial 96 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 99.97682155283256, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:18:02,844]\u001b[0m Trial 97 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 97.7280325865062, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:18:07,100]\u001b[0m Trial 98 finished with value: 0.6982769008314255 and parameters: {'kernel': 'rbf', 'C': 97.41702282473612, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:18:13,192]\u001b[0m Trial 99 finished with value: 0.6983973972767803 and parameters: {'kernel': 'rbf', 'C': 96.85540781871275, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.6983973972767803.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_svc_return, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Real Return\n",
      "Melhor pontuação: 0.6983973972767803\n",
      "Melhores hiperparâmetros: {'kernel': 'rbf', 'C': 99.94849891435051, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'SVM', 'Real Return')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_svc_risk(trial):\n",
    "    params = {\n",
    "        'kernel': trial.suggest_categorical('kernel', ['poly', 'rbf', 'sigmoid']),\n",
    "        'C':trial.suggest_float('C', 1, 100),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None])\n",
    "\t}\n",
    "    model = SVC(**params)\n",
    "    model.fit(X_risk_train, y_risk_train)\n",
    "    preds = model.predict(X_risk_test)\n",
    "    accuracy = accuracy_score(y_risk_test, preds)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 15:18:13,342]\u001b[0m A new study created in memory with name: no-name-6ae1c79e-3e63-4aec-b275-42276bafa628\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:19:16,390]\u001b[0m Trial 10 finished with value: 0.320520544643933 and parameters: {'kernel': 'sigmoid', 'C': 83.7901007847199, 'class_weight': None}. Best is trial 10 with value: 0.320520544643933.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:19:17,214]\u001b[0m Trial 0 finished with value: 0.320520544643933 and parameters: {'kernel': 'sigmoid', 'C': 27.022476186365395, 'class_weight': None}. Best is trial 10 with value: 0.320520544643933.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:19:21,357]\u001b[0m Trial 5 finished with value: 0.31811061573683574 and parameters: {'kernel': 'sigmoid', 'C': 47.869830531643885, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.320520544643933.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:19:21,404]\u001b[0m Trial 1 finished with value: 0.31811061573683574 and parameters: {'kernel': 'sigmoid', 'C': 62.25071138792972, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.320520544643933.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:19:21,753]\u001b[0m Trial 2 finished with value: 0.31847210507290036 and parameters: {'kernel': 'sigmoid', 'C': 15.760486629695423, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.320520544643933.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:20:05,531]\u001b[0m Trial 11 finished with value: 0.37522593083504036 and parameters: {'kernel': 'rbf', 'C': 64.76312766993772, 'class_weight': None}. Best is trial 11 with value: 0.37522593083504036.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:20:08,005]\u001b[0m Trial 6 finished with value: 0.369442101458007 and parameters: {'kernel': 'rbf', 'C': 47.16119364608525, 'class_weight': None}. Best is trial 11 with value: 0.37522593083504036.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:20:08,595]\u001b[0m Trial 4 finished with value: 0.3757079166164598 and parameters: {'kernel': 'rbf', 'C': 69.07184414487237, 'class_weight': None}. Best is trial 4 with value: 0.3757079166164598.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:20:09,305]\u001b[0m Trial 9 finished with value: 0.37631039884323414 and parameters: {'kernel': 'rbf', 'C': 75.75177290597816, 'class_weight': None}. Best is trial 9 with value: 0.37631039884323414.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:20:11,200]\u001b[0m Trial 14 finished with value: 0.320520544643933 and parameters: {'kernel': 'sigmoid', 'C': 85.7758563037843, 'class_weight': None}. Best is trial 9 with value: 0.37631039884323414.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:20:55,360]\u001b[0m Trial 19 finished with value: 0.320520544643933 and parameters: {'kernel': 'sigmoid', 'C': 86.08038026841504, 'class_weight': None}. Best is trial 9 with value: 0.37631039884323414.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:21:04,942]\u001b[0m Trial 16 finished with value: 0.3672731654416195 and parameters: {'kernel': 'rbf', 'C': 44.19668233895849, 'class_weight': None}. Best is trial 9 with value: 0.37631039884323414.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:21:06,041]\u001b[0m Trial 15 finished with value: 0.37847933485962165 and parameters: {'kernel': 'rbf', 'C': 91.3442619786614, 'class_weight': None}. Best is trial 15 with value: 0.37847933485962165.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:21:08,780]\u001b[0m Trial 12 finished with value: 0.39305940474755996 and parameters: {'kernel': 'rbf', 'C': 73.10161572512753, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.39305940474755996.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:22:23,161]\u001b[0m Trial 22 finished with value: 0.3757079166164598 and parameters: {'kernel': 'rbf', 'C': 68.28191581390448, 'class_weight': None}. Best is trial 12 with value: 0.39305940474755996.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:43:43,326]\u001b[0m Trial 20 finished with value: 0.3424508976985179 and parameters: {'kernel': 'poly', 'C': 53.05935576592666, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.39305940474755996.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:43:59,610]\u001b[0m Trial 13 finished with value: 0.34317387637064706 and parameters: {'kernel': 'poly', 'C': 57.81915212890683, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.39305940474755996.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:45:29,137]\u001b[0m Trial 28 finished with value: 0.39281841185685024 and parameters: {'kernel': 'rbf', 'C': 93.9275210334462, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.39305940474755996.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:46:59,014]\u001b[0m Trial 29 finished with value: 0.394746354982528 and parameters: {'kernel': 'rbf', 'C': 98.24003958500796, 'class_weight': 'balanced'}. Best is trial 29 with value: 0.394746354982528.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:48:55,218]\u001b[0m Trial 8 finished with value: 0.34534281238703457 and parameters: {'kernel': 'poly', 'C': 72.83184504857833, 'class_weight': 'balanced'}. Best is trial 29 with value: 0.394746354982528.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:49:52,068]\u001b[0m Trial 21 finished with value: 0.3469092661766478 and parameters: {'kernel': 'poly', 'C': 99.35583802195931, 'class_weight': 'balanced'}. Best is trial 29 with value: 0.394746354982528.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:50:22,100]\u001b[0m Trial 31 finished with value: 0.39558983010001203 and parameters: {'kernel': 'rbf', 'C': 99.89489576327396, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:50:52,639]\u001b[0m Trial 25 finished with value: 0.34449933726955057 and parameters: {'kernel': 'poly', 'C': 97.24234696440145, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:51:18,894]\u001b[0m Trial 32 finished with value: 0.394746354982528 and parameters: {'kernel': 'rbf', 'C': 99.04265504645065, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:51:52,029]\u001b[0m Trial 33 finished with value: 0.3945053620918183 and parameters: {'kernel': 'rbf', 'C': 98.76514740516532, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:52:22,635]\u001b[0m Trial 34 finished with value: 0.3953488372093023 and parameters: {'kernel': 'rbf', 'C': 99.80019888601215, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:52:49,514]\u001b[0m Trial 35 finished with value: 0.3942643692011086 and parameters: {'kernel': 'rbf', 'C': 80.76399993716127, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:53:20,511]\u001b[0m Trial 36 finished with value: 0.3942643692011086 and parameters: {'kernel': 'rbf', 'C': 80.56544455745012, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:53:52,483]\u001b[0m Trial 37 finished with value: 0.3935413905289794 and parameters: {'kernel': 'rbf', 'C': 79.1937305948947, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:54:20,193]\u001b[0m Trial 38 finished with value: 0.39269791541149535 and parameters: {'kernel': 'rbf', 'C': 90.96902777080177, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:54:51,464]\u001b[0m Trial 39 finished with value: 0.39281841185685024 and parameters: {'kernel': 'rbf', 'C': 92.1830141118007, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:55:23,299]\u001b[0m Trial 40 finished with value: 0.39269791541149535 and parameters: {'kernel': 'rbf', 'C': 89.92257225636604, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:55:52,427]\u001b[0m Trial 41 finished with value: 0.3925774189661405 and parameters: {'kernel': 'rbf', 'C': 90.96314366452752, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:56:28,075]\u001b[0m Trial 42 finished with value: 0.3951078443185926 and parameters: {'kernel': 'rbf', 'C': 99.96694023739556, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:57:04,097]\u001b[0m Trial 43 finished with value: 0.39558983010001203 and parameters: {'kernel': 'rbf', 'C': 99.83331923617482, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:57:34,841]\u001b[0m Trial 44 finished with value: 0.39486685142788286 and parameters: {'kernel': 'rbf', 'C': 98.24526269233583, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:58:03,988]\u001b[0m Trial 45 finished with value: 0.3933003976382697 and parameters: {'kernel': 'rbf', 'C': 86.41633974165325, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:58:31,546]\u001b[0m Trial 7 finished with value: 0.3110013254608989 and parameters: {'kernel': 'poly', 'C': 12.834434047155687, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:58:34,571]\u001b[0m Trial 46 finished with value: 0.39305940474755996 and parameters: {'kernel': 'rbf', 'C': 86.58426801680228, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:58:43,401]\u001b[0m Trial 26 finished with value: 0.34522231594167974 and parameters: {'kernel': 'poly', 'C': 99.59825130665503, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:58:46,038]\u001b[0m Trial 48 finished with value: 0.3179901192914809 and parameters: {'kernel': 'sigmoid', 'C': 94.04342934700895, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:59:09,391]\u001b[0m Trial 47 finished with value: 0.39281841185685024 and parameters: {'kernel': 'rbf', 'C': 86.65212368277344, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:59:22,948]\u001b[0m Trial 49 finished with value: 0.3179901192914809 and parameters: {'kernel': 'sigmoid', 'C': 94.02857529789117, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:59:25,899]\u001b[0m Trial 50 finished with value: 0.3179901192914809 and parameters: {'kernel': 'sigmoid', 'C': 93.61253583009768, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 15:59:34,353]\u001b[0m Trial 51 finished with value: 0.3179901192914809 and parameters: {'kernel': 'sigmoid', 'C': 93.95699559215953, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:00:35,272]\u001b[0m Trial 52 finished with value: 0.39293890830220507 and parameters: {'kernel': 'rbf', 'C': 93.84028064712159, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:00:56,438]\u001b[0m Trial 53 finished with value: 0.39305940474755996 and parameters: {'kernel': 'rbf', 'C': 94.8993415328487, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:01:09,445]\u001b[0m Trial 54 finished with value: 0.39366188697433424 and parameters: {'kernel': 'rbf', 'C': 95.807602936689, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:01:11,607]\u001b[0m Trial 55 finished with value: 0.3942643692011086 and parameters: {'kernel': 'rbf', 'C': 80.77893751607618, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:01:19,779]\u001b[0m Trial 56 finished with value: 0.3934208940836245 and parameters: {'kernel': 'rbf', 'C': 76.806144128003, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:02:17,377]\u001b[0m Trial 57 finished with value: 0.3934208940836245 and parameters: {'kernel': 'rbf', 'C': 76.70039943808187, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:02:40,624]\u001b[0m Trial 58 finished with value: 0.3933003976382697 and parameters: {'kernel': 'rbf', 'C': 75.29359519233711, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:02:53,262]\u001b[0m Trial 59 finished with value: 0.39402337631039885 and parameters: {'kernel': 'rbf', 'C': 81.76683588680802, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:02:56,817]\u001b[0m Trial 60 finished with value: 0.39522834076394747 and parameters: {'kernel': 'rbf', 'C': 99.70008031743313, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:03:05,500]\u001b[0m Trial 61 finished with value: 0.39402337631039885 and parameters: {'kernel': 'rbf', 'C': 83.91504060484537, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:03:59,101]\u001b[0m Trial 62 finished with value: 0.39522834076394747 and parameters: {'kernel': 'rbf', 'C': 99.9234517403862, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:04:26,697]\u001b[0m Trial 63 finished with value: 0.3953488372093023 and parameters: {'kernel': 'rbf', 'C': 99.25870053935898, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:04:35,692]\u001b[0m Trial 64 finished with value: 0.394746354982528 and parameters: {'kernel': 'rbf', 'C': 99.00423041168597, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:04:40,369]\u001b[0m Trial 65 finished with value: 0.39293890830220507 and parameters: {'kernel': 'rbf', 'C': 89.75501342696491, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:04:43,027]\u001b[0m Trial 66 finished with value: 0.37847933485962165 and parameters: {'kernel': 'rbf', 'C': 88.61180919210301, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:05:31,152]\u001b[0m Trial 67 finished with value: 0.37811784552355704 and parameters: {'kernel': 'rbf', 'C': 89.61657058219947, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:20:46,847]\u001b[0m Trial 18 finished with value: 0.31317026147728644 and parameters: {'kernel': 'poly', 'C': 66.50218787777868, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:20:48,105]\u001b[0m Trial 27 finished with value: 0.3446198337149054 and parameters: {'kernel': 'poly', 'C': 99.57807970849812, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:23:30,033]\u001b[0m Trial 73 finished with value: 0.39522834076394747 and parameters: {'kernel': 'rbf', 'C': 99.71704750888674, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:23:34,970]\u001b[0m Trial 74 finished with value: 0.39390287986504396 and parameters: {'kernel': 'rbf', 'C': 96.07450001029436, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:26:16,848]\u001b[0m Trial 75 finished with value: 0.3931799011929148 and parameters: {'kernel': 'rbf', 'C': 95.05480715965076, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:26:28,479]\u001b[0m Trial 76 finished with value: 0.39402337631039885 and parameters: {'kernel': 'rbf', 'C': 96.32527568503697, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:29:15,884]\u001b[0m Trial 77 finished with value: 0.3941438727557537 and parameters: {'kernel': 'rbf', 'C': 96.97932542679223, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:34:28,852]\u001b[0m Trial 17 finished with value: 0.3119652970237378 and parameters: {'kernel': 'poly', 'C': 37.53992274758263, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:37:22,476]\u001b[0m Trial 80 finished with value: 0.39281841185685024 and parameters: {'kernel': 'rbf', 'C': 91.56399222640295, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:40:33,413]\u001b[0m Trial 30 finished with value: 0.34534281238703457 and parameters: {'kernel': 'poly', 'C': 99.99406214855827, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:43:29,623]\u001b[0m Trial 82 finished with value: 0.39402337631039885 and parameters: {'kernel': 'rbf', 'C': 96.5034210919184, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:46:37,426]\u001b[0m Trial 83 finished with value: 0.39281841185685024 and parameters: {'kernel': 'rbf', 'C': 88.39128626964373, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:49:38,609]\u001b[0m Trial 84 finished with value: 0.3954693336546572 and parameters: {'kernel': 'rbf', 'C': 99.71225992825161, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:52:53,623]\u001b[0m Trial 85 finished with value: 0.39281841185685024 and parameters: {'kernel': 'rbf', 'C': 92.47775469226322, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:55:40,082]\u001b[0m Trial 86 finished with value: 0.3953488372093023 and parameters: {'kernel': 'rbf', 'C': 99.59881471215284, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:56:56,064]\u001b[0m Trial 72 finished with value: 0.3467887697312929 and parameters: {'kernel': 'poly', 'C': 97.0013161631273, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:57:43,402]\u001b[0m Trial 87 finished with value: 0.39402337631039885 and parameters: {'kernel': 'rbf', 'C': 96.5025294897463, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:59:00,528]\u001b[0m Trial 88 finished with value: 0.39281841185685024 and parameters: {'kernel': 'rbf', 'C': 91.92376628489369, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 16:59:48,138]\u001b[0m Trial 89 finished with value: 0.3941438727557537 and parameters: {'kernel': 'rbf', 'C': 83.45950976627844, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:00:56,150]\u001b[0m Trial 90 finished with value: 0.3787203277503314 and parameters: {'kernel': 'rbf', 'C': 88.01790678324583, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:01:44,444]\u001b[0m Trial 91 finished with value: 0.3828172068923967 and parameters: {'kernel': 'rbf', 'C': 99.90445136894012, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:01:45,491]\u001b[0m Trial 23 finished with value: 0.31437522593083506 and parameters: {'kernel': 'poly', 'C': 98.22942207463277, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:03:00,426]\u001b[0m Trial 92 finished with value: 0.3953488372093023 and parameters: {'kernel': 'rbf', 'C': 99.5839559582715, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:03:52,160]\u001b[0m Trial 94 finished with value: 0.39281841185685024 and parameters: {'kernel': 'rbf', 'C': 92.31350808922625, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:03:53,127]\u001b[0m Trial 93 finished with value: 0.3953488372093023 and parameters: {'kernel': 'rbf', 'C': 99.71251830186523, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:05:07,840]\u001b[0m Trial 95 finished with value: 0.39293890830220507 and parameters: {'kernel': 'rbf', 'C': 92.10563268985683, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:05:54,039]\u001b[0m Trial 96 finished with value: 0.39402337631039885 and parameters: {'kernel': 'rbf', 'C': 96.51849651535493, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:05:55,803]\u001b[0m Trial 98 finished with value: 0.3179901192914809 and parameters: {'kernel': 'sigmoid', 'C': 97.00790181315644, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:05:56,103]\u001b[0m Trial 97 finished with value: 0.39390287986504396 and parameters: {'kernel': 'rbf', 'C': 96.8553598413598, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:06:35,341]\u001b[0m Trial 99 finished with value: 0.3179901192914809 and parameters: {'kernel': 'sigmoid', 'C': 97.409124696835, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:15:05,711]\u001b[0m Trial 78 finished with value: 0.3448608266056151 and parameters: {'kernel': 'poly', 'C': 88.26476845026178, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:16:08,423]\u001b[0m Trial 24 finished with value: 0.31220628991444754 and parameters: {'kernel': 'poly', 'C': 99.00462490808277, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:21:01,697]\u001b[0m Trial 81 finished with value: 0.3448608266056151 and parameters: {'kernel': 'poly', 'C': 88.08624407436945, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:29:48,746]\u001b[0m Trial 3 finished with value: 0.31304976503193155 and parameters: {'kernel': 'poly', 'C': 63.07017074536829, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:30:09,695]\u001b[0m Trial 79 finished with value: 0.3447403301602603 and parameters: {'kernel': 'poly', 'C': 99.96402539611029, 'class_weight': 'balanced'}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:52:21,662]\u001b[0m Trial 68 finished with value: 0.31220628991444754 and parameters: {'kernel': 'poly', 'C': 89.07237537797947, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 17:56:15,377]\u001b[0m Trial 71 finished with value: 0.31208579346909265 and parameters: {'kernel': 'poly', 'C': 95.87106798370236, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:01:10,669]\u001b[0m Trial 70 finished with value: 0.31401373659477044 and parameters: {'kernel': 'poly', 'C': 87.01720048017665, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:46,909]\u001b[0m Trial 69 finished with value: 0.313531750813351 and parameters: {'kernel': 'poly', 'C': 89.27929865994452, 'class_weight': None}. Best is trial 31 with value: 0.39558983010001203.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_svc_risk, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Risk\n",
      "Melhor pontuação: 0.39558983010001203\n",
      "Melhores hiperparâmetros: {'kernel': 'rbf', 'C': 99.89489576327396, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'SVM', 'Risk')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_decision_tree_return(trial):\n",
    "    params = {\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss']),\n",
    "        'splitter': trial.suggest_categorical('splitter', ['best', 'random']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 200),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 2000),\n",
    "\t}\n",
    "    model = DecisionTreeClassifier(**params)\n",
    "    model.fit(X_real_return_train, y_real_return_train)\n",
    "    preds = model.predict(X_real_return_test)\n",
    "    accuracy = accuracy_score(y_real_return_test, preds)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 18:03:47,102]\u001b[0m A new study created in memory with name: no-name-42b6efd6-17b7-4002-8897-d8d16720259d\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,210]\u001b[0m Trial 8 finished with value: 0.7043017230991686 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 67, 'min_samples_split': 1629}. Best is trial 8 with value: 0.7043017230991686.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,218]\u001b[0m Trial 1 finished with value: 0.6642969032413544 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 170, 'min_samples_split': 1865}. Best is trial 8 with value: 0.7043017230991686.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,230]\u001b[0m Trial 0 finished with value: 0.7409326424870466 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 105, 'min_samples_split': 739}. Best is trial 0 with value: 0.7409326424870466.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,237]\u001b[0m Trial 5 finished with value: 0.6629714423424509 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 59, 'min_samples_split': 1537}. Best is trial 0 with value: 0.7409326424870466.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,253]\u001b[0m Trial 11 finished with value: 0.6936980359079408 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 71, 'min_samples_split': 1312}. Best is trial 0 with value: 0.7409326424870466.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,255]\u001b[0m Trial 2 finished with value: 0.78166044101699 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 15, 'min_samples_split': 199}. Best is trial 2 with value: 0.78166044101699.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,277]\u001b[0m Trial 4 finished with value: 0.7958790215688637 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 115, 'min_samples_split': 59}. Best is trial 4 with value: 0.7958790215688637.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,292]\u001b[0m Trial 13 finished with value: 0.6800819375828413 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 159, 'min_samples_split': 1446}. Best is trial 4 with value: 0.7958790215688637.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,310]\u001b[0m Trial 14 finished with value: 0.6938185323532956 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 98, 'min_samples_split': 899}. Best is trial 4 with value: 0.7958790215688637.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,312]\u001b[0m Trial 12 finished with value: 0.7747921436317629 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 40, 'min_samples_split': 350}. Best is trial 4 with value: 0.7958790215688637.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,315]\u001b[0m Trial 16 finished with value: 0.6755030726593565 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 154, 'min_samples_split': 1004}. Best is trial 4 with value: 0.7958790215688637.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,317]\u001b[0m Trial 15 finished with value: 0.6101939992770213 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 164, 'min_samples_split': 1961}. Best is trial 4 with value: 0.7958790215688637.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,319]\u001b[0m Trial 17 finished with value: 0.78166044101699 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 178, 'min_samples_split': 1103}. Best is trial 4 with value: 0.7958790215688637.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,405]\u001b[0m Trial 18 finished with value: 0.670803711290517 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 28, 'min_samples_split': 1920}. Best is trial 4 with value: 0.7958790215688637.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,594]\u001b[0m Trial 10 finished with value: 0.8341968911917098 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 30, 'min_samples_split': 1559}. Best is trial 10 with value: 0.8341968911917098.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,631]\u001b[0m Trial 3 finished with value: 0.8341968911917098 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 133, 'min_samples_split': 1282}. Best is trial 10 with value: 0.8341968911917098.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,665]\u001b[0m Trial 9 finished with value: 0.8350403663091939 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 1097}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,690]\u001b[0m Trial 7 finished with value: 0.8341968911917098 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 105, 'min_samples_split': 1236}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,759]\u001b[0m Trial 6 finished with value: 0.8245571755633209 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 177, 'min_samples_split': 416}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,820]\u001b[0m Trial 24 finished with value: 0.8328714302928064 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 40}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,853]\u001b[0m Trial 21 finished with value: 0.8326304374020966 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 17}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,886]\u001b[0m Trial 23 finished with value: 0.8346788769731293 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 111}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:47,923]\u001b[0m Trial 25 finished with value: 0.8328714302928064 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 60}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,044]\u001b[0m Trial 20 finished with value: 0.8141944812628027 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 20}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,164]\u001b[0m Trial 19 finished with value: 0.8179298710688034 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 141, 'min_samples_split': 110}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,226]\u001b[0m Trial 26 finished with value: 0.834076394746355 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 123, 'min_samples_split': 532}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,258]\u001b[0m Trial 28 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 199, 'min_samples_split': 655}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,264]\u001b[0m Trial 27 finished with value: 0.8347993734184842 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 132, 'min_samples_split': 570}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,356]\u001b[0m Trial 29 finished with value: 0.8347993734184842 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 198, 'min_samples_split': 578}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,391]\u001b[0m Trial 32 finished with value: 0.8341968911917098 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 128, 'min_samples_split': 1238}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,396]\u001b[0m Trial 22 finished with value: 0.806121219424027 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 122, 'min_samples_split': 67}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,400]\u001b[0m Trial 30 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 199, 'min_samples_split': 724}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,406]\u001b[0m Trial 31 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 136, 'min_samples_split': 704}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,536]\u001b[0m Trial 33 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 134, 'min_samples_split': 694}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,550]\u001b[0m Trial 34 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 135, 'min_samples_split': 664}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,694]\u001b[0m Trial 35 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 131, 'min_samples_split': 741}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,798]\u001b[0m Trial 36 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 127, 'min_samples_split': 690}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,838]\u001b[0m Trial 37 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 86, 'min_samples_split': 726}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,877]\u001b[0m Trial 39 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 84, 'min_samples_split': 806}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,894]\u001b[0m Trial 38 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 80, 'min_samples_split': 795}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,943]\u001b[0m Trial 40 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 199, 'min_samples_split': 764}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:48,978]\u001b[0m Trial 42 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 47, 'min_samples_split': 882}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,153]\u001b[0m Trial 41 finished with value: 0.8293770333775153 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 91, 'min_samples_split': 274}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,196]\u001b[0m Trial 43 finished with value: 0.8292565369321605 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 45, 'min_samples_split': 288}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,237]\u001b[0m Trial 44 finished with value: 0.8292565369321605 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 45, 'min_samples_split': 274}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,272]\u001b[0m Trial 45 finished with value: 0.8293770333775153 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 91, 'min_samples_split': 299}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,316]\u001b[0m Trial 46 finished with value: 0.8292565369321605 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 52, 'min_samples_split': 292}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,453]\u001b[0m Trial 47 finished with value: 0.8293770333775153 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 89, 'min_samples_split': 275}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,565]\u001b[0m Trial 48 finished with value: 0.8288950475960959 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 90, 'min_samples_split': 255}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,606]\u001b[0m Trial 49 finished with value: 0.8287745511507411 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 44, 'min_samples_split': 245}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,656]\u001b[0m Trial 50 finished with value: 0.8293770333775153 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 49, 'min_samples_split': 272}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,661]\u001b[0m Trial 51 finished with value: 0.8287745511507411 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 47, 'min_samples_split': 316}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,707]\u001b[0m Trial 52 finished with value: 0.8282925653693216 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 188, 'min_samples_split': 361}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,763]\u001b[0m Trial 53 finished with value: 0.8293770333775153 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 184, 'min_samples_split': 287}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,798]\u001b[0m Trial 54 finished with value: 0.830581997831064 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 184, 'min_samples_split': 486}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,826]\u001b[0m Trial 55 finished with value: 0.8339558983010001 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 184, 'min_samples_split': 526}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,863]\u001b[0m Trial 56 finished with value: 0.834076394746355 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 185, 'min_samples_split': 522}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,867]\u001b[0m Trial 57 finished with value: 0.834076394746355 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 187, 'min_samples_split': 531}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:49,990]\u001b[0m Trial 58 finished with value: 0.8339558983010001 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 180, 'min_samples_split': 505}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,014]\u001b[0m Trial 67 finished with value: 0.6697192432823231 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 19, 'min_samples_split': 1087}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,061]\u001b[0m Trial 59 finished with value: 0.8254006506808049 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 186, 'min_samples_split': 443}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,064]\u001b[0m Trial 69 finished with value: 0.6722496686347753 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 29, 'min_samples_split': 1007}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,108]\u001b[0m Trial 68 finished with value: 0.6932160501265213 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 200, 'min_samples_split': 1078}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,114]\u001b[0m Trial 61 finished with value: 0.8281720689239668 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 191, 'min_samples_split': 522}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,163]\u001b[0m Trial 71 finished with value: 0.7727437040607302 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 199, 'min_samples_split': 159}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,168]\u001b[0m Trial 70 finished with value: 0.7508133510061453 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 199, 'min_samples_split': 622}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,174]\u001b[0m Trial 60 finished with value: 0.8252801542354501 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 184, 'min_samples_split': 500}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,221]\u001b[0m Trial 62 finished with value: 0.8251596577900951 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 193, 'min_samples_split': 483}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,311]\u001b[0m Trial 63 finished with value: 0.8281720689239668 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 198, 'min_samples_split': 520}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,316]\u001b[0m Trial 66 finished with value: 0.8316664658392577 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 200, 'min_samples_split': 1096}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,319]\u001b[0m Trial 64 finished with value: 0.8282925653693216 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 199, 'min_samples_split': 552}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,326]\u001b[0m Trial 65 finished with value: 0.8281720689239668 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 200, 'min_samples_split': 567}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,550]\u001b[0m Trial 73 finished with value: 0.8347993734184842 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 169, 'min_samples_split': 604}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,693]\u001b[0m Trial 74 finished with value: 0.8345583805277744 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 172, 'min_samples_split': 644}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,761]\u001b[0m Trial 76 finished with value: 0.8345583805277744 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 171, 'min_samples_split': 911}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,809]\u001b[0m Trial 72 finished with value: 0.8347993734184842 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 149, 'min_samples_split': 609}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,918]\u001b[0m Trial 77 finished with value: 0.8347993734184842 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 167, 'min_samples_split': 623}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:50,948]\u001b[0m Trial 75 finished with value: 0.8347993734184842 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 171, 'min_samples_split': 605}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,023]\u001b[0m Trial 81 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 147, 'min_samples_split': 866}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,024]\u001b[0m Trial 78 finished with value: 0.8347993734184842 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 172, 'min_samples_split': 602}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,026]\u001b[0m Trial 79 finished with value: 0.8345583805277744 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 171, 'min_samples_split': 871}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,030]\u001b[0m Trial 80 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 170, 'min_samples_split': 898}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,030]\u001b[0m Trial 83 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 111, 'min_samples_split': 892}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,055]\u001b[0m Trial 82 finished with value: 0.8345583805277744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 147, 'min_samples_split': 869}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,211]\u001b[0m Trial 84 finished with value: 0.8345583805277744 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 149, 'min_samples_split': 880}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,278]\u001b[0m Trial 85 finished with value: 0.8345583805277744 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 149, 'min_samples_split': 889}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,333]\u001b[0m Trial 87 finished with value: 0.8341968911917098 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 156, 'min_samples_split': 1346}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,399]\u001b[0m Trial 86 finished with value: 0.8345583805277744 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 150, 'min_samples_split': 850}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,401]\u001b[0m Trial 89 finished with value: 0.8341968911917098 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 151, 'min_samples_split': 1361}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,616]\u001b[0m Trial 92 finished with value: 0.8341968911917098 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 155, 'min_samples_split': 1368}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,658]\u001b[0m Trial 88 finished with value: 0.8285335582600313 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 145, 'min_samples_split': 378}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,768]\u001b[0m Trial 91 finished with value: 0.8347993734184842 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 156, 'min_samples_split': 601}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,807]\u001b[0m Trial 90 finished with value: 0.8347993734184842 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 158, 'min_samples_split': 596}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,831]\u001b[0m Trial 94 finished with value: 0.8347993734184842 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 158, 'min_samples_split': 608}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,895]\u001b[0m Trial 93 finished with value: 0.8286540547053862 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 162, 'min_samples_split': 394}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,932]\u001b[0m Trial 97 finished with value: 0.8347993734184842 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 161, 'min_samples_split': 603}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,959]\u001b[0m Trial 95 finished with value: 0.8286540547053862 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 164, 'min_samples_split': 395}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,964]\u001b[0m Trial 98 finished with value: 0.8347993734184842 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 162, 'min_samples_split': 601}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:51,984]\u001b[0m Trial 99 finished with value: 0.8347993734184842 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 163, 'min_samples_split': 593}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,002]\u001b[0m Trial 96 finished with value: 0.8286540547053862 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 160, 'min_samples_split': 394}. Best is trial 9 with value: 0.8350403663091939.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_decision_tree_return, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier - Real Return\n",
      "Melhor pontuação: 0.8350403663091939\n",
      "Melhores hiperparâmetros: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 1097}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'DecisionTreeClassifier', 'Real Return')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_decision_tree_risk(trial):\n",
    "    params = {\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss']),\n",
    "        'splitter': trial.suggest_categorical('splitter', ['best', 'random']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 200),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 2000),\n",
    "\t}\n",
    "    model = DecisionTreeClassifier(**params)\n",
    "    model.fit(X_risk_train, y_risk_train)\n",
    "    preds = model.predict(X_risk_test)\n",
    "    accuracy = accuracy_score(y_risk_test, preds)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 18:03:52,129]\u001b[0m A new study created in memory with name: no-name-3ad0daf5-b316-4d92-bbdb-b225b6213851\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,203]\u001b[0m Trial 0 finished with value: 0.4328232317146644 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 9, 'min_samples_split': 542}. Best is trial 0 with value: 0.4328232317146644.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,217]\u001b[0m Trial 2 finished with value: 0.4598144354741535 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 30, 'min_samples_split': 1058}. Best is trial 2 with value: 0.4598144354741535.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,243]\u001b[0m Trial 5 finished with value: 0.45704301723099167 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 27, 'min_samples_split': 1962}. Best is trial 2 with value: 0.4598144354741535.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,247]\u001b[0m Trial 10 finished with value: 0.4472828051572479 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 76, 'min_samples_split': 1762}. Best is trial 2 with value: 0.4598144354741535.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,248]\u001b[0m Trial 11 finished with value: 0.42571394143872754 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 101, 'min_samples_split': 1402}. Best is trial 2 with value: 0.4598144354741535.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,268]\u001b[0m Trial 3 finished with value: 0.4712615977828654 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 30, 'min_samples_split': 427}. Best is trial 3 with value: 0.4712615977828654.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,290]\u001b[0m Trial 12 finished with value: 0.44957223761899023 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 107, 'min_samples_split': 1977}. Best is trial 3 with value: 0.4712615977828654.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,293]\u001b[0m Trial 13 finished with value: 0.44559585492227977 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 125, 'min_samples_split': 461}. Best is trial 3 with value: 0.4712615977828654.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,316]\u001b[0m Trial 15 finished with value: 0.4464393300397638 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 199, 'min_samples_split': 1191}. Best is trial 3 with value: 0.4712615977828654.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,324]\u001b[0m Trial 17 finished with value: 0.44800578382937706 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 91, 'min_samples_split': 1522}. Best is trial 3 with value: 0.4712615977828654.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,370]\u001b[0m Trial 19 finished with value: 0.46089890348234724 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 157, 'min_samples_split': 397}. Best is trial 3 with value: 0.4712615977828654.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,619]\u001b[0m Trial 6 finished with value: 0.4718640800096397 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 158, 'min_samples_split': 1499}. Best is trial 6 with value: 0.4718640800096397.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,792]\u001b[0m Trial 8 finished with value: 0.4730690444631883 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 17, 'min_samples_split': 307}. Best is trial 8 with value: 0.4730690444631883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,827]\u001b[0m Trial 1 finished with value: 0.4728280515724786 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 99, 'min_samples_split': 1570}. Best is trial 8 with value: 0.4730690444631883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,852]\u001b[0m Trial 18 finished with value: 0.47584046270635016 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 112, 'min_samples_split': 784}. Best is trial 18 with value: 0.47584046270635016.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,858]\u001b[0m Trial 20 finished with value: 0.47584046270635016 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 31, 'min_samples_split': 718}. Best is trial 18 with value: 0.47584046270635016.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,912]\u001b[0m Trial 4 finished with value: 0.4739125195806724 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 159, 'min_samples_split': 1185}. Best is trial 18 with value: 0.47584046270635016.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:52,970]\u001b[0m Trial 14 finished with value: 0.47343053379925293 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 147, 'min_samples_split': 1038}. Best is trial 18 with value: 0.47584046270635016.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,049]\u001b[0m Trial 16 finished with value: 0.4772864200506085 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 161, 'min_samples_split': 844}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,129]\u001b[0m Trial 7 finished with value: 0.47053861911073624 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 161, 'min_samples_split': 458}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,133]\u001b[0m Trial 9 finished with value: 0.4737920231353175 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 180, 'min_samples_split': 494}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,314]\u001b[0m Trial 21 finished with value: 0.4310157850343415 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 50, 'min_samples_split': 7}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,375]\u001b[0m Trial 26 finished with value: 0.47150259067357514 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 64, 'min_samples_split': 809}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,382]\u001b[0m Trial 25 finished with value: 0.4753584769249307 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 63, 'min_samples_split': 739}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,404]\u001b[0m Trial 24 finished with value: 0.475960959151705 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 162, 'min_samples_split': 766}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,473]\u001b[0m Trial 28 finished with value: 0.475960959151705 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 53, 'min_samples_split': 761}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,474]\u001b[0m Trial 23 finished with value: 0.44993372695505485 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 170, 'min_samples_split': 71}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,540]\u001b[0m Trial 29 finished with value: 0.4753584769249307 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 57, 'min_samples_split': 734}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,672]\u001b[0m Trial 31 finished with value: 0.4753584769249307 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 60, 'min_samples_split': 742}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,713]\u001b[0m Trial 32 finished with value: 0.4737920231353175 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 61, 'min_samples_split': 625}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,716]\u001b[0m Trial 22 finished with value: 0.4535486203157007 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 162, 'min_samples_split': 68}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,808]\u001b[0m Trial 27 finished with value: 0.44354741535124714 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 60, 'min_samples_split': 21}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:53,927]\u001b[0m Trial 33 finished with value: 0.47584046270635016 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 63, 'min_samples_split': 775}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,030]\u001b[0m Trial 35 finished with value: 0.47150259067357514 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 131, 'min_samples_split': 834}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,042]\u001b[0m Trial 34 finished with value: 0.47584046270635016 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 128, 'min_samples_split': 799}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,046]\u001b[0m Trial 36 finished with value: 0.47150259067357514 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 131, 'min_samples_split': 879}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,451]\u001b[0m Trial 41 finished with value: 0.47234606579105914 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 131, 'min_samples_split': 916}. Best is trial 16 with value: 0.4772864200506085.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,501]\u001b[0m Trial 38 finished with value: 0.4805398240751898 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 133, 'min_samples_split': 919}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,533]\u001b[0m Trial 30 finished with value: 0.45366911676105554 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 193, 'min_samples_split': 125}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,552]\u001b[0m Trial 42 finished with value: 0.47150259067357514 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 138, 'min_samples_split': 887}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,555]\u001b[0m Trial 37 finished with value: 0.4772864200506085 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 133, 'min_samples_split': 865}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,581]\u001b[0m Trial 39 finished with value: 0.4805398240751898 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 142, 'min_samples_split': 908}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,582]\u001b[0m Trial 43 finished with value: 0.47150259067357514 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 135, 'min_samples_split': 901}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,687]\u001b[0m Trial 44 finished with value: 0.4737920231353175 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 134, 'min_samples_split': 934}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,733]\u001b[0m Trial 40 finished with value: 0.47788890227738284 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 196, 'min_samples_split': 937}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,771]\u001b[0m Trial 48 finished with value: 0.4302928063622123 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 1191}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,901]\u001b[0m Trial 47 finished with value: 0.47680443426918906 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 187, 'min_samples_split': 960}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,916]\u001b[0m Trial 45 finished with value: 0.4805398240751898 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 188, 'min_samples_split': 921}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:54,982]\u001b[0m Trial 46 finished with value: 0.47788890227738284 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 193, 'min_samples_split': 941}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,288]\u001b[0m Trial 49 finished with value: 0.4739125195806724 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 146, 'min_samples_split': 1180}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,335]\u001b[0m Trial 50 finished with value: 0.4739125195806724 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 145, 'min_samples_split': 1174}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,369]\u001b[0m Trial 51 finished with value: 0.4739125195806724 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 148, 'min_samples_split': 1152}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,387]\u001b[0m Trial 52 finished with value: 0.4739125195806724 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 145, 'min_samples_split': 1164}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,444]\u001b[0m Trial 61 finished with value: 0.4583684781298952 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 178, 'min_samples_split': 1101}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,510]\u001b[0m Trial 54 finished with value: 0.4739125195806724 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 149, 'min_samples_split': 1160}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,520]\u001b[0m Trial 53 finished with value: 0.4739125195806724 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 145, 'min_samples_split': 1176}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,553]\u001b[0m Trial 64 finished with value: 0.4547535847692493 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 174, 'min_samples_split': 1336}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,582]\u001b[0m Trial 56 finished with value: 0.47487649114351127 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 182, 'min_samples_split': 1108}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,598]\u001b[0m Trial 63 finished with value: 0.4439089046873117 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 176, 'min_samples_split': 1340}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,602]\u001b[0m Trial 55 finished with value: 0.4739125195806724 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 148, 'min_samples_split': 1132}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,660]\u001b[0m Trial 57 finished with value: 0.47487649114351127 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 175, 'min_samples_split': 1101}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,762]\u001b[0m Trial 58 finished with value: 0.47487649114351127 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 174, 'min_samples_split': 1118}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,883]\u001b[0m Trial 60 finished with value: 0.4728280515724786 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 180, 'min_samples_split': 1302}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:55,892]\u001b[0m Trial 59 finished with value: 0.4739125195806724 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 176, 'min_samples_split': 1142}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:56,241]\u001b[0m Trial 62 finished with value: 0.47487649114351127 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 178, 'min_samples_split': 1051}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:56,393]\u001b[0m Trial 65 finished with value: 0.4728280515724786 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 180, 'min_samples_split': 1335}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:56,515]\u001b[0m Trial 66 finished with value: 0.4728280515724786 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 174, 'min_samples_split': 1306}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:56,763]\u001b[0m Trial 70 finished with value: 0.47343053379925293 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 198, 'min_samples_split': 1024}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:56,810]\u001b[0m Trial 68 finished with value: 0.47355103024460776 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 197, 'min_samples_split': 654}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:56,814]\u001b[0m Trial 69 finished with value: 0.47343053379925293 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 199, 'min_samples_split': 1006}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:56,904]\u001b[0m Trial 67 finished with value: 0.47463549825280155 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 200, 'min_samples_split': 625}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:56,905]\u001b[0m Trial 72 finished with value: 0.47463549825280155 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 117, 'min_samples_split': 602}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:56,907]\u001b[0m Trial 71 finished with value: 0.47463549825280155 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 116, 'min_samples_split': 626}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:56,968]\u001b[0m Trial 73 finished with value: 0.47463549825280155 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 121, 'min_samples_split': 632}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,003]\u001b[0m Trial 74 finished with value: 0.47463549825280155 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 199, 'min_samples_split': 639}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,070]\u001b[0m Trial 75 finished with value: 0.47463549825280155 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 200, 'min_samples_split': 628}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,236]\u001b[0m Trial 76 finished with value: 0.47355103024460776 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 115, 'min_samples_split': 657}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,272]\u001b[0m Trial 77 finished with value: 0.47343053379925293 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 119, 'min_samples_split': 984}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,360]\u001b[0m Trial 88 finished with value: 0.46511627906976744 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 189, 'min_samples_split': 961}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,396]\u001b[0m Trial 89 finished with value: 0.4615013857091216 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 189, 'min_samples_split': 968}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,444]\u001b[0m Trial 78 finished with value: 0.47355103024460776 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 120, 'min_samples_split': 657}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,753]\u001b[0m Trial 79 finished with value: 0.47463549825280155 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 123, 'min_samples_split': 613}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,784]\u001b[0m Trial 82 finished with value: 0.4772864200506085 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 193, 'min_samples_split': 848}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,871]\u001b[0m Trial 81 finished with value: 0.4702976262200265 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 166, 'min_samples_split': 560}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,901]\u001b[0m Trial 80 finished with value: 0.4702976262200265 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 115, 'min_samples_split': 567}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,980]\u001b[0m Trial 86 finished with value: 0.47343053379925293 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 187, 'min_samples_split': 971}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:57,993]\u001b[0m Trial 83 finished with value: 0.47680443426918906 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 166, 'min_samples_split': 963}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,073]\u001b[0m Trial 84 finished with value: 0.47788890227738284 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 188, 'min_samples_split': 946}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,077]\u001b[0m Trial 85 finished with value: 0.47343053379925293 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 185, 'min_samples_split': 982}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,080]\u001b[0m Trial 87 finished with value: 0.47680443426918906 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 188, 'min_samples_split': 961}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,177]\u001b[0m Trial 91 finished with value: 0.4772864200506085 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 187, 'min_samples_split': 860}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,205]\u001b[0m Trial 90 finished with value: 0.4772864200506085 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 166, 'min_samples_split': 850}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,234]\u001b[0m Trial 92 finished with value: 0.4780093987227377 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 163, 'min_samples_split': 841}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,530]\u001b[0m Trial 94 finished with value: 0.4772864200506085 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 187, 'min_samples_split': 854}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,538]\u001b[0m Trial 93 finished with value: 0.4753584769249307 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 166, 'min_samples_split': 819}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,575]\u001b[0m Trial 96 finished with value: 0.4772864200506085 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 186, 'min_samples_split': 860}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,579]\u001b[0m Trial 95 finished with value: 0.4772864200506085 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 186, 'min_samples_split': 879}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,660]\u001b[0m Trial 98 finished with value: 0.4772864200506085 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 106, 'min_samples_split': 871}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,661]\u001b[0m Trial 97 finished with value: 0.4772864200506085 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 155, 'min_samples_split': 843}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,672]\u001b[0m Trial 99 finished with value: 0.4772864200506085 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 153, 'min_samples_split': 854}. Best is trial 38 with value: 0.4805398240751898.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_decision_tree_risk, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier - Risk\n",
      "Melhor pontuação: 0.4805398240751898\n",
      "Melhores hiperparâmetros: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 133, 'min_samples_split': 919}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'DecisionTreeClassifier', 'Risk')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_naive_bayes_return(trial):\n",
    "    params = {\n",
    "        'var_smoothing': trial.suggest_loguniform('var_smoothing', 1e-12, 1e-5)\n",
    "\t}\n",
    "    model = GaussianNB(**params)\n",
    "    model.fit(X_real_return_train, y_real_return_train)\n",
    "    preds = model.predict(X_real_return_test)\n",
    "    accuracy = accuracy_score(y_real_return_test, preds)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 18:03:58,846]\u001b[0m A new study created in memory with name: no-name-28889485-c2a3-41f9-898d-4092f2ee26ab\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,958]\u001b[0m Trial 0 finished with value: 0.37341848415471746 and parameters: {'var_smoothing': 1.8557146704786043e-06}. Best is trial 0 with value: 0.37341848415471746.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,959]\u001b[0m Trial 2 finished with value: 0.37341848415471746 and parameters: {'var_smoothing': 1.847122980665886e-06}. Best is trial 0 with value: 0.37341848415471746.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,968]\u001b[0m Trial 7 finished with value: 0.3779973490782022 and parameters: {'var_smoothing': 8.335200190981194e-06}. Best is trial 7 with value: 0.3779973490782022.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,980]\u001b[0m Trial 4 finished with value: 0.3811302566574286 and parameters: {'var_smoothing': 1.3935991982085752e-08}. Best is trial 4 with value: 0.3811302566574286.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,985]\u001b[0m Trial 1 finished with value: 0.38125075310278345 and parameters: {'var_smoothing': 1.3761790657285092e-08}. Best is trial 1 with value: 0.38125075310278345.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,986]\u001b[0m Trial 5 finished with value: 0.394746354982528 and parameters: {'var_smoothing': 2.0773822519418867e-09}. Best is trial 5 with value: 0.394746354982528.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,988]\u001b[0m Trial 8 finished with value: 0.37305699481865284 and parameters: {'var_smoothing': 1.3677719835187577e-06}. Best is trial 5 with value: 0.394746354982528.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,989]\u001b[0m Trial 9 finished with value: 0.4293288347993734 and parameters: {'var_smoothing': 1.3222169637345843e-12}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,992]\u001b[0m Trial 6 finished with value: 0.3785998313049765 and parameters: {'var_smoothing': 9.436264164692027e-06}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,993]\u001b[0m Trial 10 finished with value: 0.3865525966983974 and parameters: {'var_smoothing': 5.360030618347865e-09}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:58,994]\u001b[0m Trial 3 finished with value: 0.3747439450536209 and parameters: {'var_smoothing': 1.0971098597687801e-07}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,013]\u001b[0m Trial 11 finished with value: 0.38414266779130013 and parameters: {'var_smoothing': 7.364218090573663e-09}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,120]\u001b[0m Trial 12 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 1.8623298911083506e-12}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,136]\u001b[0m Trial 13 finished with value: 0.41679720448246776 and parameters: {'var_smoothing': 6.388596110797645e-11}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,164]\u001b[0m Trial 14 finished with value: 0.37317749126400773 and parameters: {'var_smoothing': 2.1430568984534133e-06}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,177]\u001b[0m Trial 18 finished with value: 0.42764188456440533 and parameters: {'var_smoothing': 4.903946677292082e-12}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,178]\u001b[0m Trial 15 finished with value: 0.4286058561272442 and parameters: {'var_smoothing': 2.3775432028286227e-12}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,188]\u001b[0m Trial 17 finished with value: 0.4286058561272442 and parameters: {'var_smoothing': 2.59974290129949e-12}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,196]\u001b[0m Trial 20 finished with value: 0.42800337390046994 and parameters: {'var_smoothing': 3.405975666945154e-12}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,197]\u001b[0m Trial 16 finished with value: 0.42764188456440533 and parameters: {'var_smoothing': 4.9433036542016456e-12}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,198]\u001b[0m Trial 19 finished with value: 0.42764188456440533 and parameters: {'var_smoothing': 4.9574693371458196e-12}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,218]\u001b[0m Trial 22 finished with value: 0.42788287745511505 and parameters: {'var_smoothing': 4.1514213130814806e-12}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,229]\u001b[0m Trial 21 finished with value: 0.4286058561272442 and parameters: {'var_smoothing': 2.5733937207844367e-12}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,243]\u001b[0m Trial 23 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 2.0201120899768505e-12}. Best is trial 9 with value: 0.4293288347993734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,301]\u001b[0m Trial 25 finished with value: 0.4294493312447283 and parameters: {'var_smoothing': 1.191139630320361e-12}. Best is trial 25 with value: 0.4294493312447283.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,306]\u001b[0m Trial 24 finished with value: 0.4286058561272442 and parameters: {'var_smoothing': 2.2981670719403074e-12}. Best is trial 25 with value: 0.4294493312447283.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,326]\u001b[0m Trial 26 finished with value: 0.429690324135438 and parameters: {'var_smoothing': 1.1218244619811e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,358]\u001b[0m Trial 27 finished with value: 0.4223400409687914 and parameters: {'var_smoothing': 1.7970239319965742e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,359]\u001b[0m Trial 29 finished with value: 0.429690324135438 and parameters: {'var_smoothing': 1.0942405941035346e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,391]\u001b[0m Trial 31 finished with value: 0.4194481262802747 and parameters: {'var_smoothing': 3.081468181440909e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,392]\u001b[0m Trial 28 finished with value: 0.4213760694059525 and parameters: {'var_smoothing': 2.2129516310653257e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,407]\u001b[0m Trial 30 finished with value: 0.4170381973731775 and parameters: {'var_smoothing': 5.6367210650800076e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,438]\u001b[0m Trial 34 finished with value: 0.4205325942884685 and parameters: {'var_smoothing': 2.4454418298160962e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,439]\u001b[0m Trial 32 finished with value: 0.4181226653813713 and parameters: {'var_smoothing': 4.152596983008547e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,476]\u001b[0m Trial 33 finished with value: 0.4193276298349199 and parameters: {'var_smoothing': 3.273270911981528e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,484]\u001b[0m Trial 36 finished with value: 0.419207133389565 and parameters: {'var_smoothing': 3.313751879547296e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,484]\u001b[0m Trial 35 finished with value: 0.429690324135438 and parameters: {'var_smoothing': 1.0285887184650193e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,507]\u001b[0m Trial 38 finished with value: 0.4213760694059525 and parameters: {'var_smoothing': 2.206787131680114e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,508]\u001b[0m Trial 37 finished with value: 0.419207133389565 and parameters: {'var_smoothing': 3.308283080214732e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,524]\u001b[0m Trial 39 finished with value: 0.41968911917098445 and parameters: {'var_smoothing': 2.795299356732244e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,580]\u001b[0m Trial 40 finished with value: 0.4213760694059525 and parameters: {'var_smoothing': 2.2043831477356597e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,581]\u001b[0m Trial 43 finished with value: 0.4255934449933727 and parameters: {'var_smoothing': 1.1522067285356949e-11}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,583]\u001b[0m Trial 41 finished with value: 0.429690324135438 and parameters: {'var_smoothing': 1.0118188265324779e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,593]\u001b[0m Trial 42 finished with value: 0.4293288347993734 and parameters: {'var_smoothing': 1.3431544002232062e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,604]\u001b[0m Trial 44 finished with value: 0.4294493312447283 and parameters: {'var_smoothing': 1.1525688991661825e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,653]\u001b[0m Trial 45 finished with value: 0.4294493312447283 and parameters: {'var_smoothing': 1.2662127425865106e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,680]\u001b[0m Trial 48 finished with value: 0.4294493312447283 and parameters: {'var_smoothing': 1.2580384287170428e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,687]\u001b[0m Trial 46 finished with value: 0.4294493312447283 and parameters: {'var_smoothing': 1.2556563116753472e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,706]\u001b[0m Trial 49 finished with value: 0.4294493312447283 and parameters: {'var_smoothing': 1.2432847199314644e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,710]\u001b[0m Trial 47 finished with value: 0.429690324135438 and parameters: {'var_smoothing': 1.0284087622374991e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,725]\u001b[0m Trial 51 finished with value: 0.4293288347993734 and parameters: {'var_smoothing': 1.3034759985124253e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,750]\u001b[0m Trial 50 finished with value: 0.429690324135438 and parameters: {'var_smoothing': 1.001993678132467e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,780]\u001b[0m Trial 52 finished with value: 0.4294493312447283 and parameters: {'var_smoothing': 1.1777897703081062e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,796]\u001b[0m Trial 53 finished with value: 0.429690324135438 and parameters: {'var_smoothing': 1.0534000956935174e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,815]\u001b[0m Trial 56 finished with value: 0.429690324135438 and parameters: {'var_smoothing': 1.0171999394508347e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,819]\u001b[0m Trial 55 finished with value: 0.429690324135438 and parameters: {'var_smoothing': 1.0598568672966916e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,835]\u001b[0m Trial 54 finished with value: 0.4294493312447283 and parameters: {'var_smoothing': 1.18535802664387e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,872]\u001b[0m Trial 57 finished with value: 0.4267984094469213 and parameters: {'var_smoothing': 8.767912447768195e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,894]\u001b[0m Trial 59 finished with value: 0.4267984094469213 and parameters: {'var_smoothing': 8.709742309155511e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,901]\u001b[0m Trial 58 finished with value: 0.4265574165562116 and parameters: {'var_smoothing': 9.274255570447087e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,915]\u001b[0m Trial 61 finished with value: 0.4271598987829859 and parameters: {'var_smoothing': 8.063651591840673e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,952]\u001b[0m Trial 63 finished with value: 0.4275213881190505 and parameters: {'var_smoothing': 5.96510306000701e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,952]\u001b[0m Trial 62 finished with value: 0.4267984094469213 and parameters: {'var_smoothing': 8.91802891036438e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,955]\u001b[0m Trial 60 finished with value: 0.4271598987829859 and parameters: {'var_smoothing': 6.708277437219489e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,997]\u001b[0m Trial 66 finished with value: 0.4267984094469213 and parameters: {'var_smoothing': 8.868052828513253e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:03:59,999]\u001b[0m Trial 64 finished with value: 0.42703940233763105 and parameters: {'var_smoothing': 8.249060594961977e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,023]\u001b[0m Trial 65 finished with value: 0.4267984094469213 and parameters: {'var_smoothing': 8.883096533863803e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,028]\u001b[0m Trial 68 finished with value: 0.4271598987829859 and parameters: {'var_smoothing': 7.972521313398033e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,031]\u001b[0m Trial 67 finished with value: 0.42703940233763105 and parameters: {'var_smoothing': 8.129321380976488e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,078]\u001b[0m Trial 70 finished with value: 0.42824436679117966 and parameters: {'var_smoothing': 3.1310340478814925e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,095]\u001b[0m Trial 71 finished with value: 0.42800337390046994 and parameters: {'var_smoothing': 3.4014260030784408e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,100]\u001b[0m Trial 72 finished with value: 0.4281238703458248 and parameters: {'var_smoothing': 3.6252498326549257e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,106]\u001b[0m Trial 69 finished with value: 0.4275213881190505 and parameters: {'var_smoothing': 5.407561109933734e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,110]\u001b[0m Trial 73 finished with value: 0.42800337390046994 and parameters: {'var_smoothing': 3.30536820712063e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,150]\u001b[0m Trial 74 finished with value: 0.4281238703458248 and parameters: {'var_smoothing': 3.503447410975687e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,170]\u001b[0m Trial 76 finished with value: 0.4284853596818894 and parameters: {'var_smoothing': 2.6725194277658735e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,178]\u001b[0m Trial 75 finished with value: 0.42824436679117966 and parameters: {'var_smoothing': 3.170403939155352e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,210]\u001b[0m Trial 77 finished with value: 0.4281238703458248 and parameters: {'var_smoothing': 3.2328476647986583e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,233]\u001b[0m Trial 80 finished with value: 0.42824436679117966 and parameters: {'var_smoothing': 3.110929892617443e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,248]\u001b[0m Trial 79 finished with value: 0.42824436679117966 and parameters: {'var_smoothing': 3.111383520608217e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,252]\u001b[0m Trial 78 finished with value: 0.4286058561272442 and parameters: {'var_smoothing': 2.2716212280757866e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,282]\u001b[0m Trial 81 finished with value: 0.42800337390046994 and parameters: {'var_smoothing': 3.4411349138705053e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,297]\u001b[0m Trial 83 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 2.0103290346609556e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,302]\u001b[0m Trial 84 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 2.045115697912566e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,553]\u001b[0m Trial 85 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 2.1185582914416582e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,562]\u001b[0m Trial 82 finished with value: 0.4286058561272442 and parameters: {'var_smoothing': 2.2055214061625247e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,590]\u001b[0m Trial 86 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 2.070964653288907e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,610]\u001b[0m Trial 88 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 1.9848441342448813e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,623]\u001b[0m Trial 87 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 1.863661815171789e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,637]\u001b[0m Trial 89 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 2.033573984712887e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,657]\u001b[0m Trial 90 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 1.8246454387195483e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,680]\u001b[0m Trial 91 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 1.9030364925709927e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,684]\u001b[0m Trial 92 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 1.9291673519037065e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,694]\u001b[0m Trial 94 finished with value: 0.42908784190866367 and parameters: {'var_smoothing': 1.7346871306529977e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,695]\u001b[0m Trial 95 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 1.8735686530114917e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,709]\u001b[0m Trial 93 finished with value: 0.42884684901795395 and parameters: {'var_smoothing': 2.1295004163666836e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,710]\u001b[0m Trial 96 finished with value: 0.4293288347993734 and parameters: {'var_smoothing': 1.6651941057973955e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,718]\u001b[0m Trial 98 finished with value: 0.429690324135438 and parameters: {'var_smoothing': 1.019746939991686e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,720]\u001b[0m Trial 97 finished with value: 0.429690324135438 and parameters: {'var_smoothing': 1.0085140389415224e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,728]\u001b[0m Trial 99 finished with value: 0.429690324135438 and parameters: {'var_smoothing': 1.0100695964888761e-12}. Best is trial 26 with value: 0.429690324135438.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_naive_bayes_return, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Real Return\n",
      "Melhor pontuação: 0.429690324135438\n",
      "Melhores hiperparâmetros: {'var_smoothing': 1.1218244619811e-12}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'Naive Bayes', 'Real Return')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_naive_bayes_risk(trial):\n",
    "    params = {\n",
    "        'var_smoothing': trial.suggest_loguniform('var_smoothing', 1e-12, 1e-5)\n",
    "\t}\n",
    "    model = GaussianNB(**params)\n",
    "    model.fit(X_risk_train, y_risk_train)\n",
    "    preds = model.predict(X_risk_test)\n",
    "    accuracy = accuracy_score(y_risk_test, preds)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 18:04:00,856]\u001b[0m A new study created in memory with name: no-name-bd42f733-73c2-4a3e-93fd-cbb5676c5892\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,964]\u001b[0m Trial 2 finished with value: 0.356307988914327 and parameters: {'var_smoothing': 2.179134213612953e-09}. Best is trial 2 with value: 0.356307988914327.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,967]\u001b[0m Trial 0 finished with value: 0.3195565730810941 and parameters: {'var_smoothing': 9.654162864784708e-07}. Best is trial 2 with value: 0.356307988914327.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,972]\u001b[0m Trial 1 finished with value: 0.31521870104831906 and parameters: {'var_smoothing': 5.004721403902181e-06}. Best is trial 2 with value: 0.356307988914327.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,979]\u001b[0m Trial 7 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 1.9701785382290422e-11}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,982]\u001b[0m Trial 4 finished with value: 0.3354621038679359 and parameters: {'var_smoothing': 8.025213167662638e-08}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,984]\u001b[0m Trial 3 finished with value: 0.3561874924689722 and parameters: {'var_smoothing': 2.4487047047748507e-09}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,987]\u001b[0m Trial 8 finished with value: 0.3434148692613568 and parameters: {'var_smoothing': 3.684343229205848e-08}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,997]\u001b[0m Trial 9 finished with value: 0.32991926738161226 and parameters: {'var_smoothing': 1.2676578889015556e-07}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:00,999]\u001b[0m Trial 10 finished with value: 0.35666947825039164 and parameters: {'var_smoothing': 1.4722763714044168e-09}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,000]\u001b[0m Trial 6 finished with value: 0.3150982046029642 and parameters: {'var_smoothing': 5.857727717346595e-06}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,001]\u001b[0m Trial 5 finished with value: 0.3144957223761899 and parameters: {'var_smoothing': 7.674260428210192e-06}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,009]\u001b[0m Trial 11 finished with value: 0.35787444270394025 and parameters: {'var_smoothing': 4.3194363030074757e-10}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,122]\u001b[0m Trial 12 finished with value: 0.35365706711652006 and parameters: {'var_smoothing': 7.521190814407385e-09}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,131]\u001b[0m Trial 14 finished with value: 0.33787203277503314 and parameters: {'var_smoothing': 6.179661898420853e-08}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,153]\u001b[0m Trial 13 finished with value: 0.32027955175322326 and parameters: {'var_smoothing': 8.66152790784869e-07}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,178]\u001b[0m Trial 15 finished with value: 0.3585974213760694 and parameters: {'var_smoothing': 2.671359525230153e-11}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,185]\u001b[0m Trial 16 finished with value: 0.35847692493071454 and parameters: {'var_smoothing': 2.520257584411332e-11}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,196]\u001b[0m Trial 20 finished with value: 0.3585974213760694 and parameters: {'var_smoothing': 2.981475891445333e-11}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,230]\u001b[0m Trial 17 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 1.2513325872191212e-11}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,242]\u001b[0m Trial 18 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 2.1384675651663497e-11}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,243]\u001b[0m Trial 21 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 1.0850438664335006e-11}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,252]\u001b[0m Trial 19 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 2.1881414221651658e-11}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,254]\u001b[0m Trial 22 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 2.1943255322077224e-11}. Best is trial 7 with value: 0.35871791782142426.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,297]\u001b[0m Trial 24 finished with value: 0.35883841426677915 and parameters: {'var_smoothing': 1.7550945555712285e-11}. Best is trial 24 with value: 0.35883841426677915.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,301]\u001b[0m Trial 23 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 2.3018349963100768e-11}. Best is trial 24 with value: 0.35883841426677915.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,325]\u001b[0m Trial 25 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 3.7444010015247953e-11}. Best is trial 24 with value: 0.35883841426677915.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,327]\u001b[0m Trial 26 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 5.0613309303600815e-11}. Best is trial 24 with value: 0.35883841426677915.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,339]\u001b[0m Trial 27 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.013375533407592e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,362]\u001b[0m Trial 29 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.945344627183976e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,386]\u001b[0m Trial 30 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.3993943275542802e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,389]\u001b[0m Trial 28 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.4984834195867466e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,448]\u001b[0m Trial 32 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.2682209765603882e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,451]\u001b[0m Trial 33 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 3.1660681720155423e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,469]\u001b[0m Trial 31 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.5517791911299186e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,503]\u001b[0m Trial 34 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.3904038766589725e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,511]\u001b[0m Trial 35 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.2628543380265924e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,520]\u001b[0m Trial 36 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.3786990382195957e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,575]\u001b[0m Trial 44 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 3.999216819256866e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,578]\u001b[0m Trial 38 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.165375062042442e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,596]\u001b[0m Trial 37 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.085813737181805e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,599]\u001b[0m Trial 39 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.4540126244963957e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,608]\u001b[0m Trial 40 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.5589250191806063e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,609]\u001b[0m Trial 41 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.3857386537582183e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,654]\u001b[0m Trial 45 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 4.672962926656263e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,655]\u001b[0m Trial 42 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.1293845822059934e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,681]\u001b[0m Trial 43 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.2143240365349176e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,747]\u001b[0m Trial 48 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 6.16917456706195e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,749]\u001b[0m Trial 46 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 4.593454394723483e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,750]\u001b[0m Trial 47 finished with value: 0.358958910712134 and parameters: {'var_smoothing': 5.134243024629791e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,777]\u001b[0m Trial 49 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 4.654585730606329e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,785]\u001b[0m Trial 50 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 7.845582209888975e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,808]\u001b[0m Trial 54 finished with value: 0.35883841426677915 and parameters: {'var_smoothing': 5.216174411491288e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,814]\u001b[0m Trial 51 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 6.927440297706393e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,818]\u001b[0m Trial 52 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 3.936996182619065e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,853]\u001b[0m Trial 55 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 5.5331020963177796e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,854]\u001b[0m Trial 53 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 4.2691574242173976e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,885]\u001b[0m Trial 57 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 5.780360499034967e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,900]\u001b[0m Trial 56 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 5.88161982753302e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,958]\u001b[0m Trial 58 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 8.623483113873195e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,963]\u001b[0m Trial 59 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.808778957970504e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,965]\u001b[0m Trial 60 finished with value: 0.3582359320400048 and parameters: {'var_smoothing': 7.456304462885596e-11}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:01,971]\u001b[0m Trial 61 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 3.096526682209694e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,010]\u001b[0m Trial 62 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.602294031213966e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,012]\u001b[0m Trial 65 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.3666413063616494e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,029]\u001b[0m Trial 63 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.4533952394771536e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,041]\u001b[0m Trial 64 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.4360563032412142e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,058]\u001b[0m Trial 68 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.5066466831905204e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,064]\u001b[0m Trial 66 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.5607853152438637e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,073]\u001b[0m Trial 69 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.266456055322785e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,099]\u001b[0m Trial 67 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.1324457124475825e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,148]\u001b[0m Trial 70 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.708579905318415e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,161]\u001b[0m Trial 73 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.3390444435277655e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,191]\u001b[0m Trial 71 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.1110772175398228e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,206]\u001b[0m Trial 72 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.40666315977141e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,213]\u001b[0m Trial 75 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 1.2275555450079648e-11}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,226]\u001b[0m Trial 74 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 2.294478303328258e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,256]\u001b[0m Trial 79 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.0029987317223962e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,257]\u001b[0m Trial 78 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 1.4106554323121503e-11}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,266]\u001b[0m Trial 77 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 1.3638058286777012e-11}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,274]\u001b[0m Trial 76 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 1.2201598170797194e-11}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,276]\u001b[0m Trial 80 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 1.0064198205934033e-11}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,323]\u001b[0m Trial 81 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 1.3533582445270626e-11}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,346]\u001b[0m Trial 82 finished with value: 0.35871791782142426 and parameters: {'var_smoothing': 1.3163964549797934e-11}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,367]\u001b[0m Trial 83 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.561070041671956e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,405]\u001b[0m Trial 84 finished with value: 0.35883841426677915 and parameters: {'var_smoothing': 1.449020243757084e-11}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,422]\u001b[0m Trial 85 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.0592935606500987e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,433]\u001b[0m Trial 86 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.1036399300418105e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,439]\u001b[0m Trial 87 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.1588136357011466e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,466]\u001b[0m Trial 91 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.4218256318168561e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,479]\u001b[0m Trial 89 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.1305024186865483e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,484]\u001b[0m Trial 92 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.4026309606895197e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,492]\u001b[0m Trial 90 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 3.6301383609324875e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,492]\u001b[0m Trial 88 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.4426174201588353e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,501]\u001b[0m Trial 93 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.3829224451429022e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,524]\u001b[0m Trial 94 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.5853838994996764e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,527]\u001b[0m Trial 95 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.0744479686401895e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,538]\u001b[0m Trial 96 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.5454197827193021e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,551]\u001b[0m Trial 98 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.6150262182676976e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,553]\u001b[0m Trial 97 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 1.586834159392808e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:04:02,554]\u001b[0m Trial 99 finished with value: 0.3590794071574889 and parameters: {'var_smoothing': 3.8516883610699194e-12}. Best is trial 27 with value: 0.3590794071574889.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_naive_bayes_risk, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Risk\n",
      "Melhor pontuação: 0.3590794071574889\n",
      "Melhores hiperparâmetros: {'var_smoothing': 1.013375533407592e-12}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'Naive Bayes', 'Risk')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rede Neural"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_neural_network_return(trial):\n",
    "\tparams = {\n",
    "\t\t'activation': trial.suggest_categorical('activation', ['identity', 'logistic', 'tanh', 'relu']),\n",
    "\t\t'solver': trial.suggest_categorical('solver', ['lbfgs', 'sgd', 'adam']),\n",
    "\t\t'max_iter': trial.suggest_int('max_iter', 200, 2000),\n",
    "\t\t'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(100,), (200,), (300,), (400,), (500,), (600,), (700,), (800,), (900,), (1000,)]),\n",
    "\t\t'learning_rate': trial.suggest_categorical('learning_rate', ['constant', 'invscaling', 'adaptive']), \n",
    "\t}\n",
    "\n",
    "\tmodel = MLPClassifier(**params)\n",
    "\tmodel.fit(X_real_return_train, y_real_return_train)\n",
    "\tpreds = model.predict(X_real_return_test)\n",
    "\taccuracy = accuracy_score(y_real_return_test, preds)\n",
    "\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 18:04:02,689]\u001b[0m A new study created in memory with name: no-name-0819c187-d1d8-447c-a2d3-27889cab3951\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:06:37,112]\u001b[0m Trial 4 finished with value: 0.710929027593686 and parameters: {'activation': 'tanh', 'solver': 'adam', 'max_iter': 829, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}. Best is trial 4 with value: 0.710929027593686.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:07:08,694]\u001b[0m Trial 3 finished with value: 0.6986383901674901 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'max_iter': 266, 'hidden_layer_sizes': (500,), 'learning_rate': 'adaptive'}. Best is trial 4 with value: 0.710929027593686.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:07:19,987]\u001b[0m Trial 8 finished with value: 0.6880347029762622 and parameters: {'activation': 'tanh', 'solver': 'adam', 'max_iter': 1846, 'hidden_layer_sizes': (300,), 'learning_rate': 'adaptive'}. Best is trial 4 with value: 0.710929027593686.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:07:25,606]\u001b[0m Trial 7 finished with value: 0.635739245692252 and parameters: {'activation': 'identity', 'solver': 'adam', 'max_iter': 855, 'hidden_layer_sizes': (600,), 'learning_rate': 'invscaling'}. Best is trial 4 with value: 0.710929027593686.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:07:45,514]\u001b[0m Trial 6 finished with value: 0.7132184600554283 and parameters: {'activation': 'logistic', 'solver': 'adam', 'max_iter': 923, 'hidden_layer_sizes': (300,), 'learning_rate': 'constant'}. Best is trial 6 with value: 0.7132184600554283.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:07:58,592]\u001b[0m Trial 2 finished with value: 0.717917821424268 and parameters: {'activation': 'tanh', 'solver': 'adam', 'max_iter': 732, 'hidden_layer_sizes': (900,), 'learning_rate': 'adaptive'}. Best is trial 2 with value: 0.717917821424268.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:08:36,686]\u001b[0m Trial 1 finished with value: 0.7083986022412339 and parameters: {'activation': 'tanh', 'solver': 'adam', 'max_iter': 1114, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 2 with value: 0.717917821424268.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:09:07,523]\u001b[0m Trial 9 finished with value: 0.697794915050006 and parameters: {'activation': 'tanh', 'solver': 'adam', 'max_iter': 1387, 'hidden_layer_sizes': (500,), 'learning_rate': 'constant'}. Best is trial 2 with value: 0.717917821424268.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:09:09,012]\u001b[0m Trial 13 finished with value: 0.39595131943607664 and parameters: {'activation': 'relu', 'solver': 'sgd', 'max_iter': 1917, 'hidden_layer_sizes': (300,), 'learning_rate': 'invscaling'}. Best is trial 2 with value: 0.717917821424268.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:12:52,415]\u001b[0m Trial 14 finished with value: 0.6940595252440053 and parameters: {'activation': 'logistic', 'solver': 'adam', 'max_iter': 1663, 'hidden_layer_sizes': (600,), 'learning_rate': 'constant'}. Best is trial 2 with value: 0.717917821424268.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:13:34,918]\u001b[0m Trial 21 finished with value: 0.3457043017230992 and parameters: {'activation': 'identity', 'solver': 'lbfgs', 'max_iter': 300, 'hidden_layer_sizes': (900,), 'learning_rate': 'adaptive'}. Best is trial 2 with value: 0.717917821424268.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:14:28,392]\u001b[0m Trial 15 finished with value: 0.5659718038317869 and parameters: {'activation': 'relu', 'solver': 'adam', 'max_iter': 1304, 'hidden_layer_sizes': (400,), 'learning_rate': 'invscaling'}. Best is trial 2 with value: 0.717917821424268.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:14:37,988]\u001b[0m Trial 19 finished with value: 0.6842993131702615 and parameters: {'activation': 'tanh', 'solver': 'adam', 'max_iter': 1247, 'hidden_layer_sizes': (500,), 'learning_rate': 'adaptive'}. Best is trial 2 with value: 0.717917821424268.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:15:16,228]\u001b[0m Trial 20 finished with value: 0.7198457645499458 and parameters: {'activation': 'logistic', 'solver': 'adam', 'max_iter': 1090, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 20 with value: 0.7198457645499458.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:15:43,673]\u001b[0m Trial 5 finished with value: 0.68128690203639 and parameters: {'activation': 'tanh', 'solver': 'adam', 'max_iter': 894, 'hidden_layer_sizes': (1000,), 'learning_rate': 'adaptive'}. Best is trial 20 with value: 0.7198457645499458.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:17:33,218]\u001b[0m Trial 16 finished with value: 0.6189902397879262 and parameters: {'activation': 'identity', 'solver': 'adam', 'max_iter': 1681, 'hidden_layer_sizes': (1000,), 'learning_rate': 'adaptive'}. Best is trial 20 with value: 0.7198457645499458.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:17:54,563]\u001b[0m Trial 24 finished with value: 0.6120014459573443 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 668, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 20 with value: 0.7198457645499458.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:17:59,667]\u001b[0m Trial 10 finished with value: 0.7173153391974937 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'max_iter': 1174, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 20 with value: 0.7198457645499458.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:18:23,596]\u001b[0m Trial 22 finished with value: 0.6610434992167731 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 673, 'hidden_layer_sizes': (1000,), 'learning_rate': 'constant'}. Best is trial 20 with value: 0.7198457645499458.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:19:09,789]\u001b[0m Trial 17 finished with value: 0.7112905169297505 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'max_iter': 940, 'hidden_layer_sizes': (600,), 'learning_rate': 'adaptive'}. Best is trial 20 with value: 0.7198457645499458.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:19:13,119]\u001b[0m Trial 26 finished with value: 0.6630919387878058 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 519, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant'}. Best is trial 20 with value: 0.7198457645499458.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:20:31,444]\u001b[0m Trial 32 finished with value: 0.6342932883479937 and parameters: {'activation': 'relu', 'solver': 'lbfgs', 'max_iter': 1103, 'hidden_layer_sizes': (900,), 'learning_rate': 'constant'}. Best is trial 20 with value: 0.7198457645499458.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:22:02,901]\u001b[0m Trial 29 finished with value: 0.6818893842631643 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 597, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 20 with value: 0.7198457645499458.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:25:46,334]\u001b[0m Trial 12 finished with value: 0.7069526448969755 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 776, 'hidden_layer_sizes': (400,), 'learning_rate': 'adaptive'}. Best is trial 20 with value: 0.7198457645499458.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:26:50,968]\u001b[0m Trial 28 finished with value: 0.7234606579105917 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 552, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 28 with value: 0.7234606579105917.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:26:55,916]\u001b[0m Trial 27 finished with value: 0.6246535727196048 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 695, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 28 with value: 0.7234606579105917.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:29:43,213]\u001b[0m Trial 30 finished with value: 0.7287625015062056 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 613, 'hidden_layer_sizes': (900,), 'learning_rate': 'adaptive'}. Best is trial 30 with value: 0.7287625015062056.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:32:50,462]\u001b[0m Trial 11 finished with value: 0.7099650560308471 and parameters: {'activation': 'relu', 'solver': 'adam', 'max_iter': 1225, 'hidden_layer_sizes': (700,), 'learning_rate': 'invscaling'}. Best is trial 30 with value: 0.7287625015062056.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:36:44,100]\u001b[0m Trial 36 finished with value: 0.7247861188094952 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 465, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 30 with value: 0.7287625015062056.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:37:57,208]\u001b[0m Trial 37 finished with value: 0.7215327147849139 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 503, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 30 with value: 0.7287625015062056.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:38:56,487]\u001b[0m Trial 38 finished with value: 0.7256295939269791 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 418, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 30 with value: 0.7287625015062056.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:43:00,456]\u001b[0m Trial 39 finished with value: 0.7243041330280757 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 450, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 30 with value: 0.7287625015062056.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:46:22,415]\u001b[0m Trial 40 finished with value: 0.7237016508013013 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 421, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 30 with value: 0.7287625015062056.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:46:22,533]\u001b[0m Trial 41 finished with value: 0.7211712254488493 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 370, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 30 with value: 0.7287625015062056.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:48:14,202]\u001b[0m Trial 42 finished with value: 0.7256295939269791 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 409, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 30 with value: 0.7287625015062056.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:50:47,177]\u001b[0m Trial 33 finished with value: 0.7322568984214965 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1471, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:51:25,644]\u001b[0m Trial 45 finished with value: 0.7173153391974937 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 210, 'hidden_layer_sizes': (900,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:51:33,021]\u001b[0m Trial 43 finished with value: 0.7244246294734306 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 381, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:51:33,530]\u001b[0m Trial 48 finished with value: 0.3179901192914809 and parameters: {'activation': 'identity', 'solver': 'lbfgs', 'max_iter': 1563, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:51:41,779]\u001b[0m Trial 46 finished with value: 0.7020122906374262 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 252, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:51:51,025]\u001b[0m Trial 34 finished with value: 0.7145439209543318 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'max_iter': 1459, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:51:52,823]\u001b[0m Trial 49 finished with value: 0.38799855404265576 and parameters: {'activation': 'identity', 'solver': 'lbfgs', 'max_iter': 1510, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:53:55,805]\u001b[0m Trial 47 finished with value: 0.7044222195445234 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 277, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:54:26,601]\u001b[0m Trial 44 finished with value: 0.7226171827931076 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 383, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:57:29,038]\u001b[0m Trial 35 finished with value: 0.7180383178696228 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'max_iter': 1538, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 18:58:26,110]\u001b[0m Trial 52 finished with value: 0.7258705868176889 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 354, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:02:33,291]\u001b[0m Trial 0 finished with value: 0.6764670442221954 and parameters: {'activation': 'tanh', 'solver': 'sgd', 'max_iter': 839, 'hidden_layer_sizes': (900,), 'learning_rate': 'adaptive'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:03:51,875]\u001b[0m Trial 50 finished with value: 0.7241836365827208 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1020, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:04:37,918]\u001b[0m Trial 56 finished with value: 0.7185203036510422 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 600, 'hidden_layer_sizes': (200,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:05:39,717]\u001b[0m Trial 54 finished with value: 0.7241836365827208 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 606, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:06:59,269]\u001b[0m Trial 55 finished with value: 0.7149054102903964 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 986, 'hidden_layer_sizes': (200,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:07:23,329]\u001b[0m Trial 60 finished with value: 0.6059766236896011 and parameters: {'activation': 'relu', 'solver': 'lbfgs', 'max_iter': 594, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:08:32,158]\u001b[0m Trial 61 finished with value: 0.6774310157850344 and parameters: {'activation': 'relu', 'solver': 'lbfgs', 'max_iter': 348, 'hidden_layer_sizes': (400,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:09:11,377]\u001b[0m Trial 51 finished with value: 0.7167128569707194 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1384, 'hidden_layer_sizes': (200,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:11:19,665]\u001b[0m Trial 57 finished with value: 0.726714061935173 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 594, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:11:30,958]\u001b[0m Trial 59 finished with value: 0.7256295939269791 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 332, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:11:38,054]\u001b[0m Trial 53 finished with value: 0.7293649837329799 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1002, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:14:17,473]\u001b[0m Trial 62 finished with value: 0.7227376792384624 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 331, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:18:01,390]\u001b[0m Trial 58 finished with value: 0.7239426436920111 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1020, 'hidden_layer_sizes': (200,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:18:17,252]\u001b[0m Trial 70 finished with value: 0.33485962164116156 and parameters: {'activation': 'identity', 'solver': 'lbfgs', 'max_iter': 806, 'hidden_layer_sizes': (300,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:24:29,188]\u001b[0m Trial 67 finished with value: 0.7199662609953006 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 794, 'hidden_layer_sizes': (300,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:24:39,682]\u001b[0m Trial 68 finished with value: 0.7244246294734306 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 799, 'hidden_layer_sizes': (300,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:25:01,548]\u001b[0m Trial 63 finished with value: 0.7276780334980119 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 795, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:26:17,244]\u001b[0m Trial 65 finished with value: 0.728401012170141 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 769, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:27:01,905]\u001b[0m Trial 64 finished with value: 0.7259910832630437 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 825, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:27:36,613]\u001b[0m Trial 69 finished with value: 0.7203277503313652 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 788, 'hidden_layer_sizes': (300,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:28:47,032]\u001b[0m Trial 66 finished with value: 0.729244487287625 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 735, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:30:21,658]\u001b[0m Trial 31 finished with value: 0.710929027593686 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 469, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:36:49,325]\u001b[0m Trial 74 finished with value: 0.7247861188094952 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 701, 'hidden_layer_sizes': (500,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:38:11,049]\u001b[0m Trial 75 finished with value: 0.7237016508013013 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 723, 'hidden_layer_sizes': (500,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:40:49,500]\u001b[0m Trial 76 finished with value: 0.7217737076756235 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 889, 'hidden_layer_sizes': (500,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:41:53,018]\u001b[0m Trial 25 finished with value: 0.6965899505964575 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 572, 'hidden_layer_sizes': (1000,), 'learning_rate': 'adaptive'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:42:24,358]\u001b[0m Trial 72 finished with value: 0.7318954090854319 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 888, 'hidden_layer_sizes': (900,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:43:51,695]\u001b[0m Trial 77 finished with value: 0.7228581756838173 and parameters: {'activation': 'logistic', 'solver': 'adam', 'max_iter': 726, 'hidden_layer_sizes': (500,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:47:20,199]\u001b[0m Trial 23 finished with value: 0.7087600915772985 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 634, 'hidden_layer_sizes': (1000,), 'learning_rate': 'adaptive'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:47:38,556]\u001b[0m Trial 78 finished with value: 0.7246656223641402 and parameters: {'activation': 'logistic', 'solver': 'adam', 'max_iter': 902, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:48:55,860]\u001b[0m Trial 86 finished with value: 0.6494758404627063 and parameters: {'activation': 'relu', 'solver': 'lbfgs', 'max_iter': 865, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:49:30,248]\u001b[0m Trial 79 finished with value: 0.7165923605253645 and parameters: {'activation': 'logistic', 'solver': 'adam', 'max_iter': 896, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:52:13,621]\u001b[0m Trial 81 finished with value: 0.6999638510663936 and parameters: {'activation': 'tanh', 'solver': 'adam', 'max_iter': 887, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:52:54,423]\u001b[0m Trial 90 finished with value: 0.4439089046873117 and parameters: {'activation': 'identity', 'solver': 'lbfgs', 'max_iter': 645, 'hidden_layer_sizes': (600,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:53:57,774]\u001b[0m Trial 83 finished with value: 0.64634293288348 and parameters: {'activation': 'logistic', 'solver': 'adam', 'max_iter': 860, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:55:19,996]\u001b[0m Trial 71 finished with value: 0.720568743222075 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1824, 'hidden_layer_sizes': (900,), 'learning_rate': 'adaptive'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 19:56:37,643]\u001b[0m Trial 84 finished with value: 0.6808049162549705 and parameters: {'activation': 'logistic', 'solver': 'adam', 'max_iter': 870, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:01:44,963]\u001b[0m Trial 73 finished with value: 0.729244487287625 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1791, 'hidden_layer_sizes': (900,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:06:47,833]\u001b[0m Trial 85 finished with value: 0.72044824677672 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'max_iter': 952, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:08:02,788]\u001b[0m Trial 80 finished with value: 0.36510422942523196 and parameters: {'activation': 'relu', 'solver': 'sgd', 'max_iter': 904, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:14:43,474]\u001b[0m Trial 89 finished with value: 0.7190022894324617 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'max_iter': 945, 'hidden_layer_sizes': (600,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:18:55,943]\u001b[0m Trial 94 finished with value: 0.7276780334980119 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 746, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:21:28,809]\u001b[0m Trial 87 finished with value: 0.712615977828654 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'max_iter': 1160, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:23:15,481]\u001b[0m Trial 93 finished with value: 0.72490661525485 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 955, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:23:49,428]\u001b[0m Trial 88 finished with value: 0.7193637787685263 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'max_iter': 1188, 'hidden_layer_sizes': (900,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:26:27,893]\u001b[0m Trial 91 finished with value: 0.731051933967948 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1163, 'hidden_layer_sizes': (900,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:00,898]\u001b[0m Trial 92 finished with value: 0.7241836365827208 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1153, 'hidden_layer_sizes': (900,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:10,113]\u001b[0m Trial 82 finished with value: 0.7110495240390409 and parameters: {'activation': 'logistic', 'solver': 'adam', 'max_iter': 864, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:33:58,919]\u001b[0m Trial 96 finished with value: 0.7277985299433667 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1154, 'hidden_layer_sizes': (900,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:37:29,985]\u001b[0m Trial 97 finished with value: 0.7293649837329799 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1998, 'hidden_layer_sizes': (400,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[33m[W 2023-04-21 20:37:40,872]\u001b[0m Trial 18 failed with parameters: {'activation': 'identity', 'solver': 'sgd', 'max_iter': 1023, 'hidden_layer_sizes': (300,), 'learning_rate': 'constant'} because of the following error: ValueError('Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/18/phq_zpjx2pg3yqr73dvmxh_40000gp/T/ipykernel_28740/4273274004.py\", line 11, in objective_neural_network_return\n",
      "    model.fit(X_real_return_train, y_real_return_train)\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 749, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 491, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\u001b[33m[W 2023-04-21 20:37:40,881]\u001b[0m Trial 18 failed with value None.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:39:15,964]\u001b[0m Trial 95 finished with value: 0.72490661525485 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1757, 'hidden_layer_sizes': (900,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:42:42,714]\u001b[0m Trial 98 finished with value: 0.7259910832630437 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1754, 'hidden_layer_sizes': (900,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:44:18,146]\u001b[0m Trial 99 finished with value: 0.7280395228340764 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1996, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 33 with value: 0.7322568984214965.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_neural_network_return, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rede Neural - Real Return\n",
      "Melhor pontuação: 0.7322568984214965\n",
      "Melhores hiperparâmetros: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1471, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'Rede Neural', 'Real Return')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_neural_network_risk(trial):\n",
    "\tparams = {\n",
    "\t\t'activation': trial.suggest_categorical('activation', ['identity', 'logistic', 'tanh', 'relu']),\n",
    "\t\t'solver': trial.suggest_categorical('solver', ['lbfgs', 'sgd', 'adam']),\n",
    "\t\t'max_iter': trial.suggest_int('max_iter', 200, 2000),\n",
    "\t\t'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(100,), (200,), (300,), (400,), (500,), (600,), (700,), (800,), (900,), (1000,)]),\n",
    "\t\t'learning_rate': trial.suggest_categorical('learning_rate', ['constant', 'invscaling', 'adaptive']), \n",
    "\t}\n",
    "\n",
    "\tmodel = MLPClassifier(**params)\n",
    "\tmodel.fit(X_risk_train, y_risk_train)\n",
    "\tpreds = model.predict(X_risk_test)\n",
    "\taccuracy = accuracy_score(y_risk_test, preds)\n",
    "\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 20:44:18,308]\u001b[0m A new study created in memory with name: no-name-0bc2ea2b-3032-43e1-b768-9d72314e5e59\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:48:51,882]\u001b[0m Trial 3 finished with value: 0.4055910350644656 and parameters: {'activation': 'identity', 'solver': 'lbfgs', 'max_iter': 1940, 'hidden_layer_sizes': (700,), 'learning_rate': 'invscaling'}. Best is trial 3 with value: 0.4055910350644656.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:51:39,607]\u001b[0m Trial 9 finished with value: 0.37149054102903967 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 1508, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}. Best is trial 3 with value: 0.4055910350644656.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:54:25,308]\u001b[0m Trial 5 finished with value: 0.376430895288589 and parameters: {'activation': 'identity', 'solver': 'adam', 'max_iter': 727, 'hidden_layer_sizes': (400,), 'learning_rate': 'invscaling'}. Best is trial 3 with value: 0.4055910350644656.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:57:55,743]\u001b[0m Trial 4 finished with value: 0.45692252078563683 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 912, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:58:33,415]\u001b[0m Trial 2 finished with value: 0.4537896132064104 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 923, 'hidden_layer_sizes': (800,), 'learning_rate': 'adaptive'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:58:40,499]\u001b[0m Trial 12 finished with value: 0.4523436558621521 and parameters: {'activation': 'logistic', 'solver': 'adam', 'max_iter': 694, 'hidden_layer_sizes': (400,), 'learning_rate': 'constant'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:01:26,704]\u001b[0m Trial 13 finished with value: 0.33690806121219424 and parameters: {'activation': 'relu', 'solver': 'sgd', 'max_iter': 1830, 'hidden_layer_sizes': (900,), 'learning_rate': 'adaptive'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:01:54,643]\u001b[0m Trial 11 finished with value: 0.4120978431136281 and parameters: {'activation': 'tanh', 'solver': 'sgd', 'max_iter': 1922, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:02:12,292]\u001b[0m Trial 15 finished with value: 0.3428123870345825 and parameters: {'activation': 'relu', 'solver': 'sgd', 'max_iter': 870, 'hidden_layer_sizes': (600,), 'learning_rate': 'adaptive'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:03:20,372]\u001b[0m Trial 1 finished with value: 0.4131823111218219 and parameters: {'activation': 'relu', 'solver': 'lbfgs', 'max_iter': 1320, 'hidden_layer_sizes': (900,), 'learning_rate': 'constant'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:03:49,695]\u001b[0m Trial 18 finished with value: 0.4283648632365345 and parameters: {'activation': 'tanh', 'solver': 'adam', 'max_iter': 321, 'hidden_layer_sizes': (200,), 'learning_rate': 'invscaling'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:04:54,189]\u001b[0m Trial 19 finished with value: 0.42764188456440533 and parameters: {'activation': 'tanh', 'solver': 'adam', 'max_iter': 647, 'hidden_layer_sizes': (600,), 'learning_rate': 'invscaling'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:05:58,241]\u001b[0m Trial 21 finished with value: 0.42282202675021086 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'max_iter': 221, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:09:36,173]\u001b[0m Trial 10 finished with value: 0.4006506808049163 and parameters: {'activation': 'identity', 'solver': 'adam', 'max_iter': 1926, 'hidden_layer_sizes': (800,), 'learning_rate': 'invscaling'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:11:58,101]\u001b[0m Trial 20 finished with value: 0.40836245330762744 and parameters: {'activation': 'logistic', 'solver': 'adam', 'max_iter': 892, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:21:13,257]\u001b[0m Trial 22 finished with value: 0.44884925894686106 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1101, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:24:13,419]\u001b[0m Trial 23 finished with value: 0.44463188335944087 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1158, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 4 with value: 0.45692252078563683.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:24:44,271]\u001b[0m Trial 24 finished with value: 0.45812748523918545 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1120, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 24 with value: 0.45812748523918545.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:25:08,738]\u001b[0m Trial 25 finished with value: 0.45089769851789374 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1089, 'hidden_layer_sizes': (500,), 'learning_rate': 'adaptive'}. Best is trial 24 with value: 0.45812748523918545.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:28:00,133]\u001b[0m Trial 0 finished with value: 0.4233040125316303 and parameters: {'activation': 'relu', 'solver': 'adam', 'max_iter': 824, 'hidden_layer_sizes': (600,), 'learning_rate': 'constant'}. Best is trial 24 with value: 0.45812748523918545.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:34:54,370]\u001b[0m Trial 28 finished with value: 0.45812748523918545 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 477, 'hidden_layer_sizes': (1000,), 'learning_rate': 'adaptive'}. Best is trial 24 with value: 0.45812748523918545.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:37:19,391]\u001b[0m Trial 26 finished with value: 0.4502952162911194 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1164, 'hidden_layer_sizes': (1000,), 'learning_rate': 'adaptive'}. Best is trial 24 with value: 0.45812748523918545.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:38:16,999]\u001b[0m Trial 27 finished with value: 0.4583684781298952 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1094, 'hidden_layer_sizes': (500,), 'learning_rate': 'adaptive'}. Best is trial 27 with value: 0.4583684781298952.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:39:24,762]\u001b[0m Trial 31 finished with value: 0.4430654295698277 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 482, 'hidden_layer_sizes': (1000,), 'learning_rate': 'constant'}. Best is trial 27 with value: 0.4583684781298952.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:42:32,996]\u001b[0m Trial 33 finished with value: 0.44282443667911797 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 459, 'hidden_layer_sizes': (300,), 'learning_rate': 'constant'}. Best is trial 27 with value: 0.4583684781298952.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:43:51,245]\u001b[0m Trial 30 finished with value: 0.45403060609712015 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1455, 'hidden_layer_sizes': (300,), 'learning_rate': 'constant'}. Best is trial 27 with value: 0.4583684781298952.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:44:50,274]\u001b[0m Trial 32 finished with value: 0.450656705627184 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 447, 'hidden_layer_sizes': (1000,), 'learning_rate': 'constant'}. Best is trial 27 with value: 0.4583684781298952.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:45:09,616]\u001b[0m Trial 34 finished with value: 0.45427159898782987 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 509, 'hidden_layer_sizes': (500,), 'learning_rate': 'adaptive'}. Best is trial 27 with value: 0.4583684781298952.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:48:31,338]\u001b[0m Trial 29 finished with value: 0.45113869140860346 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1601, 'hidden_layer_sizes': (500,), 'learning_rate': 'constant'}. Best is trial 27 with value: 0.4583684781298952.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:50:25,753]\u001b[0m Trial 40 finished with value: 0.33594408964935535 and parameters: {'activation': 'identity', 'solver': 'lbfgs', 'max_iter': 1299, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive'}. Best is trial 27 with value: 0.4583684781298952.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:50:30,536]\u001b[0m Trial 39 finished with value: 0.3719725268104591 and parameters: {'activation': 'identity', 'solver': 'lbfgs', 'max_iter': 1699, 'hidden_layer_sizes': (500,), 'learning_rate': 'adaptive'}. Best is trial 27 with value: 0.4583684781298952.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 21:54:27,805]\u001b[0m Trial 35 finished with value: 0.4618628750451862 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1415, 'hidden_layer_sizes': (300,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:00:15,814]\u001b[0m Trial 6 finished with value: 0.43210025304253524 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 1228, 'hidden_layer_sizes': (600,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:02:40,944]\u001b[0m Trial 37 finished with value: 0.4484877696107965 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1510, 'hidden_layer_sizes': (500,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:02:47,069]\u001b[0m Trial 36 finished with value: 0.4564405350042174 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1574, 'hidden_layer_sizes': (500,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:05:30,098]\u001b[0m Trial 38 finished with value: 0.4458368478129895 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1639, 'hidden_layer_sizes': (500,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:05:35,449]\u001b[0m Trial 46 finished with value: 0.38221472466562234 and parameters: {'activation': 'relu', 'solver': 'lbfgs', 'max_iter': 1396, 'hidden_layer_sizes': (300,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:05:51,770]\u001b[0m Trial 42 finished with value: 0.45089769851789374 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1028, 'hidden_layer_sizes': (700,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:06:50,111]\u001b[0m Trial 48 finished with value: 0.40450656705627186 and parameters: {'activation': 'relu', 'solver': 'lbfgs', 'max_iter': 981, 'hidden_layer_sizes': (300,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:07:58,839]\u001b[0m Trial 44 finished with value: 0.4005301843595614 and parameters: {'activation': 'relu', 'solver': 'lbfgs', 'max_iter': 1019, 'hidden_layer_sizes': (300,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:09:29,531]\u001b[0m Trial 43 finished with value: 0.45909145680202434 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1364, 'hidden_layer_sizes': (300,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:13:20,516]\u001b[0m Trial 45 finished with value: 0.4172791902638872 and parameters: {'activation': 'relu', 'solver': 'lbfgs', 'max_iter': 993, 'hidden_layer_sizes': (300,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:19:04,869]\u001b[0m Trial 47 finished with value: 0.4140257862393059 and parameters: {'activation': 'relu', 'solver': 'lbfgs', 'max_iter': 1006, 'hidden_layer_sizes': (300,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:22:11,890]\u001b[0m Trial 41 finished with value: 0.3402819616821304 and parameters: {'activation': 'relu', 'solver': 'sgd', 'max_iter': 1004, 'hidden_layer_sizes': (500,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:24:18,651]\u001b[0m Trial 50 finished with value: 0.4427039402337631 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 793, 'hidden_layer_sizes': (1000,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:27:57,755]\u001b[0m Trial 49 finished with value: 0.4125798288950476 and parameters: {'activation': 'relu', 'solver': 'lbfgs', 'max_iter': 983, 'hidden_layer_sizes': (1000,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:38:35,630]\u001b[0m Trial 53 finished with value: 0.44149897578021446 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1315, 'hidden_layer_sizes': (900,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:38:39,076]\u001b[0m Trial 52 finished with value: 0.4419809615616339 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1326, 'hidden_layer_sizes': (1000,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:39:31,631]\u001b[0m Trial 59 finished with value: 0.3585974213760694 and parameters: {'activation': 'identity', 'solver': 'sgd', 'max_iter': 1768, 'hidden_layer_sizes': (400,), 'learning_rate': 'invscaling'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:40:53,516]\u001b[0m Trial 57 finished with value: 0.41908663694421017 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 1344, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:41:52,346]\u001b[0m Trial 58 finished with value: 0.3681166405591035 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 1242, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:43:35,483]\u001b[0m Trial 61 finished with value: 0.41486926135679 and parameters: {'activation': 'tanh', 'solver': 'adam', 'max_iter': 1243, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:44:18,383]\u001b[0m Trial 60 finished with value: 0.4367996144113749 and parameters: {'activation': 'logistic', 'solver': 'adam', 'max_iter': 1248, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:44:42,394]\u001b[0m Trial 55 finished with value: 0.45089769851789374 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1306, 'hidden_layer_sizes': (900,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:45:33,400]\u001b[0m Trial 56 finished with value: 0.453307627424991 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1288, 'hidden_layer_sizes': (900,), 'learning_rate': 'invscaling'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:48:15,569]\u001b[0m Trial 17 finished with value: 0.4327027352693096 and parameters: {'activation': 'tanh', 'solver': 'sgd', 'max_iter': 1620, 'hidden_layer_sizes': (900,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:54:29,579]\u001b[0m Trial 66 finished with value: 0.45306663453428125 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 582, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:54:49,045]\u001b[0m Trial 62 finished with value: 0.42101458006988796 and parameters: {'activation': 'tanh', 'solver': 'adam', 'max_iter': 606, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:55:23,600]\u001b[0m Trial 63 finished with value: 0.450656705627184 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 798, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:56:14,423]\u001b[0m Trial 64 finished with value: 0.4400530184359561 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 786, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:56:38,870]\u001b[0m Trial 65 finished with value: 0.4525846487528618 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 785, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 22:57:38,826]\u001b[0m Trial 67 finished with value: 0.44668032293047355 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 589, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:10:15,555]\u001b[0m Trial 68 finished with value: 0.45053620918182913 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 833, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:11:06,724]\u001b[0m Trial 69 finished with value: 0.45619954211350766 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 841, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[33m[W 2023-04-21 23:17:21,917]\u001b[0m Trial 8 failed with parameters: {'activation': 'identity', 'solver': 'sgd', 'max_iter': 928, 'hidden_layer_sizes': (300,), 'learning_rate': 'constant'} because of the following error: ValueError('Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/18/phq_zpjx2pg3yqr73dvmxh_40000gp/T/ipykernel_28740/4149990182.py\", line 11, in objective_neural_network_risk\n",
      "    model.fit(X_risk_train, y_risk_train)\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 749, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 491, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\u001b[33m[W 2023-04-21 23:17:21,923]\u001b[0m Trial 8 failed with value None.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:18:37,313]\u001b[0m Trial 70 finished with value: 0.4523436558621521 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1163, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:18:49,815]\u001b[0m Trial 71 finished with value: 0.4555970598867333 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1128, 'hidden_layer_sizes': (800,), 'learning_rate': 'constant'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:24:53,333]\u001b[0m Trial 72 finished with value: 0.44993372695505485 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1548, 'hidden_layer_sizes': (800,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:25:08,264]\u001b[0m Trial 73 finished with value: 0.4484877696107965 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1543, 'hidden_layer_sizes': (800,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:30:17,831]\u001b[0m Trial 74 finished with value: 0.44872876250150623 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1546, 'hidden_layer_sizes': (600,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[33m[W 2023-04-21 23:30:35,391]\u001b[0m Trial 14 failed with parameters: {'activation': 'identity', 'solver': 'sgd', 'max_iter': 629, 'hidden_layer_sizes': (600,), 'learning_rate': 'constant'} because of the following error: ValueError('Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/18/phq_zpjx2pg3yqr73dvmxh_40000gp/T/ipykernel_28740/4149990182.py\", line 11, in objective_neural_network_risk\n",
      "    model.fit(X_risk_train, y_risk_train)\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 749, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 491, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\u001b[33m[W 2023-04-21 23:30:35,392]\u001b[0m Trial 14 failed with value None.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:30:44,071]\u001b[0m Trial 75 finished with value: 0.45198216652608747 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'max_iter': 1539, 'hidden_layer_sizes': (600,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:31:39,675]\u001b[0m Trial 51 finished with value: 0.43752259308350405 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 1312, 'hidden_layer_sizes': (1000,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:31:50,937]\u001b[0m Trial 54 finished with value: 0.43740209663814916 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'max_iter': 1310, 'hidden_layer_sizes': (900,), 'learning_rate': 'adaptive'}. Best is trial 35 with value: 0.4618628750451862.\u001b[0m\n",
      "\u001b[33m[W 2023-04-21 23:34:04,441]\u001b[0m Trial 16 failed with parameters: {'activation': 'identity', 'solver': 'sgd', 'max_iter': 1615, 'hidden_layer_sizes': (700,), 'learning_rate': 'constant'} because of the following error: ValueError('Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/18/phq_zpjx2pg3yqr73dvmxh_40000gp/T/ipykernel_28740/4149990182.py\", line 11, in objective_neural_network_risk\n",
      "    model.fit(X_risk_train, y_risk_train)\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 749, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 491, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\u001b[33m[W 2023-04-21 23:34:04,442]\u001b[0m Trial 16 failed with value None.\u001b[0m\n",
      "\u001b[33m[W 2023-04-21 23:34:12,494]\u001b[0m Trial 7 failed with parameters: {'activation': 'identity', 'solver': 'sgd', 'max_iter': 1728, 'hidden_layer_sizes': (700,), 'learning_rate': 'adaptive'} because of the following error: ValueError('Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/18/phq_zpjx2pg3yqr73dvmxh_40000gp/T/ipykernel_28740/4149990182.py\", line 11, in objective_neural_network_risk\n",
      "    model.fit(X_risk_train, y_risk_train)\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 749, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 491, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\u001b[33m[W 2023-04-21 23:34:12,495]\u001b[0m Trial 7 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective_neural_network_risk, n_trials\u001b[39m=\u001b[39;49mN_TRIALS, n_jobs\u001b[39m=\u001b[39;49mN_JOBS)\n",
      "File \u001b[0;32m~/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     _optimize(\n\u001b[1;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    435\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/optuna/study/_optimize.py:103\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[39m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m                     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m completed:\n\u001b[0;32m--> 103\u001b[0m                         f\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    105\u001b[0m                 futures\u001b[39m.\u001b[39madd(\n\u001b[1;32m    106\u001b[0m                     executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m    107\u001b[0m                         _optimize_sequential,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m                     )\n\u001b[1;32m    119\u001b[0m                 )\n\u001b[1;32m    120\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/pyenv/versions/3.9.9/lib/python3.9/concurrent/futures/_base.py:438\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    437\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/pyenv/versions/3.9.9/lib/python3.9/concurrent/futures/_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    389\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    391\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pyenv/versions/3.9.9/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[48], line 11\u001b[0m, in \u001b[0;36mobjective_neural_network_risk\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      2\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m \t\u001b[39m'\u001b[39m\u001b[39mactivation\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_categorical(\u001b[39m'\u001b[39m\u001b[39mactivation\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m'\u001b[39m\u001b[39midentity\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlogistic\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtanh\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m      4\u001b[0m \t\u001b[39m'\u001b[39m\u001b[39msolver\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_categorical(\u001b[39m'\u001b[39m\u001b[39msolver\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msgd\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \t\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_categorical(\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minvscaling\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39madaptive\u001b[39m\u001b[39m'\u001b[39m]), \n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m model \u001b[39m=\u001b[39m MLPClassifier(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m---> 11\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_risk_train, y_risk_train)\n\u001b[1;32m     12\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_risk_test)\n\u001b[1;32m     13\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_risk_test, preds)\n",
      "File \u001b[0;32m~/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:749\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \n\u001b[1;32m    733\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[39m    Returns a trained MLP model.\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 749\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, incremental\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:491\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    489\u001b[0m weights \u001b[39m=\u001b[39m chain(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoefs_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercepts_)\n\u001b[1;32m    490\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(np\u001b[39m.\u001b[39misfinite(w)\u001b[39m.\u001b[39mall() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m weights):\n\u001b[0;32m--> 491\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    492\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSolver produced non-finite parameter weights. The input data may\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    493\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m contain large values and need to be preprocessed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    494\u001b[0m     )\n\u001b[1;32m    496\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed."
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_neural_network_risk, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_best_result(study, 'Rede Neural', 'Risk')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logistica"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_logistic_regression_return(trial):\n",
    "    params = {\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l2']),\n",
    "        'C':trial.suggest_float('C', 1, 100),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']),\n",
    "        'max_iter': trial.suggest_int('max_iter', 100, 10000),\n",
    "        'n_jobs': N_JOBS\n",
    "\n",
    "\t}\n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(X_real_return_train, y_real_return_train)\n",
    "    preds = model.predict(X_real_return_test)\n",
    "    accuracy = accuracy_score(y_real_return_test, preds)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-22 01:15:52,001]\u001b[0m A new study created in memory with name: no-name-33d91aac-bc0f-48fd-b75e-6efb86872be6\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #6. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #6. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #6. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #8. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #8. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:16:04,426]\u001b[0m Trial 0 finished with value: 0.7127364742740089 and parameters: {'penalty': 'l2', 'C': 43.76093989363369, 'class_weight': 'balanced', 'solver': 'lbfgs', 'max_iter': 685}. Best is trial 0 with value: 0.7127364742740089.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[32m[I 2023-04-22 01:16:10,159]\u001b[0m Trial 4 finished with value: 0.8084106518857693 and parameters: {'penalty': 'l2', 'C': 74.2559224950879, 'class_weight': 'balanced', 'solver': 'newton-cholesky', 'max_iter': 2768}. Best is trial 4 with value: 0.8084106518857693.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[32m[I 2023-04-22 01:16:11,244]\u001b[0m Trial 11 finished with value: 0.8086516447764791 and parameters: {'penalty': 'l2', 'C': 23.27722909646627, 'class_weight': 'balanced', 'solver': 'newton-cholesky', 'max_iter': 3059}. Best is trial 11 with value: 0.8086516447764791.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[32m[I 2023-04-22 01:16:15,265]\u001b[0m Trial 10 finished with value: 0.8091336305578986 and parameters: {'penalty': 'l2', 'C': 17.3871025160825, 'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 4128}. Best is trial 10 with value: 0.8091336305578986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:16:47,909]\u001b[0m Trial 5 finished with value: 0.7275575370526569 and parameters: {'penalty': 'l2', 'C': 23.575938386048865, 'class_weight': 'balanced', 'solver': 'lbfgs', 'max_iter': 6801}. Best is trial 10 with value: 0.8091336305578986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #6. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #8. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[32m[I 2023-04-22 01:17:05,719]\u001b[0m Trial 16 finished with value: 0.8116640559103506 and parameters: {'penalty': 'l2', 'C': 77.17370862095854, 'class_weight': 'balanced', 'solver': 'newton-cholesky', 'max_iter': 5633}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:17:05,957]\u001b[0m Trial 2 finished with value: 0.7428605856127244 and parameters: {'penalty': 'l2', 'C': 29.65662159754782, 'class_weight': None, 'solver': 'lbfgs', 'max_iter': 9413}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:17:22,644]\u001b[0m Trial 1 finished with value: 0.710085552476202 and parameters: {'penalty': 'l2', 'C': 47.45977742587616, 'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 9924}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:17:23,209]\u001b[0m Trial 3 finished with value: 0.710085552476202 and parameters: {'penalty': 'l2', 'C': 58.71410151914689, 'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 9530}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:17:23,569]\u001b[0m Trial 8 finished with value: 0.710085552476202 and parameters: {'penalty': 'l2', 'C': 56.77009503045765, 'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 7845}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:17:29,802]\u001b[0m Trial 7 finished with value: 0.7600915772984697 and parameters: {'penalty': 'l2', 'C': 66.47367748649123, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2776}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #6. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-22 01:17:35,719]\u001b[0m Trial 14 finished with value: 0.7068321484516207 and parameters: {'penalty': 'l2', 'C': 37.901886608932706, 'class_weight': None, 'solver': 'saga', 'max_iter': 7728}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:17:35,722]\u001b[0m Trial 13 finished with value: 0.710085552476202 and parameters: {'penalty': 'l2', 'C': 9.382657791076314, 'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 8323}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #6. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-22 01:17:37,302]\u001b[0m Trial 19 finished with value: 0.705747680443427 and parameters: {'penalty': 'l2', 'C': 76.74131709321323, 'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 508}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #6. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-22 01:17:39,284]\u001b[0m Trial 15 finished with value: 0.7068321484516207 and parameters: {'penalty': 'l2', 'C': 98.73858212891392, 'class_weight': None, 'solver': 'saga', 'max_iter': 7817}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[32m[I 2023-04-22 01:17:47,266]\u001b[0m Trial 22 finished with value: 0.8107000843475117 and parameters: {'penalty': 'l2', 'C': 2.4152490567969522, 'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 5548}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[32m[I 2023-04-22 01:17:53,399]\u001b[0m Trial 23 finished with value: 0.8111820701289312 and parameters: {'penalty': 'l2', 'C': 93.70120078963777, 'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 5409}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:17:54,104]\u001b[0m Trial 25 finished with value: 0.8110615736835763 and parameters: {'penalty': 'l2', 'C': 98.2507885152624, 'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 5173}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:18:10,702]\u001b[0m Trial 9 finished with value: 0.7690083142547295 and parameters: {'penalty': 'l2', 'C': 35.1234266659655, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 3618}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:18:13,119]\u001b[0m Trial 20 finished with value: 0.7604530666345343 and parameters: {'penalty': 'l2', 'C': 56.05618765483929, 'class_weight': 'balanced', 'solver': 'lbfgs', 'max_iter': 7727}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "\u001b[32m[I 2023-04-22 01:18:24,334]\u001b[0m Trial 17 finished with value: 0.7068321484516207 and parameters: {'penalty': 'l2', 'C': 42.98353935270296, 'class_weight': None, 'solver': 'saga', 'max_iter': 5374}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "\u001b[32m[I 2023-04-22 01:18:34,141]\u001b[0m Trial 12 finished with value: 0.7116520062658152 and parameters: {'penalty': 'l2', 'C': 69.8379421091788, 'class_weight': 'balanced', 'solver': 'sag', 'max_iter': 6545}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "\u001b[32m[I 2023-04-22 01:19:17,591]\u001b[0m Trial 21 finished with value: 0.7086395951319436 and parameters: {'penalty': 'l2', 'C': 97.02931357609451, 'class_weight': None, 'solver': 'sag', 'max_iter': 6112}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:19:22,131]\u001b[0m Trial 18 finished with value: 0.7732256898421497 and parameters: {'penalty': 'l2', 'C': 91.54793239410358, 'class_weight': None, 'solver': 'liblinear', 'max_iter': 3753}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:19:28,201]\u001b[0m Trial 24 finished with value: 0.7086395951319436 and parameters: {'penalty': 'l2', 'C': 90.05285205144213, 'class_weight': None, 'solver': 'sag', 'max_iter': 5300}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:19:39,084]\u001b[0m Trial 27 finished with value: 0.7087600915772985 and parameters: {'penalty': 'l2', 'C': 2.1817925645706118, 'class_weight': None, 'solver': 'sag', 'max_iter': 5648}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:19:46,672]\u001b[0m Trial 29 finished with value: 0.7086395951319436 and parameters: {'penalty': 'l2', 'C': 84.85036272139978, 'class_weight': None, 'solver': 'sag', 'max_iter': 5948}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "\u001b[32m[I 2023-04-22 01:20:06,774]\u001b[0m Trial 30 finished with value: 0.7087600915772985 and parameters: {'penalty': 'l2', 'C': 88.02129438507352, 'class_weight': None, 'solver': 'sag', 'max_iter': 6243}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:20:15,103]\u001b[0m Trial 31 finished with value: 0.7087600915772985 and parameters: {'penalty': 'l2', 'C': 86.23097390008111, 'class_weight': None, 'solver': 'sag', 'max_iter': 6219}. Best is trial 16 with value: 0.8116640559103506.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:22:50,136]\u001b[0m Trial 6 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 56.967789206689766, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 6121}. Best is trial 6 with value: 0.8202193035305458.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:23:05,237]\u001b[0m Trial 26 finished with value: 0.8208217857573201 and parameters: {'penalty': 'l2', 'C': 8.82516085005323, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 5411}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:24:52,512]\u001b[0m Trial 28 finished with value: 0.8199783106398362 and parameters: {'penalty': 'l2', 'C': 93.9347507616544, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 5813}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:25:14,169]\u001b[0m Trial 33 finished with value: 0.8199783106398362 and parameters: {'penalty': 'l2', 'C': 98.54530510274982, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 4809}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:25:53,189]\u001b[0m Trial 34 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 84.77495740922912, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 4486}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:26:21,501]\u001b[0m Trial 35 finished with value: 0.8199783106398362 and parameters: {'penalty': 'l2', 'C': 85.94562898962329, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 4372}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:26:24,122]\u001b[0m Trial 32 finished with value: 0.8199783106398362 and parameters: {'penalty': 'l2', 'C': 97.69232127433482, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 6254}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:26:30,247]\u001b[0m Trial 38 finished with value: 0.8199783106398362 and parameters: {'penalty': 'l2', 'C': 81.17180261541104, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 4478}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:27:24,855]\u001b[0m Trial 40 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 80.81720796931138, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 4449}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:27:33,933]\u001b[0m Trial 39 finished with value: 0.8199783106398362 and parameters: {'penalty': 'l2', 'C': 81.19986319084391, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 4523}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:28:12,250]\u001b[0m Trial 37 finished with value: 0.8199783106398362 and parameters: {'penalty': 'l2', 'C': 83.41317985947916, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 4404}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:28:29,219]\u001b[0m Trial 36 finished with value: 0.8199783106398362 and parameters: {'penalty': 'l2', 'C': 84.05918868628692, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 4407}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:29:20,739]\u001b[0m Trial 42 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 81.3959054229699, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 4487}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:29:48,094]\u001b[0m Trial 41 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 78.84009447098144, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 4503}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:31:15,668]\u001b[0m Trial 43 finished with value: 0.8203397999759007 and parameters: {'penalty': 'l2', 'C': 78.30565163836269, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 4485}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:31:30,153]\u001b[0m Trial 45 finished with value: 0.8198578141944812 and parameters: {'penalty': 'l2', 'C': 47.064113901636034, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 1475}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:33:15,703]\u001b[0m Trial 50 finished with value: 0.8203397999759007 and parameters: {'penalty': 'l2', 'C': 63.91477217771374, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 1532}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:33:19,526]\u001b[0m Trial 44 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 51.43834104054986, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 4473}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:33:32,197]\u001b[0m Trial 58 finished with value: 0.6941800216893602 and parameters: {'penalty': 'l2', 'C': 64.63259864548603, 'class_weight': 'balanced', 'solver': 'lbfgs', 'max_iter': 1671}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:33:35,963]\u001b[0m Trial 49 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 64.57165379498662, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 1279}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:33:38,996]\u001b[0m Trial 47 finished with value: 0.8199783106398362 and parameters: {'penalty': 'l2', 'C': 46.320328667207015, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 6938}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:33:51,636]\u001b[0m Trial 48 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 46.78371123718766, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 1470}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:34:07,701]\u001b[0m Trial 51 finished with value: 0.8203397999759007 and parameters: {'penalty': 'l2', 'C': 63.70161708326948, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 2093}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:34:22,677]\u001b[0m Trial 46 finished with value: 0.8199783106398362 and parameters: {'penalty': 'l2', 'C': 49.56200660476512, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 4622}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:34:26,377]\u001b[0m Trial 52 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 63.56385241002103, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 1663}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:35:49,369]\u001b[0m Trial 54 finished with value: 0.8203397999759007 and parameters: {'penalty': 'l2', 'C': 62.97640303667815, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 7047}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:36:08,030]\u001b[0m Trial 53 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 63.9249613510094, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 1919}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:36:10,102]\u001b[0m Trial 61 finished with value: 0.7888902277382818 and parameters: {'penalty': 'l2', 'C': 72.14510179681007, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2603}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:36:53,343]\u001b[0m Trial 56 finished with value: 0.8205807928666105 and parameters: {'penalty': 'l2', 'C': 70.47744846120767, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 7036}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:36:55,606]\u001b[0m Trial 69 finished with value: 0.7115315098204603 and parameters: {'penalty': 'l2', 'C': 69.3284404688459, 'class_weight': 'balanced', 'solver': 'lbfgs', 'max_iter': 165}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:37:01,026]\u001b[0m Trial 60 finished with value: 0.7770815760935053 and parameters: {'penalty': 'l2', 'C': 71.62800743797246, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2469}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:37:02,867]\u001b[0m Trial 68 finished with value: 0.7331003735389806 and parameters: {'penalty': 'l2', 'C': 59.055378912942984, 'class_weight': 'balanced', 'solver': 'lbfgs', 'max_iter': 7145}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:37:10,191]\u001b[0m Trial 65 finished with value: 0.7529822870225328 and parameters: {'penalty': 'l2', 'C': 68.79173077386207, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2248}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:37:17,388]\u001b[0m Trial 64 finished with value: 0.797324978913122 and parameters: {'penalty': 'l2', 'C': 70.00842837802952, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2665}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:37:21,383]\u001b[0m Trial 63 finished with value: 0.7653934208940836 and parameters: {'penalty': 'l2', 'C': 74.0269095792754, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2342}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "\u001b[32m[I 2023-04-22 01:38:24,532]\u001b[0m Trial 67 finished with value: 0.7888902277382818 and parameters: {'penalty': 'l2', 'C': 60.41643994613192, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 7061}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "\u001b[32m[I 2023-04-22 01:38:48,873]\u001b[0m Trial 66 finished with value: 0.7873237739486685 and parameters: {'penalty': 'l2', 'C': 71.93962587519174, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 7180}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:39:37,056]\u001b[0m Trial 55 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 69.49814247982611, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 1295}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:39:53,184]\u001b[0m Trial 59 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 71.83765119313023, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 7134}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:40:07,296]\u001b[0m Trial 70 finished with value: 0.778166044101699 and parameters: {'penalty': 'l2', 'C': 60.699912923229654, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 8711}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:40:14,464]\u001b[0m Trial 57 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 65.28937740251924, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 1970}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:41:13,381]\u001b[0m Trial 62 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 71.74597578636785, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 3126}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:41:14,878]\u001b[0m Trial 72 finished with value: 0.8208217857573201 and parameters: {'penalty': 'l2', 'C': 75.2627061661406, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 8642}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:41:36,899]\u001b[0m Trial 81 finished with value: 0.710085552476202 and parameters: {'penalty': 'l2', 'C': 54.65711612295648, 'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 6465}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:42:59,208]\u001b[0m Trial 71 finished with value: 0.8205807928666105 and parameters: {'penalty': 'l2', 'C': 60.20875128969549, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 8731}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:43:43,129]\u001b[0m Trial 75 finished with value: 0.8203397999759007 and parameters: {'penalty': 'l2', 'C': 59.3249570758316, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 8683}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:44:05,922]\u001b[0m Trial 73 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 59.68474144292424, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 8488}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:44:15,804]\u001b[0m Trial 74 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 61.11835555549325, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 7351}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:44:42,101]\u001b[0m Trial 77 finished with value: 0.8203397999759007 and parameters: {'penalty': 'l2', 'C': 55.06553617998246, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 8558}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:45:29,181]\u001b[0m Trial 83 finished with value: 0.8208217857573201 and parameters: {'penalty': 'l2', 'C': 56.007120694781044, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9982}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:46:36,352]\u001b[0m Trial 79 finished with value: 0.8203397999759007 and parameters: {'penalty': 'l2', 'C': 53.908551625232526, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 8785}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #6. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:47:02,797]\u001b[0m Trial 76 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 54.95594227266251, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 8688}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #8. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:47:05,536]\u001b[0m Trial 78 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 56.78727549316945, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 8735}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #6. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:47:25,806]\u001b[0m Trial 80 finished with value: 0.8203397999759007 and parameters: {'penalty': 'l2', 'C': 53.510959514265735, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 6636}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #8. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #6. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-22 01:47:26,791]\u001b[0m Trial 91 finished with value: 0.8099771056753826 and parameters: {'penalty': 'l2', 'C': 67.15316929987566, 'class_weight': 'balanced', 'solver': 'newton-cholesky', 'max_iter': 9655}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #8. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[32m[I 2023-04-22 01:47:46,700]\u001b[0m Trial 93 finished with value: 0.8102180985660923 and parameters: {'penalty': 'l2', 'C': 77.08885213616686, 'class_weight': 'balanced', 'solver': 'newton-cholesky', 'max_iter': 9607}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[32m[I 2023-04-22 01:48:00,960]\u001b[0m Trial 94 finished with value: 0.8100976021207374 and parameters: {'penalty': 'l2', 'C': 67.08243300564604, 'class_weight': 'balanced', 'solver': 'newton-cholesky', 'max_iter': 9502}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:49:14,278]\u001b[0m Trial 82 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 75.75369380070684, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 6616}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:50:19,109]\u001b[0m Trial 84 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 75.74414921269688, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9975}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:50:28,297]\u001b[0m Trial 87 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 75.2756032931351, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9729}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:50:58,058]\u001b[0m Trial 86 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 76.6914611122224, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9531}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:51:05,399]\u001b[0m Trial 88 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 75.25088372343983, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9989}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:51:19,226]\u001b[0m Trial 85 finished with value: 0.8203397999759007 and parameters: {'penalty': 'l2', 'C': 75.80563752859845, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9550}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:51:45,112]\u001b[0m Trial 90 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 66.67074177612726, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9881}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:52:14,466]\u001b[0m Trial 89 finished with value: 0.8203397999759007 and parameters: {'penalty': 'l2', 'C': 74.54231580033026, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9286}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:53:01,085]\u001b[0m Trial 96 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 66.923465947805, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9283}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:53:19,156]\u001b[0m Trial 97 finished with value: 0.8203397999759007 and parameters: {'penalty': 'l2', 'C': 75.33210421749742, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9160}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:53:21,816]\u001b[0m Trial 92 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 66.63971866089858, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9739}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:53:42,816]\u001b[0m Trial 95 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 75.63012649961263, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9110}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:54:00,023]\u001b[0m Trial 98 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 62.11358231288674, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 8094}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:54:24,742]\u001b[0m Trial 99 finished with value: 0.8202193035305458 and parameters: {'penalty': 'l2', 'C': 67.0969107249809, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9102}. Best is trial 26 with value: 0.8208217857573201.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_logistic_regression_return, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Real Return\n",
      "Melhor pontuação: 0.8208217857573201\n",
      "Melhores hiperparâmetros: {'penalty': 'l2', 'C': 8.82516085005323, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 5411}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'Logistic Regression', 'Real Return')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_logistic_regression_risk(trial):\n",
    "    params = {\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l2']),\n",
    "        'C':trial.suggest_float('C', 1, 100),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']),\n",
    "        'max_iter': trial.suggest_int('max_iter', 100, 10000),\n",
    "        'n_jobs': N_JOBS\n",
    "\n",
    "\t}\n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(X_risk_train, y_risk_train)\n",
    "    preds = model.predict(X_risk_test)\n",
    "    accuracy = accuracy_score(y_risk_test, preds)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-22 01:54:24,919]\u001b[0m A new study created in memory with name: no-name-32e50b4d-440c-425b-b0c5-318054062d60\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:54:25,203]\u001b[0m Trial 0 finished with value: 0.40426557416556214 and parameters: {'penalty': 'l2', 'C': 4.327319582199049, 'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 7696}. Best is trial 0 with value: 0.40426557416556214.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:54:25,267]\u001b[0m Trial 8 finished with value: 0.4040245812748524 and parameters: {'penalty': 'l2', 'C': 33.78414884741859, 'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 399}. Best is trial 0 with value: 0.40426557416556214.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:54:25,318]\u001b[0m Trial 12 finished with value: 0.4040245812748524 and parameters: {'penalty': 'l2', 'C': 32.2822339929061, 'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 7981}. Best is trial 0 with value: 0.40426557416556214.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:54:25,329]\u001b[0m Trial 10 finished with value: 0.4182431618267261 and parameters: {'penalty': 'l2', 'C': 15.138944585252398, 'class_weight': 'balanced', 'solver': 'newton-cholesky', 'max_iter': 8147}. Best is trial 10 with value: 0.4182431618267261.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:54:31,654]\u001b[0m Trial 4 finished with value: 0.425352452102663 and parameters: {'penalty': 'l2', 'C': 82.28298152024324, 'class_weight': 'balanced', 'solver': 'lbfgs', 'max_iter': 906}. Best is trial 4 with value: 0.425352452102663.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:54:37,920]\u001b[0m Trial 7 finished with value: 0.37847933485962165 and parameters: {'penalty': 'l2', 'C': 37.497748562909734, 'class_weight': None, 'solver': 'saga', 'max_iter': 506}. Best is trial 4 with value: 0.425352452102663.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:54:38,029]\u001b[0m Trial 17 finished with value: 0.4040245812748524 and parameters: {'penalty': 'l2', 'C': 78.2958992809479, 'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 3145}. Best is trial 4 with value: 0.425352452102663.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:54:41,326]\u001b[0m Trial 9 finished with value: 0.42065309073382334 and parameters: {'penalty': 'l2', 'C': 19.596966257024977, 'class_weight': 'balanced', 'solver': 'lbfgs', 'max_iter': 2494}. Best is trial 4 with value: 0.425352452102663.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:55:02,125]\u001b[0m Trial 2 finished with value: 0.4284853596818894 and parameters: {'penalty': 'l2', 'C': 84.44376448030559, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 4582}. Best is trial 2 with value: 0.4284853596818894.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:55:03,648]\u001b[0m Trial 16 finished with value: 0.43246174237859986 and parameters: {'penalty': 'l2', 'C': 12.784017261261628, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2936}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:55:08,815]\u001b[0m Trial 6 finished with value: 0.4151102542474997 and parameters: {'penalty': 'l2', 'C': 78.88220595325964, 'class_weight': None, 'solver': 'liblinear', 'max_iter': 6992}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:55:09,994]\u001b[0m Trial 14 finished with value: 0.425352452102663 and parameters: {'penalty': 'l2', 'C': 95.68538862865535, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2403}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:55:31,917]\u001b[0m Trial 21 finished with value: 0.4293288347993734 and parameters: {'penalty': 'l2', 'C': 60.409361618301034, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 5712}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "\u001b[32m[I 2023-04-22 01:55:43,482]\u001b[0m Trial 22 finished with value: 0.41788167249066155 and parameters: {'penalty': 'l2', 'C': 99.74522307147174, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 4999}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:55:51,643]\u001b[0m Trial 1 finished with value: 0.386070610916978 and parameters: {'penalty': 'l2', 'C': 37.463318785427816, 'class_weight': 'balanced', 'solver': 'sag', 'max_iter': 3981}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:55:55,332]\u001b[0m Trial 13 finished with value: 0.3871550789251717 and parameters: {'penalty': 'l2', 'C': 79.96959599840496, 'class_weight': 'balanced', 'solver': 'sag', 'max_iter': 4147}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:56:02,684]\u001b[0m Trial 18 finished with value: 0.42703940233763105 and parameters: {'penalty': 'l2', 'C': 65.15351328668233, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 5689}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:56:24,062]\u001b[0m Trial 3 finished with value: 0.41366429690324136 and parameters: {'penalty': 'l2', 'C': 48.663058089617486, 'class_weight': None, 'solver': 'newton-cg', 'max_iter': 720}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:56:29,936]\u001b[0m Trial 11 finished with value: 0.38414266779130013 and parameters: {'penalty': 'l2', 'C': 85.45095309502379, 'class_weight': None, 'solver': 'sag', 'max_iter': 5756}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:56:40,105]\u001b[0m Trial 28 finished with value: 0.4186046511627907 and parameters: {'penalty': 'l2', 'C': 55.07192710013129, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 9392}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:57:03,464]\u001b[0m Trial 23 finished with value: 0.38980600072297866 and parameters: {'penalty': 'l2', 'C': 57.07707514033649, 'class_weight': 'balanced', 'solver': 'sag', 'max_iter': 5258}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:57:05,508]\u001b[0m Trial 29 finished with value: 0.4236655018676949 and parameters: {'penalty': 'l2', 'C': 53.23909678586421, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 6104}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:57:07,700]\u001b[0m Trial 5 finished with value: 0.3882395469333655 and parameters: {'penalty': 'l2', 'C': 94.42911622231566, 'class_weight': None, 'solver': 'sag', 'max_iter': 7532}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:57:08,407]\u001b[0m Trial 19 finished with value: 0.42703940233763105 and parameters: {'penalty': 'l2', 'C': 68.69679828307575, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 7465}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:57:08,975]\u001b[0m Trial 30 finished with value: 0.42077358717917823 and parameters: {'penalty': 'l2', 'C': 57.8047989593351, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 9665}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:57:11,941]\u001b[0m Trial 15 finished with value: 0.3852271357994939 and parameters: {'penalty': 'l2', 'C': 33.96124676624879, 'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 6769}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:57:33,082]\u001b[0m Trial 20 finished with value: 0.42703940233763105 and parameters: {'penalty': 'l2', 'C': 79.35179600808597, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 532}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:57:33,438]\u001b[0m Trial 27 finished with value: 0.42691890589227616 and parameters: {'penalty': 'l2', 'C': 59.4703558466519, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9877}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:57:38,954]\u001b[0m Trial 24 finished with value: 0.3901674900590433 and parameters: {'penalty': 'l2', 'C': 58.07051354515386, 'class_weight': 'balanced', 'solver': 'sag', 'max_iter': 5741}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:57:40,941]\u001b[0m Trial 33 finished with value: 0.42607543077479215 and parameters: {'penalty': 'l2', 'C': 67.45519251338585, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 3950}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:57:48,191]\u001b[0m Trial 26 finished with value: 0.42703940233763105 and parameters: {'penalty': 'l2', 'C': 56.649869690182214, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 6224}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 01:57:48,885]\u001b[0m Trial 25 finished with value: 0.42703940233763105 and parameters: {'penalty': 'l2', 'C': 54.77592836086235, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 9706}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:57:57,163]\u001b[0m Trial 34 finished with value: 0.41884564405350044 and parameters: {'penalty': 'l2', 'C': 68.27827635284112, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 4109}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:57:58,517]\u001b[0m Trial 32 finished with value: 0.4277623810097602 and parameters: {'penalty': 'l2', 'C': 63.42282164814138, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 6535}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:06,319]\u001b[0m Trial 35 finished with value: 0.42728039522834077 and parameters: {'penalty': 'l2', 'C': 68.8181956132658, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 3846}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:06,609]\u001b[0m Trial 36 finished with value: 0.4214965658513074 and parameters: {'penalty': 'l2', 'C': 44.17672114064455, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 3720}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:07,509]\u001b[0m Trial 37 finished with value: 0.42981082058079284 and parameters: {'penalty': 'l2', 'C': 68.25990537565748, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 4258}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:18,249]\u001b[0m Trial 39 finished with value: 0.42607543077479215 and parameters: {'penalty': 'l2', 'C': 71.31735406485289, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 4276}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:58:21,339]\u001b[0m Trial 48 finished with value: 0.4217375587420171 and parameters: {'penalty': 'l2', 'C': 3.072159563263021, 'class_weight': 'balanced', 'solver': 'lbfgs', 'max_iter': 1817}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:58:31,871]\u001b[0m Trial 49 finished with value: 0.4242679840944692 and parameters: {'penalty': 'l2', 'C': 44.6247576070441, 'class_weight': 'balanced', 'solver': 'lbfgs', 'max_iter': 1829}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:33,731]\u001b[0m Trial 38 finished with value: 0.41679720448246776 and parameters: {'penalty': 'l2', 'C': 70.21865312656485, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 4344}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:34,767]\u001b[0m Trial 40 finished with value: 0.4242679840944692 and parameters: {'penalty': 'l2', 'C': 2.376726654023379, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 3924}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:40,905]\u001b[0m Trial 41 finished with value: 0.4242679840944692 and parameters: {'penalty': 'l2', 'C': 1.9014480045190485, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2001}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:44,434]\u001b[0m Trial 43 finished with value: 0.4243884805398241 and parameters: {'penalty': 'l2', 'C': 3.2884043040915003, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 4521}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:50,448]\u001b[0m Trial 45 finished with value: 0.42800337390046994 and parameters: {'penalty': 'l2', 'C': 46.186459601024666, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 1626}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:50,581]\u001b[0m Trial 42 finished with value: 0.42511145921195326 and parameters: {'penalty': 'l2', 'C': 66.22439538719976, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 4738}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:51,120]\u001b[0m Trial 44 finished with value: 0.4222195445234366 and parameters: {'penalty': 'l2', 'C': 2.0063583791213606, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 4800}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:54,023]\u001b[0m Trial 47 finished with value: 0.42414748764911436 and parameters: {'penalty': 'l2', 'C': 5.0349533970908125, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 1548}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:58:54,347]\u001b[0m Trial 46 finished with value: 0.4222195445234366 and parameters: {'penalty': 'l2', 'C': 45.20402097228422, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 4752}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:59:00,959]\u001b[0m Trial 53 finished with value: 0.4171586938185324 and parameters: {'penalty': 'l2', 'C': 88.26416407216959, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 4805}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:59:12,842]\u001b[0m Trial 52 finished with value: 0.4271598987829859 and parameters: {'penalty': 'l2', 'C': 62.68704578723204, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 4849}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:59:15,398]\u001b[0m Trial 57 finished with value: 0.3757079166164598 and parameters: {'penalty': 'l2', 'C': 10.003209370126442, 'class_weight': None, 'solver': 'saga', 'max_iter': 1117}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:59:15,620]\u001b[0m Trial 56 finished with value: 0.37631039884323414 and parameters: {'penalty': 'l2', 'C': 9.315987710636039, 'class_weight': None, 'solver': 'saga', 'max_iter': 1149}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:59:15,742]\u001b[0m Trial 64 finished with value: 0.4040245812748524 and parameters: {'penalty': 'l2', 'C': 73.92892194255197, 'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 2898}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:59:18,537]\u001b[0m Trial 58 finished with value: 0.4108928786600795 and parameters: {'penalty': 'l2', 'C': 9.907746633612888, 'class_weight': None, 'solver': 'liblinear', 'max_iter': 1254}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:59:25,383]\u001b[0m Trial 31 finished with value: 0.38450415712736474 and parameters: {'penalty': 'l2', 'C': 62.46130333741699, 'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 6379}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:59:42,574]\u001b[0m Trial 67 finished with value: 0.4204120978431136 and parameters: {'penalty': 'l2', 'C': 25.14743692232091, 'class_weight': 'balanced', 'solver': 'lbfgs', 'max_iter': 3153}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:59:44,975]\u001b[0m Trial 65 finished with value: 0.41968911917098445 and parameters: {'penalty': 'l2', 'C': 63.01101588600382, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 3233}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-04-22 01:59:54,263]\u001b[0m Trial 66 finished with value: 0.4265574165562116 and parameters: {'penalty': 'l2', 'C': 25.369692172903022, 'class_weight': 'balanced', 'solver': 'lbfgs', 'max_iter': 6742}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:59:56,645]\u001b[0m Trial 55 finished with value: 0.3759489095071695 and parameters: {'penalty': 'l2', 'C': 75.1219635152572, 'class_weight': None, 'solver': 'saga', 'max_iter': 3276}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 01:59:58,881]\u001b[0m Trial 59 finished with value: 0.37498493794433063 and parameters: {'penalty': 'l2', 'C': 50.21498105605962, 'class_weight': None, 'solver': 'saga', 'max_iter': 3061}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:02,362]\u001b[0m Trial 60 finished with value: 0.3757079166164598 and parameters: {'penalty': 'l2', 'C': 85.96078080550285, 'class_weight': None, 'solver': 'saga', 'max_iter': 3207}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:08,576]\u001b[0m Trial 61 finished with value: 0.37558742017110497 and parameters: {'penalty': 'l2', 'C': 72.67846921378859, 'class_weight': None, 'solver': 'saga', 'max_iter': 3167}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:09,747]\u001b[0m Trial 68 finished with value: 0.42378599831304975 and parameters: {'penalty': 'l2', 'C': 48.482015604682545, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 7071}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:18,364]\u001b[0m Trial 50 finished with value: 0.3829377033377515 and parameters: {'penalty': 'l2', 'C': 50.01817847635006, 'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 5078}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:21,918]\u001b[0m Trial 72 finished with value: 0.42318351608627547 and parameters: {'penalty': 'l2', 'C': 83.62431719183644, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2591}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:22,355]\u001b[0m Trial 62 finished with value: 0.3759489095071695 and parameters: {'penalty': 'l2', 'C': 49.39464796573798, 'class_weight': None, 'solver': 'saga', 'max_iter': 3182}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:23,516]\u001b[0m Trial 51 finished with value: 0.37751536329678276 and parameters: {'penalty': 'l2', 'C': 86.62562573947342, 'class_weight': None, 'solver': 'saga', 'max_iter': 4889}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:25,313]\u001b[0m Trial 78 finished with value: 0.380768767321364 and parameters: {'penalty': 'l2', 'C': 77.47407557555255, 'class_weight': 'balanced', 'solver': 'sag', 'max_iter': 138}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:26,999]\u001b[0m Trial 54 finished with value: 0.3766718881792987 and parameters: {'penalty': 'l2', 'C': 63.001197639469964, 'class_weight': None, 'solver': 'saga', 'max_iter': 4708}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:31,374]\u001b[0m Trial 63 finished with value: 0.3760694059525244 and parameters: {'penalty': 'l2', 'C': 74.39399834407625, 'class_weight': None, 'solver': 'saga', 'max_iter': 3362}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:37,202]\u001b[0m Trial 73 finished with value: 0.4163152187010483 and parameters: {'penalty': 'l2', 'C': 71.59350314526115, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 5493}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:39,712]\u001b[0m Trial 75 finished with value: 0.4233040125316303 and parameters: {'penalty': 'l2', 'C': 76.23226346384486, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 5346}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:47,316]\u001b[0m Trial 70 finished with value: 0.38257621400168695 and parameters: {'penalty': 'l2', 'C': 74.56264478910259, 'class_weight': 'balanced', 'solver': 'sag', 'max_iter': 2455}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:00:58,110]\u001b[0m Trial 74 finished with value: 0.43113628147969635 and parameters: {'penalty': 'l2', 'C': 75.9945341791241, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2476}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:01:01,394]\u001b[0m Trial 76 finished with value: 0.426195927220147 and parameters: {'penalty': 'l2', 'C': 61.07353524715596, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 3554}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:01:09,499]\u001b[0m Trial 80 finished with value: 0.4211350765152428 and parameters: {'penalty': 'l2', 'C': 59.76773096640273, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 5465}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:01:11,325]\u001b[0m Trial 88 finished with value: 0.41848415471743583 and parameters: {'penalty': 'l2', 'C': 66.53478566119537, 'class_weight': 'balanced', 'solver': 'newton-cholesky', 'max_iter': 2718}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:01:17,393]\u001b[0m Trial 81 finished with value: 0.42318351608627547 and parameters: {'penalty': 'l2', 'C': 60.731873755117924, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 5388}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:01:18,658]\u001b[0m Trial 77 finished with value: 0.4275213881190505 and parameters: {'penalty': 'l2', 'C': 60.405176067010416, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 5465}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:01:20,610]\u001b[0m Trial 82 finished with value: 0.4317387637064707 and parameters: {'penalty': 'l2', 'C': 60.42139764244634, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 5456}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:01:30,163]\u001b[0m Trial 83 finished with value: 0.4211350765152428 and parameters: {'penalty': 'l2', 'C': 58.997224800425, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 3668}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:01:37,992]\u001b[0m Trial 84 finished with value: 0.4243884805398241 and parameters: {'penalty': 'l2', 'C': 59.39172570672653, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 6089}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:01:44,196]\u001b[0m Trial 69 finished with value: 0.38980600072297866 and parameters: {'penalty': 'l2', 'C': 51.179926344297535, 'class_weight': 'balanced', 'solver': 'sag', 'max_iter': 5295}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:01:47,897]\u001b[0m Trial 85 finished with value: 0.42764188456440533 and parameters: {'penalty': 'l2', 'C': 61.217639049782974, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 3805}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:01:49,664]\u001b[0m Trial 86 finished with value: 0.42378599831304975 and parameters: {'penalty': 'l2', 'C': 65.94999080834758, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 3677}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:01:54,668]\u001b[0m Trial 87 finished with value: 0.4274008916736956 and parameters: {'penalty': 'l2', 'C': 66.17787386548605, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2207}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:02:01,243]\u001b[0m Trial 89 finished with value: 0.41884564405350044 and parameters: {'penalty': 'l2', 'C': 68.92062339754911, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2128}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:02:03,624]\u001b[0m Trial 71 finished with value: 0.38968550427762383 and parameters: {'penalty': 'l2', 'C': 51.48474185609798, 'class_weight': 'balanced', 'solver': 'sag', 'max_iter': 5449}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:02:04,594]\u001b[0m Trial 92 finished with value: 0.42499096276659837 and parameters: {'penalty': 'l2', 'C': 54.02192771036502, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 5995}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:02:05,338]\u001b[0m Trial 90 finished with value: 0.4233040125316303 and parameters: {'penalty': 'l2', 'C': 65.13887983983567, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2246}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:02:09,860]\u001b[0m Trial 93 finished with value: 0.4277623810097602 and parameters: {'penalty': 'l2', 'C': 54.086014927427776, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 5940}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:02:10,459]\u001b[0m Trial 91 finished with value: 0.4293288347993734 and parameters: {'penalty': 'l2', 'C': 64.80695945214633, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2133}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:02:19,424]\u001b[0m Trial 94 finished with value: 0.42884684901795395 and parameters: {'penalty': 'l2', 'C': 65.35463707651134, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 5894}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:02:23,025]\u001b[0m Trial 97 finished with value: 0.42691890589227616 and parameters: {'penalty': 'l2', 'C': 55.76184573218326, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2251}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:02:24,749]\u001b[0m Trial 79 finished with value: 0.38980600072297866 and parameters: {'penalty': 'l2', 'C': 76.28270554330243, 'class_weight': 'balanced', 'solver': 'sag', 'max_iter': 5417}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:02:25,158]\u001b[0m Trial 96 finished with value: 0.42161706229666224 and parameters: {'penalty': 'l2', 'C': 65.29569464761099, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2283}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:02:25,891]\u001b[0m Trial 95 finished with value: 0.4255934449933727 and parameters: {'penalty': 'l2', 'C': 55.931061463084035, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2245}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:02:27,932]\u001b[0m Trial 98 finished with value: 0.41908663694421017 and parameters: {'penalty': 'l2', 'C': 55.05183268308993, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 5924}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/iuryfaria/Documents/cefet/TCC2/tcc-mcs/env/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2023-04-22 02:03:07,537]\u001b[0m Trial 99 finished with value: 0.4271598987829859 and parameters: {'penalty': 'l2', 'C': 79.98248752717272, 'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 5835}. Best is trial 16 with value: 0.43246174237859986.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_logistic_regression_risk, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Risk\n",
      "Melhor pontuação: 0.43246174237859986\n",
      "Melhores hiperparâmetros: {'penalty': 'l2', 'C': 12.784017261261628, 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 2936}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'Logistic Regression', 'Risk')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_kn_return(trial):\n",
    "    params = {\n",
    "\t\t'n_neighbors': trial.suggest_int('n_neighbors', 5, 200),\n",
    "\t\t'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "\t\t'algorithm': trial.suggest_categorical('algorithm', ['ball_tree', 'kd_tree', 'brute']),\n",
    "\t\t'leaf_size': trial.suggest_int('leaf_size', 30, 100),\n",
    "\t\t'p': trial.suggest_int('p', 1, 3),\n",
    "    \t'n_jobs': N_JOBS\n",
    "\t}\n",
    "    \n",
    "    model = KNeighborsClassifier(**params)\n",
    "    model.fit(X_real_return_train, y_real_return_train)\n",
    "    preds = model.predict(X_real_return_test)\n",
    "    accuracy = accuracy_score(y_real_return_test, preds)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-22 02:03:07,694]\u001b[0m A new study created in memory with name: no-name-09e1b074-7376-4e99-98c3-332d620db329\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:09,903]\u001b[0m Trial 4 finished with value: 0.6046511627906976 and parameters: {'n_neighbors': 73, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 62, 'p': 2}. Best is trial 4 with value: 0.6046511627906976.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:11,518]\u001b[0m Trial 5 finished with value: 0.616580310880829 and parameters: {'n_neighbors': 23, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 44, 'p': 2}. Best is trial 5 with value: 0.616580310880829.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:12,553]\u001b[0m Trial 6 finished with value: 0.5717556332088204 and parameters: {'n_neighbors': 139, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 65, 'p': 2}. Best is trial 5 with value: 0.616580310880829.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:13,448]\u001b[0m Trial 12 finished with value: 0.6697192432823231 and parameters: {'n_neighbors': 187, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 62, 'p': 1}. Best is trial 12 with value: 0.6697192432823231.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:14,331]\u001b[0m Trial 3 finished with value: 0.587781660441017 and parameters: {'n_neighbors': 42, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 73, 'p': 3}. Best is trial 12 with value: 0.6697192432823231.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:14,504]\u001b[0m Trial 0 finished with value: 0.6717676828533559 and parameters: {'n_neighbors': 153, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 87, 'p': 1}. Best is trial 0 with value: 0.6717676828533559.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:14,857]\u001b[0m Trial 8 finished with value: 0.6691167610555488 and parameters: {'n_neighbors': 191, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 74, 'p': 1}. Best is trial 0 with value: 0.6717676828533559.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:15,313]\u001b[0m Trial 2 finished with value: 0.6180262682250873 and parameters: {'n_neighbors': 45, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 83, 'p': 2}. Best is trial 0 with value: 0.6717676828533559.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:15,568]\u001b[0m Trial 7 finished with value: 0.68550427762381 and parameters: {'n_neighbors': 25, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 70, 'p': 1}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:16,504]\u001b[0m Trial 16 finished with value: 0.5893481142306302 and parameters: {'n_neighbors': 114, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 59, 'p': 2}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:17,960]\u001b[0m Trial 11 finished with value: 0.6833353416074226 and parameters: {'n_neighbors': 76, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 31, 'p': 1}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:18,460]\u001b[0m Trial 1 finished with value: 0.5952524400530185 and parameters: {'n_neighbors': 58, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 46, 'p': 2}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:19,681]\u001b[0m Trial 18 finished with value: 0.6107964815037956 and parameters: {'n_neighbors': 54, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:21,393]\u001b[0m Trial 20 finished with value: 0.5866971924328233 and parameters: {'n_neighbors': 141, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 64, 'p': 2}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:22,518]\u001b[0m Trial 17 finished with value: 0.6641764067959995 and parameters: {'n_neighbors': 124, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 58, 'p': 1}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:22,660]\u001b[0m Trial 15 finished with value: 0.6721291721894204 and parameters: {'n_neighbors': 148, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 67, 'p': 1}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:23,610]\u001b[0m Trial 14 finished with value: 0.583443788408242 and parameters: {'n_neighbors': 84, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 98, 'p': 2}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:26,978]\u001b[0m Trial 19 finished with value: 0.6695987468369683 and parameters: {'n_neighbors': 197, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 89, 'p': 1}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:28,176]\u001b[0m Trial 22 finished with value: 0.6779130015664538 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 34, 'p': 1}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:29,148]\u001b[0m Trial 23 finished with value: 0.6787564766839378 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:31,010]\u001b[0m Trial 24 finished with value: 0.6697192432823231 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 33, 'p': 1}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:33,869]\u001b[0m Trial 25 finished with value: 0.6697192432823231 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 35, 'p': 1}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:36,939]\u001b[0m Trial 26 finished with value: 0.6697192432823231 and parameters: {'n_neighbors': 89, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}. Best is trial 7 with value: 0.68550427762381.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:03:46,790]\u001b[0m Trial 34 finished with value: 0.6870707314134233 and parameters: {'n_neighbors': 33, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 40, 'p': 1}. Best is trial 34 with value: 0.6870707314134233.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:01,819]\u001b[0m Trial 29 finished with value: 0.599108326304374 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 32, 'p': 3}. Best is trial 34 with value: 0.6870707314134233.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:12,292]\u001b[0m Trial 36 finished with value: 0.6868297385227136 and parameters: {'n_neighbors': 34, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 40, 'p': 1}. Best is trial 34 with value: 0.6870707314134233.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:12,764]\u001b[0m Trial 13 finished with value: 0.549343294372816 and parameters: {'n_neighbors': 195, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 98, 'p': 3}. Best is trial 34 with value: 0.6870707314134233.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:12,841]\u001b[0m Trial 30 finished with value: 0.5480178334739125 and parameters: {'n_neighbors': 86, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 3}. Best is trial 34 with value: 0.6870707314134233.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:16,099]\u001b[0m Trial 21 finished with value: 0.5907940715748885 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 99, 'p': 3}. Best is trial 34 with value: 0.6870707314134233.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:21,979]\u001b[0m Trial 39 finished with value: 0.6874322207494878 and parameters: {'n_neighbors': 30, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 40, 'p': 1}. Best is trial 39 with value: 0.6874322207494878.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:23,379]\u001b[0m Trial 38 finished with value: 0.6852632847331004 and parameters: {'n_neighbors': 26, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 41, 'p': 1}. Best is trial 39 with value: 0.6874322207494878.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:23,851]\u001b[0m Trial 37 finished with value: 0.6883961923123267 and parameters: {'n_neighbors': 31, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 41, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:24,740]\u001b[0m Trial 31 finished with value: 0.5472948548017833 and parameters: {'n_neighbors': 90, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 39, 'p': 3}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:24,760]\u001b[0m Trial 33 finished with value: 0.573804072779853 and parameters: {'n_neighbors': 27, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 40, 'p': 3}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:26,206]\u001b[0m Trial 40 finished with value: 0.6883961923123267 and parameters: {'n_neighbors': 31, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 40, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:31,965]\u001b[0m Trial 41 finished with value: 0.6870707314134233 and parameters: {'n_neighbors': 33, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 41, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:33,495]\u001b[0m Trial 43 finished with value: 0.6833353416074226 and parameters: {'n_neighbors': 38, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:34,206]\u001b[0m Trial 44 finished with value: 0.6795999518014219 and parameters: {'n_neighbors': 44, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 51, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:34,423]\u001b[0m Trial 42 finished with value: 0.6868297385227136 and parameters: {'n_neighbors': 32, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 39, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:34,496]\u001b[0m Trial 45 finished with value: 0.6853837811784552 and parameters: {'n_neighbors': 37, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 53, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:35,153]\u001b[0m Trial 10 finished with value: 0.5500662730449452 and parameters: {'n_neighbors': 199, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 45, 'p': 3}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:36,664]\u001b[0m Trial 46 finished with value: 0.67682853355826 and parameters: {'n_neighbors': 54, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 52, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:36,670]\u001b[0m Trial 35 finished with value: 0.5698276900831426 and parameters: {'n_neighbors': 35, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 40, 'p': 3}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:38,223]\u001b[0m Trial 9 finished with value: 0.5391010965176527 and parameters: {'n_neighbors': 130, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 47, 'p': 3}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:40,999]\u001b[0m Trial 47 finished with value: 0.6763465477768406 and parameters: {'n_neighbors': 60, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 52, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:43,246]\u001b[0m Trial 51 finished with value: 0.5963369080612122 and parameters: {'n_neighbors': 55, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 46, 'p': 2}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:43,846]\u001b[0m Trial 50 finished with value: 0.5938064827087601 and parameters: {'n_neighbors': 62, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 46, 'p': 2}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:43,896]\u001b[0m Trial 49 finished with value: 0.6771900228943246 and parameters: {'n_neighbors': 59, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 47, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:44,359]\u001b[0m Trial 48 finished with value: 0.6761055548861309 and parameters: {'n_neighbors': 61, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:45,706]\u001b[0m Trial 52 finished with value: 0.6774310157850344 and parameters: {'n_neighbors': 56, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 47, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:46,712]\u001b[0m Trial 53 finished with value: 0.6741776117604531 and parameters: {'n_neighbors': 63, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 45, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:47,494]\u001b[0m Trial 55 finished with value: 0.5934449933726955 and parameters: {'n_neighbors': 60, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 44, 'p': 2}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:47,895]\u001b[0m Trial 54 finished with value: 0.6728521508615496 and parameters: {'n_neighbors': 70, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 45, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:47,933]\u001b[0m Trial 57 finished with value: 0.6867092420773587 and parameters: {'n_neighbors': 17, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 43, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:50,204]\u001b[0m Trial 59 finished with value: 0.6869502349680684 and parameters: {'n_neighbors': 21, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 36, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:50,221]\u001b[0m Trial 58 finished with value: 0.6867092420773587 and parameters: {'n_neighbors': 17, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 56, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:51,006]\u001b[0m Trial 56 finished with value: 0.5938064827087601 and parameters: {'n_neighbors': 62, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 45, 'p': 2}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:51,594]\u001b[0m Trial 27 finished with value: 0.599108326304374 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 3}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:51,764]\u001b[0m Trial 28 finished with value: 0.599108326304374 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 3}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:51,959]\u001b[0m Trial 60 finished with value: 0.6734546330883239 and parameters: {'n_neighbors': 73, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 36, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:52,034]\u001b[0m Trial 61 finished with value: 0.6869502349680684 and parameters: {'n_neighbors': 21, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 36, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:52,786]\u001b[0m Trial 62 finished with value: 0.6869502349680684 and parameters: {'n_neighbors': 21, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 36, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:52,859]\u001b[0m Trial 63 finished with value: 0.6850222918423906 and parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 36, 'p': 1}. Best is trial 37 with value: 0.6883961923123267.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:53,828]\u001b[0m Trial 74 finished with value: 0.6911676105554886 and parameters: {'n_neighbors': 47, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 37, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:53,861]\u001b[0m Trial 32 finished with value: 0.5721171225448849 and parameters: {'n_neighbors': 26, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 3}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:54,110]\u001b[0m Trial 64 finished with value: 0.6869502349680684 and parameters: {'n_neighbors': 21, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 37, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:54,478]\u001b[0m Trial 65 finished with value: 0.6863477527412941 and parameters: {'n_neighbors': 19, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 36, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:54,711]\u001b[0m Trial 75 finished with value: 0.68996264610194 and parameters: {'n_neighbors': 46, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 42, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:54,949]\u001b[0m Trial 76 finished with value: 0.68996264610194 and parameters: {'n_neighbors': 46, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 42, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:55,051]\u001b[0m Trial 77 finished with value: 0.6883961923123267 and parameters: {'n_neighbors': 48, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 42, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:55,297]\u001b[0m Trial 78 finished with value: 0.68996264610194 and parameters: {'n_neighbors': 46, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 42, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:55,824]\u001b[0m Trial 67 finished with value: 0.6803229304735511 and parameters: {'n_neighbors': 46, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 37, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:55,946]\u001b[0m Trial 79 finished with value: 0.6883961923123267 and parameters: {'n_neighbors': 48, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 42, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:56,095]\u001b[0m Trial 81 finished with value: 0.6906856247740691 and parameters: {'n_neighbors': 43, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 43, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:56,244]\u001b[0m Trial 66 finished with value: 0.6804434269189059 and parameters: {'n_neighbors': 45, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 36, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:56,426]\u001b[0m Trial 82 finished with value: 0.6883961923123267 and parameters: {'n_neighbors': 48, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 43, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:56,428]\u001b[0m Trial 80 finished with value: 0.6883961923123267 and parameters: {'n_neighbors': 48, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 77, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:56,935]\u001b[0m Trial 84 finished with value: 0.6911676105554886 and parameters: {'n_neighbors': 47, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 43, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:57,030]\u001b[0m Trial 68 finished with value: 0.6785154837932281 and parameters: {'n_neighbors': 48, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 36, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:57,439]\u001b[0m Trial 83 finished with value: 0.6879142065309073 and parameters: {'n_neighbors': 50, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 81, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:57,476]\u001b[0m Trial 85 finished with value: 0.6879142065309073 and parameters: {'n_neighbors': 50, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 33, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:57,692]\u001b[0m Trial 69 finished with value: 0.6804434269189059 and parameters: {'n_neighbors': 45, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 37, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:57,717]\u001b[0m Trial 86 finished with value: 0.68996264610194 and parameters: {'n_neighbors': 41, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 33, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:57,735]\u001b[0m Trial 88 finished with value: 0.6897216532112302 and parameters: {'n_neighbors': 40, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 33, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:57,766]\u001b[0m Trial 87 finished with value: 0.6897216532112302 and parameters: {'n_neighbors': 40, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 33, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:58,019]\u001b[0m Trial 72 finished with value: 0.6850222918423906 and parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 37, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:58,413]\u001b[0m Trial 90 finished with value: 0.68996264610194 and parameters: {'n_neighbors': 41, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 33, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:58,422]\u001b[0m Trial 71 finished with value: 0.6803229304735511 and parameters: {'n_neighbors': 46, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 38, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:58,559]\u001b[0m Trial 89 finished with value: 0.683817327388842 and parameters: {'n_neighbors': 69, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 48, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:58,972]\u001b[0m Trial 70 finished with value: 0.6557416556211592 and parameters: {'n_neighbors': 173, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 36, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:59,007]\u001b[0m Trial 73 finished with value: 0.6785154837932281 and parameters: {'n_neighbors': 48, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 78, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:59,672]\u001b[0m Trial 92 finished with value: 0.6897216532112302 and parameters: {'n_neighbors': 40, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 49, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:59,800]\u001b[0m Trial 94 finished with value: 0.6897216532112302 and parameters: {'n_neighbors': 40, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 33, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:59,823]\u001b[0m Trial 96 finished with value: 0.68996264610194 and parameters: {'n_neighbors': 41, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 33, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:59,830]\u001b[0m Trial 95 finished with value: 0.6904446318833595 and parameters: {'n_neighbors': 39, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 33, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:04:59,891]\u001b[0m Trial 97 finished with value: 0.6897216532112302 and parameters: {'n_neighbors': 38, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 32, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:00,183]\u001b[0m Trial 91 finished with value: 0.6722496686347753 and parameters: {'n_neighbors': 169, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 48, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:00,193]\u001b[0m Trial 93 finished with value: 0.6712856970719364 and parameters: {'n_neighbors': 166, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 33, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:00,277]\u001b[0m Trial 98 finished with value: 0.67682853355826 and parameters: {'n_neighbors': 110, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 32, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:00,327]\u001b[0m Trial 99 finished with value: 0.6722496686347753 and parameters: {'n_neighbors': 170, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 32, 'p': 1}. Best is trial 74 with value: 0.6911676105554886.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_kn_return, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier - Real Return\n",
      "Melhor pontuação: 0.6911676105554886\n",
      "Melhores hiperparâmetros: {'n_neighbors': 47, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 37, 'p': 1}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'KNeighborsClassifier', 'Real Return')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_kn_risk(trial):\n",
    "    params = {\n",
    "\t\t'n_neighbors': trial.suggest_int('n_neighbors', 5, 200),\n",
    "\t\t'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "\t\t'algorithm': trial.suggest_categorical('algorithm', ['ball_tree', 'kd_tree', 'brute']),\n",
    "\t\t'leaf_size': trial.suggest_int('leaf_size', 30, 100),\n",
    "\t\t'p': trial.suggest_int('p', 1, 3),\n",
    "    \t'n_jobs': N_JOBS\n",
    "\t}\n",
    "    \n",
    "    model = KNeighborsClassifier(**params)\n",
    "    model.fit(X_risk_train, y_risk_train)\n",
    "    preds = model.predict(X_risk_test)\n",
    "    accuracy = accuracy_score(y_risk_test, preds)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-22 02:05:00,479]\u001b[0m A new study created in memory with name: no-name-d7e6d596-071b-4a08-9a36-5224c40e1b31\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:06,292]\u001b[0m Trial 8 finished with value: 0.4075189781901434 and parameters: {'n_neighbors': 80, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 98, 'p': 2}. Best is trial 8 with value: 0.4075189781901434.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:08,837]\u001b[0m Trial 1 finished with value: 0.4119773466682733 and parameters: {'n_neighbors': 96, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 62, 'p': 2}. Best is trial 1 with value: 0.4119773466682733.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:09,058]\u001b[0m Trial 10 finished with value: 0.4205325942884685 and parameters: {'n_neighbors': 81, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 58, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:09,123]\u001b[0m Trial 0 finished with value: 0.4161947222556935 and parameters: {'n_neighbors': 142, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 42, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:10,603]\u001b[0m Trial 12 finished with value: 0.4112543679961441 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 94, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:10,632]\u001b[0m Trial 9 finished with value: 0.4075189781901434 and parameters: {'n_neighbors': 98, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 76, 'p': 2}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:11,553]\u001b[0m Trial 4 finished with value: 0.41571273647427404 and parameters: {'n_neighbors': 39, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 88, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:12,582]\u001b[0m Trial 7 finished with value: 0.4110133751054344 and parameters: {'n_neighbors': 135, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 64, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:13,506]\u001b[0m Trial 2 finished with value: 0.41366429690324136 and parameters: {'n_neighbors': 97, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 43, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:14,978]\u001b[0m Trial 11 finished with value: 0.40643451018194965 and parameters: {'n_neighbors': 172, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 93, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:18,246]\u001b[0m Trial 20 finished with value: 0.40739848174478854 and parameters: {'n_neighbors': 163, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 82, 'p': 2}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:20,109]\u001b[0m Trial 13 finished with value: 0.40836245330762744 and parameters: {'n_neighbors': 107, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 62, 'p': 3}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:20,450]\u001b[0m Trial 15 finished with value: 0.40763947463549827 and parameters: {'n_neighbors': 79, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 46, 'p': 2}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:22,176]\u001b[0m Trial 6 finished with value: 0.40426557416556214 and parameters: {'n_neighbors': 167, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 83, 'p': 3}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:23,441]\u001b[0m Trial 17 finished with value: 0.40848294975298227 and parameters: {'n_neighbors': 138, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 77, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:31,971]\u001b[0m Trial 26 finished with value: 0.41980961561633934 and parameters: {'n_neighbors': 53, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 31, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:34,095]\u001b[0m Trial 25 finished with value: 0.4120978431136281 and parameters: {'n_neighbors': 196, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 33, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:05:39,504]\u001b[0m Trial 27 finished with value: 0.41788167249066155 and parameters: {'n_neighbors': 50, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:27,190]\u001b[0m Trial 21 finished with value: 0.40703699240872393 and parameters: {'n_neighbors': 53, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 3}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:29,156]\u001b[0m Trial 3 finished with value: 0.4047475599469816 and parameters: {'n_neighbors': 181, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 96, 'p': 3}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:35,139]\u001b[0m Trial 19 finished with value: 0.4090854319797566 and parameters: {'n_neighbors': 50, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 64, 'p': 3}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:36,004]\u001b[0m Trial 30 finished with value: 0.4161947222556935 and parameters: {'n_neighbors': 21, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 53, 'p': 2}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:36,552]\u001b[0m Trial 31 finished with value: 0.4131823111218219 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 52, 'p': 2}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:40,121]\u001b[0m Trial 24 finished with value: 0.40763947463549827 and parameters: {'n_neighbors': 136, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 31, 'p': 3}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:40,693]\u001b[0m Trial 5 finished with value: 0.4096879142065309 and parameters: {'n_neighbors': 104, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 47, 'p': 3}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:41,921]\u001b[0m Trial 32 finished with value: 0.41848415471743583 and parameters: {'n_neighbors': 22, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 51, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:43,398]\u001b[0m Trial 18 finished with value: 0.40836245330762744 and parameters: {'n_neighbors': 111, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 69, 'p': 3}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:44,251]\u001b[0m Trial 33 finished with value: 0.41993011206169417 and parameters: {'n_neighbors': 69, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 36, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:45,110]\u001b[0m Trial 23 finished with value: 0.40643451018194965 and parameters: {'n_neighbors': 57, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 38, 'p': 3}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:45,228]\u001b[0m Trial 34 finished with value: 0.41993011206169417 and parameters: {'n_neighbors': 69, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 36, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:46,720]\u001b[0m Trial 22 finished with value: 0.4034220990480781 and parameters: {'n_neighbors': 199, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 38, 'p': 3}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:49,170]\u001b[0m Trial 37 finished with value: 0.4189661404988553 and parameters: {'n_neighbors': 31, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 56, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:49,389]\u001b[0m Trial 36 finished with value: 0.41993011206169417 and parameters: {'n_neighbors': 69, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 36, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:50,500]\u001b[0m Trial 35 finished with value: 0.41788167249066155 and parameters: {'n_neighbors': 66, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 37, 'p': 1}. Best is trial 10 with value: 0.4205325942884685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:51,247]\u001b[0m Trial 38 finished with value: 0.4224605374141463 and parameters: {'n_neighbors': 28, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 38, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:53,019]\u001b[0m Trial 14 finished with value: 0.4034220990480781 and parameters: {'n_neighbors': 165, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 90, 'p': 3}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:53,334]\u001b[0m Trial 39 finished with value: 0.4181226653813713 and parameters: {'n_neighbors': 67, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 36, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:53,933]\u001b[0m Trial 16 finished with value: 0.4059525244005302 and parameters: {'n_neighbors': 165, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 36, 'p': 3}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:54,872]\u001b[0m Trial 41 finished with value: 0.4205325942884685 and parameters: {'n_neighbors': 79, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 37, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:55,537]\u001b[0m Trial 40 finished with value: 0.4163152187010483 and parameters: {'n_neighbors': 77, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 38, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:56,690]\u001b[0m Trial 28 finished with value: 0.40944692131582117 and parameters: {'n_neighbors': 46, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 53, 'p': 3}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:57,065]\u001b[0m Trial 42 finished with value: 0.4211350765152428 and parameters: {'n_neighbors': 74, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 37, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:06:58,659]\u001b[0m Trial 43 finished with value: 0.4189661404988553 and parameters: {'n_neighbors': 70, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 39, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:01,251]\u001b[0m Trial 44 finished with value: 0.41980961561633934 and parameters: {'n_neighbors': 76, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 36, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:02,354]\u001b[0m Trial 45 finished with value: 0.41908663694421017 and parameters: {'n_neighbors': 78, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 43, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:03,889]\u001b[0m Trial 29 finished with value: 0.40836245330762744 and parameters: {'n_neighbors': 47, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 53, 'p': 3}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:04,613]\u001b[0m Trial 46 finished with value: 0.42005060850704906 and parameters: {'n_neighbors': 85, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 43, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:06,091]\u001b[0m Trial 47 finished with value: 0.41872514760814555 and parameters: {'n_neighbors': 121, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 46, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:06,316]\u001b[0m Trial 49 finished with value: 0.4205325942884685 and parameters: {'n_neighbors': 81, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 44, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:06,700]\u001b[0m Trial 48 finished with value: 0.42077358717917823 and parameters: {'n_neighbors': 119, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 43, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:07,230]\u001b[0m Trial 50 finished with value: 0.41968911917098445 and parameters: {'n_neighbors': 83, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 44, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:07,272]\u001b[0m Trial 55 finished with value: 0.41884564405350044 and parameters: {'n_neighbors': 93, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 43, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:07,330]\u001b[0m Trial 56 finished with value: 0.4180021689360164 and parameters: {'n_neighbors': 90, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 43, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:07,680]\u001b[0m Trial 51 finished with value: 0.41884564405350044 and parameters: {'n_neighbors': 93, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 42, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:07,790]\u001b[0m Trial 58 finished with value: 0.41173635377756357 and parameters: {'n_neighbors': 90, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 47, 'p': 2}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:08,075]\u001b[0m Trial 52 finished with value: 0.4180021689360164 and parameters: {'n_neighbors': 90, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 43, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:08,617]\u001b[0m Trial 57 finished with value: 0.4205325942884685 and parameters: {'n_neighbors': 118, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 43, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:08,664]\u001b[0m Trial 53 finished with value: 0.42077358717917823 and parameters: {'n_neighbors': 119, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 43, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:08,954]\u001b[0m Trial 54 finished with value: 0.4211350765152428 and parameters: {'n_neighbors': 125, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 44, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:10,382]\u001b[0m Trial 60 finished with value: 0.4107723822147247 and parameters: {'n_neighbors': 88, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 57, 'p': 2}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:10,408]\u001b[0m Trial 59 finished with value: 0.4081214604169177 and parameters: {'n_neighbors': 93, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 58, 'p': 2}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:10,604]\u001b[0m Trial 61 finished with value: 0.40763947463549827 and parameters: {'n_neighbors': 92, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 59, 'p': 2}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:13,296]\u001b[0m Trial 62 finished with value: 0.40763947463549827 and parameters: {'n_neighbors': 92, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 58, 'p': 2}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:14,173]\u001b[0m Trial 63 finished with value: 0.40932642487046633 and parameters: {'n_neighbors': 116, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 49, 'p': 2}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:15,096]\u001b[0m Trial 67 finished with value: 0.4026991203759489 and parameters: {'n_neighbors': 128, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 57, 'p': 2}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:15,693]\u001b[0m Trial 68 finished with value: 0.40607302084588504 and parameters: {'n_neighbors': 122, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 59, 'p': 2}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:16,023]\u001b[0m Trial 69 finished with value: 0.40535004217375586 and parameters: {'n_neighbors': 153, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 48, 'p': 2}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:16,114]\u001b[0m Trial 64 finished with value: 0.41330280756717674 and parameters: {'n_neighbors': 119, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 40, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:16,423]\u001b[0m Trial 66 finished with value: 0.4128208217857573 and parameters: {'n_neighbors': 121, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 58, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:16,562]\u001b[0m Trial 73 finished with value: 0.4211350765152428 and parameters: {'n_neighbors': 125, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 69, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:16,747]\u001b[0m Trial 65 finished with value: 0.407880467526208 and parameters: {'n_neighbors': 150, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 60, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:16,773]\u001b[0m Trial 71 finished with value: 0.4129413182311122 and parameters: {'n_neighbors': 153, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 49, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:16,799]\u001b[0m Trial 70 finished with value: 0.40607302084588504 and parameters: {'n_neighbors': 122, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 59, 'p': 2}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:17,438]\u001b[0m Trial 72 finished with value: 0.41595372936498376 and parameters: {'n_neighbors': 147, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 49, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:21,372]\u001b[0m Trial 74 finished with value: 0.4129413182311122 and parameters: {'n_neighbors': 153, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 68, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:23,329]\u001b[0m Trial 75 finished with value: 0.4181226653813713 and parameters: {'n_neighbors': 130, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 40, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:27,894]\u001b[0m Trial 76 finished with value: 0.4204120978431136 and parameters: {'n_neighbors': 107, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 69, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:30,604]\u001b[0m Trial 77 finished with value: 0.41595372936498376 and parameters: {'n_neighbors': 147, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 34, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:31,415]\u001b[0m Trial 78 finished with value: 0.4128208217857573 and parameters: {'n_neighbors': 149, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 40, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:32,404]\u001b[0m Trial 80 finished with value: 0.4204120978431136 and parameters: {'n_neighbors': 107, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 68, 'p': 1}. Best is trial 38 with value: 0.4224605374141463.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:32,559]\u001b[0m Trial 84 finished with value: 0.42282202675021086 and parameters: {'n_neighbors': 103, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 75, 'p': 1}. Best is trial 84 with value: 0.42282202675021086.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:32,612]\u001b[0m Trial 82 finished with value: 0.42197855163272685 and parameters: {'n_neighbors': 101, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 70, 'p': 1}. Best is trial 84 with value: 0.42282202675021086.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:32,621]\u001b[0m Trial 79 finished with value: 0.4230630196409206 and parameters: {'n_neighbors': 104, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 69, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:32,982]\u001b[0m Trial 85 finished with value: 0.4201711049524039 and parameters: {'n_neighbors': 108, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 70, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:33,089]\u001b[0m Trial 83 finished with value: 0.41884564405350044 and parameters: {'n_neighbors': 100, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 70, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:33,190]\u001b[0m Trial 81 finished with value: 0.413061814676467 and parameters: {'n_neighbors': 151, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 68, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:35,525]\u001b[0m Trial 86 finished with value: 0.42197855163272685 and parameters: {'n_neighbors': 101, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 74, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:38,066]\u001b[0m Trial 87 finished with value: 0.42197855163272685 and parameters: {'n_neighbors': 101, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 70, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:42,974]\u001b[0m Trial 88 finished with value: 0.41884564405350044 and parameters: {'n_neighbors': 100, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 74, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:44,407]\u001b[0m Trial 89 finished with value: 0.41884564405350044 and parameters: {'n_neighbors': 100, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 67, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:44,735]\u001b[0m Trial 90 finished with value: 0.41848415471743583 and parameters: {'n_neighbors': 59, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 76, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:46,564]\u001b[0m Trial 91 finished with value: 0.4220990480780817 and parameters: {'n_neighbors': 99, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 74, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:46,716]\u001b[0m Trial 92 finished with value: 0.4220990480780817 and parameters: {'n_neighbors': 99, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 74, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:46,858]\u001b[0m Trial 93 finished with value: 0.42258103385950113 and parameters: {'n_neighbors': 102, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 79, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:46,970]\u001b[0m Trial 97 finished with value: 0.4213760694059525 and parameters: {'n_neighbors': 113, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 75, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:46,982]\u001b[0m Trial 95 finished with value: 0.4205325942884685 and parameters: {'n_neighbors': 114, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 74, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:47,033]\u001b[0m Trial 94 finished with value: 0.42282202675021086 and parameters: {'n_neighbors': 103, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 74, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:47,132]\u001b[0m Trial 96 finished with value: 0.4202916013977588 and parameters: {'n_neighbors': 129, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 76, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:47,343]\u001b[0m Trial 98 finished with value: 0.42185805518737196 and parameters: {'n_neighbors': 112, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 76, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 02:07:47,890]\u001b[0m Trial 99 finished with value: 0.42197855163272685 and parameters: {'n_neighbors': 101, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 74, 'p': 1}. Best is trial 79 with value: 0.4230630196409206.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_kn_risk, n_trials=N_TRIALS, n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier - Risk\n",
      "Melhor pontuação: 0.4230630196409206\n",
      "Melhores hiperparâmetros: {'n_neighbors': 104, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 69, 'p': 1}\n"
     ]
    }
   ],
   "source": [
    "print_best_result(study, 'KNeighborsClassifier', 'Risk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc8a3245a31a46333b724f0fa902266a4a2d307e3e7797c60732a355503841f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
