{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Classifiers Ensemble System (MCS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iury Zanonni de Faria"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diversity imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifiers imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = ['Unnamed: 0', 'revenue','cost-goods-sold','gross-profit','research-development-expenses','selling-general-administrative-expenses','operating-expenses',\n",
    "'operating-income','total-non-operating-income-expense','pre-tax-income','total-provision-income-taxes','income-after-taxes','income-from-continuous-operations',\n",
    "'income-from-discontinued-operations','net-income','ebitda','ebit','basic-shares-outstanding','shares-outstanding','eps-basic-net-earnings-per-share',\n",
    "'eps-earnings-per-share-diluted','cash-on-hand','receivables-total','inventory','other-current-assets','total-current-assets','net-property-plant-equipment',\n",
    "'long-term-investments','goodwill-intangible-assets-total','other-long-term-assets','total-long-term-assets','total-assets','total-current-liabilities','long-term-debt',\n",
    "'other-non-current-liabilities','total-long-term-liabilities','total-liabilities','common-stock-net','retained-earnings-accumulated-deficit','comprehensive-income',\n",
    "'total-share-holder-equity','total-liabilities-share-holders-equity','net-income-loss','total-depreciation-amortization-cash-flow','other-non-cash-items','total-non-cash-items',\n",
    "'change-in-accounts-receivable','change-in-inventories','change-in-accounts-payable','change-in-assets-liabilities','total-change-in-assets-liabilities',\n",
    "'cash-flow-from-operating-activities','net-change-in-property-plant-equipment','net-change-in-intangible-assets','net-acquisitions-divestitures','investing-activities-other',\n",
    "'cash-flow-from-investing-activities','net-long-term-debt','net-current-debt','debt-issuance-retirement-net-total','net-common-equity-issued-repurchased',\n",
    "'net-total-equity-issued-repurchased','total-common-preferred-stock-dividends-paid','financial-activities-other','cash-flow-from-financial-activities',\n",
    "'net-cash-flow','stock-based-compensation','common-stock-dividends-paid','current-ratio','long-term-debt-capital','debt-equity-ratio','gross-margin',\n",
    "'operating-margin','ebit-margin','pre-tax-profit-margin','net-profit-margin','asset-turnover','inventory-turnover','receiveable-turnover','days-sales-in-receivables',\n",
    "'roe','return-on-tangible-equity','roa','roi','book-value-per-share','operating-cash-flow-per-share','free-cash-flow-per-share','net-change-in-short-term-investments',\n",
    "'net-change-in-long-term-investments','net-change-in-investments-total','other-operating-income-expenses','pre-paid-expenses','other-share-holders-equity','other-income',\n",
    "'ebitda-margin']\n",
    "\n",
    "REAL_RETURN_CLASS = \"RealReturnClass\"\n",
    "REAL_RETURN = \"RealReturn\"\n",
    "RISK_CLASS = 'RiskClass'\n",
    "RISK = \"Risk\"\n",
    "\n",
    "HIGH = 'high'\n",
    "MEDIUM = 'medium'\n",
    "LOW = 'low'\n",
    "\n",
    "DATE = 'Unnamed: 0'\n",
    "\n",
    "N_PERIODS = 2\n",
    "N_FEATURES = 60\n",
    "\n",
    "DATASET_PATH = 'new_dataset/process_final_{}.csv'.format(N_PERIODS)\n",
    "\n",
    "MUTUAL_INFORMATION = \"MUTUAL_INFORMATION\"\n",
    "\n",
    "SPEARMAN = \"SPEARMAN\"\n",
    "\n",
    "ONE_R = \"ONE_R\"\n",
    "\n",
    "FEATURE_SELECTION = MUTUAL_INFORMATION\n",
    "\n",
    "#Remove os warnings do notebook\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f'files/{FEATURE_SELECTION}_{N_FEATURES}.txt', 'w+')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(dataset:pd.DataFrame, title_1:str, title_2:str):\n",
    "  fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "  fig.set_figwidth(15)\n",
    "  fig.set_figheight(5)\n",
    "\n",
    "  x = dataset[REAL_RETURN_CLASS].value_counts()\n",
    "  x.plot.bar(ax=axes[0])\n",
    "  axes[0].set_title(title_1)\n",
    "\n",
    "  x = dataset[RISK_CLASS].value_counts()\n",
    "  x.plot.bar(ax=axes[1])\n",
    "  axes[1].set_title(title_2)\n",
    "\n",
    "plotResults(dataset, \"Real Return\", \"Risk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.replace(to_replace=[HIGH], value=2.0)\n",
    "dataset = dataset.replace(to_replace=[MEDIUM], value=1.0)\n",
    "dataset = dataset.replace(to_replace=[LOW], value=0.0)\n",
    "\n",
    "dataset = dataset.replace(to_replace=[np.NaN], value=0.0)\n",
    "\n",
    "dataset_X = dataset.drop(columns=[REAL_RETURN_CLASS, REAL_RETURN, RISK_CLASS, RISK, DATE])\n",
    "dataset_y = dataset.drop(columns=DATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"######## FEATURES ########\")\n",
    "file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_start_date = dt.datetime.now()\n",
    "file.write(f\"\\nSTART: {run_start_date}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFeatures(typeFeature, typeClass, num):\n",
    "\tfile = open(f'./feature_selection/files/{typeFeature}_{typeClass}.txt', 'r')\n",
    "\tresult = []\n",
    "\t\n",
    "\tfor feature in file:\n",
    "\t\tresult.append(eval(str(feature)))\n",
    "\t    \n",
    "\tfile.close()\n",
    "    \n",
    "\treturn result[:num]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ranking_real_return = readFeatures(FEATURE_SELECTION, REAL_RETURN, N_FEATURES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ranking_risk  = readFeatures(FEATURE_SELECTION, RISK, N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColumnsRank(rank: list):\n",
    "  ranking = []\n",
    "  for column in rank:\n",
    "    ranking.append(column[0])\n",
    "    \n",
    "  return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_real_return = getColumnsRank(final_ranking_real_return)[:N_FEATURES]\n",
    "features_risk = getColumnsRank(final_ranking_risk)[:N_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"REAL RETURN\\n\")\n",
    "file.write(str(features_real_return))\n",
    "file.write(\"\\nRISK\\n\")\n",
    "file.write(str(features_risk))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O cálculo será feito com o número total de features ou somente com as 15 mais bem ranqueadas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SSCAS = []\n",
    "\n",
    "features_return = getColumnsRank(final_ranking_real_return)[:N_FEATURES]\n",
    "\n",
    "#dataset_X = dataset.drop(columns=[REAL_RETURN_CLASS, REAL_RETURN, RISK_CLASS, RISK, \"Date\", \"Company\"])\n",
    "dataset_X = dataset[features_return]\n",
    "dataset_y = dataset.drop(columns=DATA)\n",
    "\n",
    "dataset_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in range(2, 7):\n",
    "  clusterer = KMeans(n_clusters=cluster, random_state=10)\n",
    "\n",
    "  cluster_labels = clusterer.fit_predict(dataset_X)\n",
    "\n",
    "  silhouette_values = silhouette_samples(dataset_X, cluster_labels)\n",
    "  #silhouette_avg = silhouette_score(dataset_X, cluster_labels)\n",
    "\n",
    "  sum_count = 0\n",
    "  count_2 = 0\n",
    "\n",
    "  #Primeiro somatorio\n",
    "  for k in range(cluster):\n",
    "    count = 0\n",
    "    n_j = 0\n",
    "\n",
    "    #Segundo somatorio\n",
    "    for j in range(len(cluster_labels)):\n",
    "      if cluster_labels[j] == k:\n",
    "        n_j += 1\n",
    "        count += silhouette_values[j]\n",
    "\n",
    "    count_2 = (count/n_j)\n",
    "    sum_count += count_2\n",
    "\n",
    "  SSCA = (sum_count/cluster)\n",
    "  SSCAS.append((cluster, round(SSCA, 2)))\n",
    "\n",
    "SSCAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n\\n######## SSCAS ########\\n\\n\")\n",
    "file.write(str(SSCAS))\n",
    "file.write(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dataset = DATA\n",
    "columns_dataset.append(REAL_RETURN)\n",
    "columns_dataset.append(RISK)\n",
    "columns_dataset.append(REAL_RETURN_CLASS)\n",
    "columns_dataset.append(RISK_CLASS)\n",
    "\n",
    "df_train = None\n",
    "df_test = None\n",
    "\n",
    "df_train = pd.DataFrame(columns=columns_dataset)\n",
    "df_test = pd.DataFrame(columns=columns_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING_START_DATE =  dt.datetime.strptime('2009-03-31', \"%Y-%m-%d\")\n",
    "# TRAINING_END_DATE =  dt.datetime.strptime('2018-03-31', \"%Y-%m-%d\")\n",
    "\n",
    "# TEST_START_DATE =  dt.datetime.strptime('2018-06-30', \"%Y-%m-%d\")\n",
    "# TEST_END_DATE =  dt.datetime.strptime('2022-03-31', \"%Y-%m-%d\")\n",
    "\n",
    "# dataset_sort = dataset.sort_values(by=DATE)\n",
    "# count_train = 0\n",
    "# count_test = 0\n",
    "\n",
    "# for index, row in dataset_sort.iterrows():\n",
    "#   date = dt.datetime.strptime(row[DATE], \"%Y-%m-%d\")\n",
    "#   if date.year < TEST_START_DATE.year:\n",
    "#     df_train = df_train.append(row)\n",
    "#     count_train +=1\n",
    "#   elif date.year == TEST_START_DATE.year and date.month < TEST_START_DATE.month:\n",
    "#     df_train = df_train.append(row)\n",
    "#     count_train +=1\n",
    "#   else:\n",
    "#     df_test = df_test.append(row)\n",
    "#     count_test += 1\n",
    "\n",
    "# print(count_train)\n",
    "# print(count_test)\n",
    "\n",
    "# df_train = df_train.drop(columns=[REAL_RETURN, RISK, DATE])\n",
    "# df_test = df_test.drop(columns=[REAL_RETURN, RISK, DATE])\n",
    "\n",
    "# plotResults(df_train, \"Real Return\", \"Risk\")\n",
    "\n",
    "# plotResults(df_test, \"Real Return\", \"Risk\")\n",
    "\n",
    "# df_train.to_csv('./util/dataset_train.csv')\n",
    "# df_test.to_csv('./util/dataset_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./util/dataset_train.csv')\n",
    "df_test = pd.read_csv('./util/dataset_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_return_train = df_train[features_real_return]\n",
    "y_real_return_train = df_train[REAL_RETURN_CLASS]\n",
    "\n",
    "X_real_return_test = df_test[features_real_return]\n",
    "y_real_return_test = df_test[REAL_RETURN_CLASS]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risk_train = df_train[features_risk]\n",
    "y_risk_train = df_train[RISK_CLASS]\n",
    "\n",
    "X_risk_test = df_test[features_risk]\n",
    "y_risk_test = df_test[RISK_CLASS]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificadores Únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## CLASSIFICADORES UNICOS ########\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_real_return = {}\n",
    "classifiers_risk = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_FOREST = 'RANDOM_FOREST'\n",
    "\n",
    "randon_forest_return = RandomForestClassifier(n_estimators = 840, max_depth = 178, min_samples_split = 4, min_samples_leaf = 6, max_features = 'sqrt')\n",
    "classifiers_real_return[RANDOM_FOREST] = randon_forest_return\n",
    "\n",
    "randon_forest_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_randon_forest_return = randon_forest_return.score(X_real_return_test, y_real_return_test)\n",
    "result_randon_forest_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randon_forest_risk = RandomForestClassifier(n_estimators = 622, max_depth = 70, min_samples_split = 3, min_samples_leaf = 9, max_features = 'log2')\n",
    "\n",
    "classifiers_risk[RANDOM_FOREST] = randon_forest_risk\n",
    "randon_forest_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_randon_forest_risk = randon_forest_risk.score(X_risk_test, y_risk_test)\n",
    "result_randon_forest_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"RANDOM FOREST:({result_randon_forest_return},{result_randon_forest_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = 'SVM'\n",
    "\n",
    "svm_real_return = SVC(kernel = 'rbf', C = 99.94849891435051, class_weight = 'balanced')\n",
    "classifiers_real_return[SVM] = svm_real_return\n",
    "\n",
    "svm_real_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_svm_return = svm_real_return.score(X_real_return_test, y_real_return_test)\n",
    "result_svm_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_risk = SVC(kernel = 'rbf', C = 99.89489576327396, class_weight = 'balanced')\n",
    "classifiers_risk[SVM] = svm_risk\n",
    "\n",
    "svm_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_svm_risk = svm_risk.score(X_risk_test, y_risk_test)\n",
    "result_svm_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"SVM:({result_svm_return},{result_svm_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECISION_TREE = 'DECISION_TREE'\n",
    "\n",
    "decision_tree_real_return = DecisionTreeClassifier(criterion = 'entropy', splitter = 'best', max_depth = 10, min_samples_split = 1097)\n",
    "classifiers_real_return[DECISION_TREE] = decision_tree_real_return\n",
    "\n",
    "decision_tree_real_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_decision_return = decision_tree_real_return.score(X_real_return_test, y_real_return_test)\n",
    "result_decision_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_risk = DecisionTreeClassifier(criterion = 'entropy', splitter = 'best', max_depth = 133, min_samples_split = 919)\n",
    "classifiers_risk[DECISION_TREE] = decision_tree_risk\n",
    "\n",
    "decision_tree_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_decision_risk = decision_tree_risk.score(X_risk_test, y_risk_test)\n",
    "result_decision_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"DECISION TREE:({result_decision_return},{result_decision_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAIVE_BAYES = 'NAIVE_BAYES'\n",
    "\n",
    "nb_real_return = GaussianNB(var_smoothing = 1.1218244619811e-12)\n",
    "classifiers_real_return[NAIVE_BAYES] = nb_real_return\n",
    "\n",
    "nb_real_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_nb_return = nb_real_return.score(X_real_return_test, y_real_return_test)\n",
    "result_nb_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_risk = GaussianNB(var_smoothing = 1.013375533407592e-12)\n",
    "classifiers_risk[NAIVE_BAYES] = nb_risk\n",
    "\n",
    "nb_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_nb_risk = nb_risk.score(X_risk_test, y_risk_test)\n",
    "result_nb_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"NAIVE BAYES:({result_nb_return},{result_nb_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rede Neural"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEURAL_NETWORK = 'NEURAL_NETWORK'\n",
    "neural_return = MLPClassifier(activation = 'logistic', solver = 'lbfgs', max_iter = 500, hidden_layer_sizes = (300,), learning_rate = 'constant')\n",
    "classifiers_real_return[NEURAL_NETWORK] = neural_return\n",
    "\n",
    "neural_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_neural_return = neural_return.score(X_real_return_test, y_real_return_test)\n",
    "result_neural_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_risk = MLPClassifier(activation = 'logistic', solver = 'lbfgs', max_iter = 500, hidden_layer_sizes = (300,), learning_rate = 'constant')\n",
    "classifiers_risk[NEURAL_NETWORK] = neural_risk\n",
    "\n",
    "neural_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_neural_risk = neural_risk.score(X_risk_test, y_risk_test)\n",
    "result_neural_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"NEURAL NETWORK:({result_neural_return},{result_decision_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGISTIC_REGRESSION ='LOGISTIC_REGRESSION'\n",
    "\n",
    "rl_return = LogisticRegression(penalty = 'l2', C = 8.82516085005323, class_weight = None, solver = 'newton-cg', max_iter = 5411)\n",
    "classifiers_real_return[LOGISTIC_REGRESSION] = rl_return\n",
    "\n",
    "rl_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_rl_return = rl_return.score(X_real_return_test, y_real_return_test)\n",
    "result_rl_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_risk = LogisticRegression(penalty = 'l2', C = 12.784017261261628, class_weight = 'balanced', solver = 'liblinear', max_iter = 2936)\n",
    "classifiers_risk[LOGISTIC_REGRESSION] = rl_risk\n",
    "\n",
    "rl_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_rl_risk = rl_risk.score(X_risk_test, y_risk_test)\n",
    "result_rl_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"LOGISTIC REGRESSION:({result_rl_return},{result_rl_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_NEIGHBORS ='KNeighborsClassifier'\n",
    "\n",
    "knn_return = KNeighborsClassifier(n_neighbors = 47, weights = 'distance', algorithm = 'kd_tree', leaf_size = 37, p = 1)\n",
    "classifiers_real_return[K_NEIGHBORS] = knn_return\n",
    "\n",
    "knn_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_knn_result = knn_return.score(X_real_return_test, y_real_return_test)\n",
    "result_knn_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_risk = KNeighborsClassifier(n_neighbors = 47, weights = 'distance', algorithm = 'kd_tree', leaf_size = 37, p = 1)\n",
    "classifiers_risk[K_NEIGHBORS] = knn_risk\n",
    "\n",
    "knn_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_knn_risk = knn_risk.score(X_risk_test, y_risk_test)\n",
    "result_knn_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"KNEIGHBORS:({result_knn_result},{result_knn_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGboost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_BOOST = 'XG_BOOST'\n",
    "\n",
    "xg_boost_return = xgboost.XGBClassifier()\n",
    "classifiers_real_return[XG_BOOST] = xg_boost_return\n",
    "\n",
    "xg_boost_return.fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "result_xgboost_result = xg_boost_return.score(X_real_return_test, y_real_return_test)\n",
    "result_xgboost_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_boost_risk = xgboost.XGBClassifier()\n",
    "classifiers_risk[XG_BOOST] = xg_boost_risk\n",
    "\n",
    "xg_boost_risk.fit(X_risk_train, y_risk_train)\n",
    "\n",
    "result_xgboost_risk = xg_boost_risk.score(X_risk_test, y_risk_test)\n",
    "result_xgboost_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"XGBOOST:({result_xgboost_result},{result_xgboost_risk})\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 10\n",
    "result_cv_real_return = {}\n",
    "result_cv_risk = {}\n",
    "\n",
    "X_dataset_real_return = dataset[features_real_return]\n",
    "y_dataset_real_return = dataset[REAL_RETURN_CLASS]\n",
    "\n",
    "X_dataset_risk = dataset[features_risk]\n",
    "y_dataset_risk = dataset[RISK_CLASS]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = cross_val_score(classifiers_real_return[RANDOM_FOREST], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[RANDOM_FOREST] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[SVM], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[SVM] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[DECISION_TREE], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[DECISION_TREE] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[NAIVE_BAYES], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[NAIVE_BAYES] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[NEURAL_NETWORK], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[NEURAL_NETWORK] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[LOGISTIC_REGRESSION], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[LOGISTIC_REGRESSION] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[K_NEIGHBORS], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[K_NEIGHBORS] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_real_return[XG_BOOST], X_dataset_real_return, y_dataset_real_return, cv=CV, n_jobs=-1)\n",
    "result_cv_real_return[XG_BOOST] = cv_result.mean()\n",
    "\n",
    "result_cv_real_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = cross_val_score(classifiers_risk[RANDOM_FOREST], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[RANDOM_FOREST] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[SVM], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[SVM] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[DECISION_TREE], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[DECISION_TREE] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[NAIVE_BAYES], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[NAIVE_BAYES] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[NEURAL_NETWORK], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[NEURAL_NETWORK] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[LOGISTIC_REGRESSION], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[LOGISTIC_REGRESSION] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[K_NEIGHBORS], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[K_NEIGHBORS] = cv_result.mean()\n",
    "\n",
    "cv_result = cross_val_score(classifiers_risk[XG_BOOST], X_dataset_risk, y_dataset_risk, cv=CV, n_jobs=-1)\n",
    "result_cv_risk[XG_BOOST] = cv_result.mean()\n",
    "\n",
    "result_cv_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## CV ########\\n\")\n",
    "file.write(f\"Real Return: {result_cv_real_return}\\n\")\n",
    "file.write(f\"Risk: {result_cv_risk}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Of Cassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = list(result_cv_real_return.keys())\n",
    "list_sets = []\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "  for j in range(i + 1, len(classifiers)):\n",
    "    list_sets.append((classifiers[i], classifiers[j]))\n",
    "\n",
    "list_sets\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Return Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_return_classifiers = []\n",
    "\n",
    "for classifier_set in list_sets:  \n",
    "  set_0 = result_cv_real_return[classifier_set[0]]\n",
    "  set_1 = result_cv_real_return[classifier_set[1]]\n",
    "\n",
    "  avg = (set_0 + set_1) / 2\n",
    "  if avg >= 0.75:\n",
    "    if classifier_set[0] not in real_return_classifiers:\n",
    "      real_return_classifiers.append(classifier_set[0])\n",
    "\n",
    "    if classifier_set[1] not in real_return_classifiers:\n",
    "      real_return_classifiers.append(classifier_set[1])\n",
    "\n",
    "real_return_classifiers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_classifiers = []\n",
    "\n",
    "for classifier_set in list_sets:  \n",
    "  set_0 = result_cv_risk[classifier_set[0]]\n",
    "  set_1 = result_cv_risk[classifier_set[1]]\n",
    "\n",
    "  avg = (set_0 + set_1) / 2\n",
    "  if avg >= 0.45:\n",
    "    if classifier_set[0] not in risk_classifiers:\n",
    "      risk_classifiers.append(classifier_set[0])\n",
    "\n",
    "    if classifier_set[1] not in risk_classifiers:\n",
    "      risk_classifiers.append(classifier_set[1])\n",
    "\n",
    "risk_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## CLASSIFIERS SELECTION ########\\n\")\n",
    "file.write(f\"Real Return: {real_return_classifiers}\\n\")\n",
    "file.write(f\"Risk: {risk_classifiers}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion of Classifiers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with diversification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Whitout diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## WHITOUT DIVERSITY ########\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_return_whitout_diversity = {}\n",
    "\n",
    "for classifier in real_return_classifiers:\n",
    "  real_return_whitout_diversity[classifier] = classifiers_real_return[classifier]\n",
    "  real_return_whitout_diversity[classifier].fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "  file.write(f\"Real Return: {classifier}, {real_return_whitout_diversity[classifier].score(X_real_return_test, y_real_return_test)}\\n\")\n",
    "  print(classifier, real_return_whitout_diversity[classifier].score(X_real_return_test, y_real_return_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_whitout_diversity = {}\n",
    "\n",
    "for classifier in risk_classifiers:\n",
    "  risk_whitout_diversity[classifier] = classifiers_risk[classifier]\n",
    "  risk_whitout_diversity[classifier].fit(X_risk_train, y_risk_train)\n",
    "\n",
    "  file.write(f\"Risk: {classifier}, {risk_whitout_diversity[classifier].score(X_risk_test, y_risk_test)}\\n\")\n",
    "  print(classifier, risk_whitout_diversity[classifier].score(X_risk_test, y_risk_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## BAGGING ########\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_return_bagging = {}\n",
    "count = 0\n",
    "for classifier in real_return_classifiers:\n",
    "  estimator = classifiers_real_return[classifier]\n",
    "  real_return_bagging[classifier] = BaggingClassifier(estimator=estimator, n_jobs=-1)\n",
    "  real_return_bagging[classifier].fit(X_real_return_train, y_real_return_train)\n",
    "\n",
    "  file.write(f\"Real Return: {classifier}, {real_return_bagging[classifier].score(X_real_return_test, y_real_return_test)}\\n\")\n",
    "  print(classifier, real_return_bagging[classifier].score(X_real_return_test, y_real_return_test))\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_bagging = {}\n",
    "\n",
    "for classifier in risk_classifiers:\n",
    "  estimator = classifiers_risk[classifier]\n",
    "  risk_bagging[classifier] = BaggingClassifier(estimator=estimator, n_jobs=-1)\n",
    "  risk_bagging[classifier].fit(X_risk_train, y_risk_train)\n",
    "\n",
    "  file.write(f\"Risk: {classifier}, {risk_bagging[classifier].score(X_risk_test, y_risk_test)}\\n\")\n",
    "  print(classifier, risk_bagging[classifier].score(X_risk_test, y_risk_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## ADABOOST ########\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_return_adaboost = {}\n",
    "\n",
    "for classifier in real_return_classifiers:\n",
    "  estimator = classifiers_real_return[classifier]\n",
    "  try:\n",
    "    real_return_adaboost[classifier] = AdaBoostClassifier(estimator=estimator)\n",
    "    real_return_adaboost[classifier].fit(X_real_return_train, y_real_return_train)\n",
    "    file.write(f\"RealReturn: {classifier}, {real_return_adaboost[classifier].score(X_real_return_test, y_real_return_test)}\\n\")\n",
    "    print(classifier, real_return_adaboost[classifier].score(X_real_return_test, y_real_return_test))\n",
    "  except:\n",
    "    real_return_adaboost.pop(classifier)\n",
    "    print(classifier, \"Não utilizado\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_adaboost = {}\n",
    "\n",
    "for classifier in risk_classifiers:\n",
    "  estimator = classifiers_risk[classifier]\n",
    "  try:\n",
    "    risk_adaboost[classifier] = AdaBoostClassifier(estimator=estimator)\n",
    "    risk_adaboost[classifier].fit(X_risk_train, y_risk_train)\n",
    "    file.write(f\"Risk: {classifier}, {risk_adaboost[classifier].score(X_risk_test, y_risk_test)}\\n\")\n",
    "    print(classifier, risk_adaboost[classifier].score(X_risk_test, y_risk_test))\n",
    "  except:\n",
    "    risk_adaboost.pop(classifier)\n",
    "    print(classifier, \"Não utilizado\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fusion = xgboost.XGBClassifier()\n",
    "model_fusion_name = XG_BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"\\n######## FUSION ########\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(fusion_model, models, X_data, y_data):\n",
    "  df_fusion = pd.DataFrame()\n",
    "\n",
    "  for model in models:\n",
    "    X_predict = models[model].predict(X_data)\n",
    "  \n",
    "    df_fusion[model] = X_predict\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(df_fusion, y_data, test_size=0.3, random_state=42)\n",
    "\n",
    "  print(X_train)\n",
    "  fusion_model.fit(X_train, y_train)\n",
    "  \n",
    "  return fusion_model.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Whitout diversity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiout_return = fusion(model_fusion, real_return_whitout_diversity, X_dataset_real_return, y_dataset_real_return)\n",
    "whiout_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiout_risk = fusion(model_fusion, risk_whitout_diversity, X_dataset_risk, y_dataset_risk)\n",
    "whiout_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"[WHITOUT] [{model_fusion_name}] RealReturn: {whiout_return}\\n\")\n",
    "file.write(f\"[WHITOUT] [{model_fusion_name}] Risk: {whiout_risk}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bagging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_return = fusion(model_fusion, real_return_bagging, X_dataset_real_return, y_dataset_real_return)\n",
    "bagging_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_risk = fusion(model_fusion, risk_bagging, X_dataset_risk, y_dataset_risk)\n",
    "bagging_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"[BAGGING] [{model_fusion_name}] RealReturn: {bagging_return}\\n\")\n",
    "file.write(f\"[BAGGING] [{model_fusion_name}] Risk: {bagging_risk}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_return = fusion(model_fusion, real_return_adaboost, X_dataset_real_return, y_dataset_real_return)\n",
    "ada_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_risk = fusion(model_fusion, risk_adaboost, X_dataset_risk, y_dataset_risk)\n",
    "ada_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(f\"[ADABOOST] [{model_fusion_name}] RealReturn: {ada_return}\\n\")\n",
    "file.write(f\"[ADABOOST] [{model_fusion_name}] Risk: {ada_risk}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_end_date = dt.datetime.now()\n",
    "file.write(f\"\\nEND: {run_end_date}\")\n",
    "file.write(f\"\\nTOTAL EXEC: {run_end_date-run_start_date}\")\n",
    "\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc8a3245a31a46333b724f0fa902266a4a2d307e3e7797c60732a355503841f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
