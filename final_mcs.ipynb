{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Classifiers Ensemble System (MCS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iury Zanonni de Faria"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "# Info gain - App do passarinho"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diversity imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifiers imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = ['Date', 'Current Ratio','Quick Ratio','Current Assets', 'Long-term debt to equity ratio', 'Share Holder Equity','Debt to Equity Ratio', 'Percentage of net profit to sale',\n",
    "'Percentage of operating profit to sale','Percentage of Gross profit to sale','ROA','ROE','EPS','P/E','P/S','Stock book value','Stock Price','ROI','MarketReturn', 'Company']\n",
    "\n",
    "REAL_RETURN_CLASS = \"RealReturnClass\"\n",
    "REAL_RETURN = \"RealReturn\"\n",
    "RISK_CLASS = 'RiskClass'\n",
    "RISK = \"Risk\"\n",
    "\n",
    "HIGH = 'high'\n",
    "MEDIUM = 'medium'\n",
    "LOW = 'low'\n",
    "\n",
    "N_PERIODS = 2\n",
    "N_FEATURES = 15\n",
    "\n",
    "DATASET_PATH = 'dataset/process_final_reverse_{}.csv'.format(N_PERIODS)\n",
    "\n",
    "#Remove os warnings do notebook\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(dataset:pd.DataFrame, title_1:str, title_2:str):\n",
    "  fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "  fig.set_figwidth(15)\n",
    "  fig.set_figheight(5)\n",
    "\n",
    "  x = dataset[REAL_RETURN_CLASS].value_counts()\n",
    "  x.plot.bar(ax=axes[0])\n",
    "  axes[0].set_title(title_1)\n",
    "\n",
    "  x = dataset[RISK_CLASS].value_counts()\n",
    "  x.plot.bar(ax=axes[1])\n",
    "  axes[1].set_title(title_2)\n",
    "\n",
    "plotResults(dataset, \"Real Return\", \"Risk\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.replace(to_replace=[HIGH], value=2.0)\n",
    "dataset = dataset.replace(to_replace=[MEDIUM], value=1.0)\n",
    "dataset = dataset.replace(to_replace=[LOW], value=0.0)\n",
    "\n",
    "dataset_X = dataset.drop(columns=[REAL_RETURN_CLASS, REAL_RETURN, RISK_CLASS, RISK, \"Date\", \"Company\"])\n",
    "dataset_y = dataset.drop(columns=DATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_real_return = mutual_info_classif(dataset_X, dataset_y[REAL_RETURN_CLASS], discrete_features=True)\n",
    "\n",
    "result_real_return = {}\n",
    "\n",
    "for i in range(0, len(dataset_X.columns)):\n",
    "    result_real_return[dataset_X.columns[i]] = rank_real_return[i]\n",
    "\n",
    "final_ranking_real_return = sorted(result_real_return.items(), key=lambda x: x[1])\n",
    "final_ranking_real_return.reverse()\n",
    "final_ranking_real_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_risk = mutual_info_classif(dataset_X, dataset_y[RISK_CLASS], discrete_features=True)\n",
    "\n",
    "result_risk = {}\n",
    "\n",
    "for i in range(0, len(dataset_X.columns)):\n",
    "    result_risk[dataset_X.columns[i]] = rank_risk[i]\n",
    "\n",
    "final_ranking_risk = sorted(result_risk.items(), key=lambda x: x[1])\n",
    "final_ranking_risk.reverse()\n",
    "final_ranking_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColumnsRank(rank: list):\n",
    "  ranking = []\n",
    "  for column in rank:\n",
    "    ranking.append(column[0])\n",
    "    \n",
    "  return ranking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O cálculo será feito com o número total de features ou somente com as 15 mais bem ranqueadas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SSCAS = []\n",
    "\n",
    "features_return = getColumnsRank(final_ranking_real_return)[:N_FEATURES]\n",
    "\n",
    "#dataset_X = dataset.drop(columns=[REAL_RETURN_CLASS, REAL_RETURN, RISK_CLASS, RISK, \"Date\", \"Company\"])\n",
    "dataset_X = dataset[features_return]\n",
    "dataset_y = dataset.drop(columns=DATA)\n",
    "\n",
    "dataset_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cluster in range(2, 7):\n",
    "#   clusterer = KMeans(n_clusters=cluster, random_state=10)\n",
    "\n",
    "#   cluster_labels = clusterer.fit_predict(dataset_X)\n",
    "\n",
    "#   silhouette_values = silhouette_samples(dataset_X, cluster_labels)\n",
    "#   #silhouette_avg = silhouette_score(dataset_X, cluster_labels)\n",
    "\n",
    "#   sum_count = 0\n",
    "#   count_2 = 0\n",
    "\n",
    "#   #Primeiro somatorio\n",
    "#   for k in range(cluster):\n",
    "#     count = 0\n",
    "#     n_j = 0\n",
    "\n",
    "#     #Segundo somatorio\n",
    "#     for j in range(len(cluster_labels)):\n",
    "#       if cluster_labels[j] == k:\n",
    "#         n_j += 1\n",
    "#         count += silhouette_values[j]\n",
    "\n",
    "#     count_2 = (count/n_j)\n",
    "#     sum_count += count_2\n",
    "\n",
    "#   SSCA = (sum_count/cluster)\n",
    "#   SSCAS.append((cluster, round(SSCA, 2)))\n",
    "\n",
    "# SSCAS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificadores Únicos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<s>RandomForestClassifier</s>\n",
    "\n",
    "SVC\n",
    "\n",
    "DecisionTreeClassifier\n",
    "\n",
    "GaussianNB\n",
    "\n",
    "MLPClassifier\n",
    "\n",
    "xgboost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divisão do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dataset = DATA\n",
    "columns_dataset.append(REAL_RETURN)\n",
    "columns_dataset.append(RISK)\n",
    "columns_dataset.append(REAL_RETURN_CLASS)\n",
    "columns_dataset.append(RISK_CLASS)\n",
    "\n",
    "df_train = None\n",
    "df_test = None\n",
    "\n",
    "df_train = pd.DataFrame(columns=columns_dataset)\n",
    "df_test = pd.DataFrame(columns=columns_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_START_DATE =  dt.datetime.strptime('2009-03-31', \"%Y-%m-%d\")\n",
    "TRAINING_END_DATE =  dt.datetime.strptime('2018-03-31', \"%Y-%m-%d\")\n",
    "\n",
    "TEST_START_DATE =  dt.datetime.strptime('2018-06-30', \"%Y-%m-%d\")\n",
    "TEST_END_DATE =  dt.datetime.strptime('2022-03-31', \"%Y-%m-%d\")\n",
    "\n",
    "dataset_sort = dataset.sort_values(by='Date')\n",
    "count_train = 0\n",
    "count_test = 0\n",
    "\n",
    "for index, row in dataset_sort.iterrows():\n",
    "  date = dt.datetime.strptime(row['Date'], \"%Y-%m-%d\")\n",
    "  if date.year < TEST_START_DATE.year:\n",
    "    df_train = df_train.append(row)\n",
    "    count_train +=1\n",
    "  elif date.year == TEST_START_DATE.year and date.month < TEST_START_DATE.month:\n",
    "    df_train = df_train.append(row)\n",
    "    count_train +=1\n",
    "  else:\n",
    "    df_test = df_test.append(row)\n",
    "    count_test += 1\n",
    "\n",
    "print(count_train)\n",
    "print(count_test)\n",
    "\n",
    "df_train = df_train.drop(columns=[REAL_RETURN, RISK, \"Date\", \"Company\"])\n",
    "df_test = df_test.drop(columns=[REAL_RETURN, RISK, \"Date\", \"Company\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[REAL_RETURN_CLASS, RISK_CLASS])\n",
    "y_real_return_train = df_train[REAL_RETURN_CLASS]\n",
    "y_risk_train = df_train[RISK_CLASS]\n",
    "\n",
    "plotResults(df_train, \"Real Return\", \"Risk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns=[REAL_RETURN_CLASS, RISK_CLASS])\n",
    "y_real_return_test = df_test[REAL_RETURN_CLASS]\n",
    "y_risk_test = df_test[RISK_CLASS]\n",
    "\n",
    "plotResults(df_test, \"Real Return\", \"Risk\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randon_forest_return = RandomForestClassifier(max_depth=10, random_state=42)\n",
    "randon_forest_return.fit(X_train, y_real_return_train)\n",
    "\n",
    "randon_forest_return.score(X_test, y_real_return_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randon_forest_risk = RandomForestClassifier(max_depth=100, random_state=10)\n",
    "randon_forest_risk.fit(X_train, y_risk_train)\n",
    "\n",
    "randon_forest_risk.score(X_test, y_risk_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kernel in (\"linear\", \"rbf\", \"poly\"):\n",
    "  svm = SVC(kernel=kernel, gamma=10)\n",
    "  svm.fit(X_train, y_real_return_train)\n",
    "\n",
    "  print(kernel, svm.score(X_test, y_real_return_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kernel in (\"linear\", \"rbf\", \"poly\"):\n",
    "  svm = SVC(kernel=kernel, gamma=10)\n",
    "  svm.fit(X_train, y_risk_train)\n",
    "\n",
    "  print(kernel, svm.score(X_test, y_risk_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc8a3245a31a46333b724f0fa902266a4a2d307e3e7797c60732a355503841f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
